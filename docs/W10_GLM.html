<!DOCTYPE html>
<html lang="en"><head>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/tabby.min.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.3.353">

  <meta name="author" content="Dr.&nbsp;Mario Reutter (slides adapted from Dr.&nbsp;Lea Hildebrandt)">
  <title>Biostatistics - 10 The General Linear Model &amp; Multivariate Statistics</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="site_libs/revealjs/dist/theme/quarto.css">
  <link href="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-titled.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-titled) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-titled.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-titled .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-titled .callout-title  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-titled.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-titled.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-title {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-title {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-title {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-titled .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-titled .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-titled) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-title {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-title {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-title {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-title {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-title {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">10 The General Linear Model &amp; Multivariate Statistics</h1>
  <p class="subtitle"></p><p>Julius-Maximilians-University Würzburg<br>
Course: “Biostatistics”<br>
Translational Neuroscience</p><p></p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Dr.&nbsp;Mario Reutter (slides adapted from Dr.&nbsp;Lea Hildebrandt) 
</div>
</div>
</div>

</section>
<section>
<section id="general-linear-model-glm" class="title-slide slide level1 center">
<h1>General Linear Model (GLM)</h1>
<div class="cell">
<style type="text/css">
code.sourceCode {
  font-size: 1.4em;
}

div.cell-output-stdout {
  font-size: 1.4em;
}
</style>
</div>
<p>Remember the basic model of statistics:</p>
<p><span class="math display">\[
data = model + error
\]</span></p>
<p>Our general goal is to find the model with the <em>best fit</em>, i.e., that minimizes the error.</p>
<div class="fragment">
<p>One approach is the GLM. You might be surprised that a lot of the common models can be viewed as linear models:</p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/linear_tests_cheat_sheet.png"></p>
<figcaption>All models can be thought of as linear models</figcaption>
</figure>
</div>
</div>
</section>
<section id="definitions" class="slide level2">
<h2>Definitions</h2>
<p><strong>Dependent variable (DV)</strong>: The outcome variable that the model aims to explain (<span class="math inline">\(Y\)</span>).</p>
<p><strong>Independent variable (IV)</strong>: The variable(s) that we use to explain the DV (<span class="math inline">\(X\)</span>).</p>
<p><strong>Linear model</strong>: The model for the DV is composed of a <em>linear combination</em> of IVs (that are multiplied by different <u>weights</u>!)</p>
<div class="fragment">
<p>The weights are the <em>parameters</em> <span class="math inline">\(\beta\)</span> and determine the relative contribution of each IV. (This is what the model estimates! The weights thus give us the important information we’re usually interested in: How strong are IV and DV related.)</p>
<p>There may also be several DVs (“<em>multivariate statistics</em>”), but usually that’s not the case except for specific biopsychological methods (e.g., fMRI). Thus, we will focus on those cases with one DV!</p>
</div>
</section>
<section id="example" class="slide level2">
<h2>Example</h2>
<div class="columns">
<div class="column">
<p>Let’s use some simulated data:</p>
<div class="cell">
<div class="cell-output-display">
<p><img data-src="W10_GLM_files/figure-revealjs/unnamed-chunk-3-1.png" style="height:50.0%" width="288"></p>
</div>
</div>
</div><div class="column">
<p>We can calculate the <em>correlation</em> between the two variables:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>
    Pearson's product-moment correlation

data:  df$grade and df$studyTime
t = 2.0134, df = 6, p-value = 0.09073
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 -0.1261283  0.9255245
sample estimates:
      cor 
0.6349813 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>r(6) = .63 [-.13; .93], p = .091</code></pre>
</div>
</div>
<p>The correlation is quite high (.63), but the CI is also pretty wide.</p>
</div>
</div>
<div class="fragment">
<p>Fundamental activities of statistics:</p>
<ul>
<li><p><em>Describe</em>: How strong is the relationship between grade and study time?</p></li>
<li><p><em>Decide</em>: Is there a statistically significant relationship between grade and study time?</p></li>
<li><p><em>Predict</em>: Given a particular amount of study time, what grade do we expect?</p></li>
</ul>
<aside class="notes">
<p>relationship study time and grade</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section>
<section id="linear-regression" class="slide level2">
<h2>Linear Regression</h2>
<p>Use the GLM to…</p>
<div>
<ul>
<li class="fragment"><p>describe the relation between two variables (similar to correlation)</p></li>
<li class="fragment"><p>predict DV for new values of IV (new observations)</p></li>
<li class="fragment"><p>add multiple IVs!</p></li>
</ul>
</div>
<div class="fragment">
<div class="columns">
<div class="column">
<p>Simple GLM (here: equivalent to linear regression):</p>
<p><span class="math display">\[
y = \beta_0+ x * \beta_x + \epsilon
\]</span></p>
<p><span class="math inline">\(\beta_0\)</span> = <em>intercept</em>: the overall offset of the line when <span class="math inline">\(x=0\)</span> (this cannot always be interpreted)<br>
<span class="math inline">\(\beta_x\)</span> = <em>slope</em>: how much do we expect <span class="math inline">\(y\)</span> to change with each change in <span class="math inline">\(x\)</span>?<br>
<span class="math inline">\(y\)</span> = <em>DV</em><br>
<span class="math inline">\(x\)</span> = <em>IV</em> or <em>predictor<br>
<span class="math inline">\(\epsilon\)</span> = </em>error term* or <em>resudials</em>: whatever variance is left once the model is fit (Think of the model as the blue line and the residuals are the vertical deviations of the data points from the line)</p>
<p>(If we refer to <em>predicted</em> <span class="math inline">\(y\)</span>-values, after we have estimated the model, we can drop the error term: <span class="math inline">\(\hat{y} = \hat{\beta_0} + x * \hat{\beta_x}\)</span>.)</p>
</div><div class="column">
<div class="cell">
<div class="cell-output-display">
<p><img data-src="W10_GLM_files/figure-revealjs/unnamed-chunk-5-1.png" width="960"></p>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="the-relation-between-correlation-and-regression" class="slide level2">
<h2>The Relation Between Correlation and Regression</h2>
<p>There is a close relation and we can convert <span class="math inline">\(r\)</span> to <span class="math inline">\(\hat{\beta_x}\)</span>.</p>
<p><span class="math inline">\(\hat{r} = \frac{covariance_{xy}}{s_x * s_y}\)</span></p>
<p><span class="math inline">\(\hat{\beta_x} = \frac{covariance_{xy}}{s_x*s_x}\)</span></p>
<p><span class="math inline">\(covariance_{xy} = \hat{r} * s_x * s_y\)</span></p>
<p><span class="math inline">\(\hat{\beta_x} = \frac{\hat{r} * s_x * s_y}{s_x * s_x} = r * \frac{s_y}{s_x}\)</span></p>
<p>--&gt; Regression slope = correlation multiplied by ratio of SDs (if SDs are equal, <span class="math inline">\(r\)</span> = <span class="math inline">\(\hat{\beta}\)</span> )</p>
<aside class="notes">
<p>Estimation of GLM:</p>
<p>linear algebra (R will do that for us!) –&gt; Appendix book</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="standard-errors-for-regression-models" class="slide level2">
<h2>Standard Errors for Regression Models</h2>
<p>We usually want to make inferences about the regression parameter estimates. For this we need an estimate of their variability.</p>
<p>We first need an estimate of how much variability is <em>not</em> explained by the model: the <strong>residual variance</strong> (or <strong>error variance</strong>):</p>
<p>Compute <em>residuals</em>:</p>
<p><span class="math display">\[
residual = y - \hat{y} = y - (x*\hat{\beta_x} + \hat{\beta_0})
\]</span></p>
<p>Compute <em>Sum of Squared Errors</em> (remember from ANOVA?):</p>
<p><span class="math display">\[
SS_{error} = \sum_{i=1}^n{(y_i - \hat{y_i})^2} = \sum_{i=1}^n{residuals^2}
\]</span></p>
<p>Compute <em>Mean Squared Error</em>:</p>
<p><span class="math display">\[
MS_{error} = \frac{SS_{error}}{df} = \frac{\sum_{i=1}^n{(y_i - \hat{y_i})^2} }{N - p}
\]</span></p>
<p>where the <span class="math inline">\(df\)</span> are the number of observations <span class="math inline">\(N\)</span> - the number of estimated parameter <span class="math inline">\(p\)</span> (in this case 2: <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\hat{\beta_x}\)</span>).</p>
<p>Finally, we can calculate the <em>standard error</em> for the <em>full</em> model:</p>
<p><span class="math display">\[
SE_{model} = \sqrt{MS_{error}}
\]</span></p>
<p>We can also calculate the SE for specific regression parameter estimates by rescaling the <span class="math inline">\(SE_{model}\)</span>:</p>
<p><span class="math display">\[
SE_{\hat{\beta_x}} = \frac{SE_{model}}{\sqrt{\sum{(x_i - \bar{x})^2}}}
\]</span></p>
<aside class="notes">
<p>rescaling SE: by square root of the SS of the X variable</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="statistical-tests-for-regression-parameters" class="slide level2">
<h2>Statistical Tests for Regression Parameters</h2>
<p>With the parameter estimates and their standard errors, we can compute <span class="math inline">\(t\)</span>-statistics, which represent the likelihood of the observed estimate vs.&nbsp;the expected value under <span class="math inline">\(H_0\)</span> (usually 0, no effect).</p>
<p><span class="math display">\[
\begin{array}{c}
t_{N - p} = \frac{\hat{\beta} - \beta_{expected}}{SE_{\hat{\beta}}}\\
t_{N - p} = \frac{\hat{\beta} - 0}{SE_{\hat{\beta}}}\\
t_{N - p} = \frac{\hat{\beta} }{SE_{\hat{\beta}}}
\end{array}
\]</span></p>
</section>
<section id="glm-results" class="slide level2">
<h2>GLM results</h2>
<p>Usually, we would just let R do the calculations:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a><span class="fu">summary</span>(lmResult)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = grade ~ studyTime, data = df)

Residuals:
    Min      1Q  Median      3Q     Max 
-10.656  -2.719   0.125   4.703   7.469 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   76.156      5.161  14.756 6.09e-06 ***
studyTime      4.313      2.142   2.013   0.0907 .  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 6.386 on 6 degrees of freedom
Multiple R-squared:  0.4032,    Adjusted R-squared:  0.3037 
F-statistic: 4.054 on 1 and 6 DF,  p-value: 0.09073</code></pre>
</div>
</div>
<p>The intercept is significantly different from zero (which is usually not very relevant: with 0 study time, you don’t get 0%) and the effect of <code>studyTime</code> is not (or only “marginally”) significant. So for every hour that we study more, the effect on the grade is <em>descriptively</em> rather small (~4%) but possibly not present at all (because it is not <em>statistically</em> significant).</p>
<aside class="notes">
<p><span class="math inline">\(t\)</span> ratio of <span class="math inline">\(\beta\)</span> to its <span class="math inline">\(SE\)</span>!</p>
<p>intercept: expected grade without studying at all</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="quantifying-goodness-of-fit-of-the-model" class="slide level2">
<h2>Quantifying Goodness of Fit of the Model</h2>
<p>Often, it is useful to check how good the (total) model we estimated fits the data.</p>
<div class="fragment">
<p>We can do that easily by asking <em>how much of the variability in the data is accounted for by the model?</em></p>
</div>
<div class="fragment">
<p>If we only have one IV (<span class="math inline">\(x\)</span>), then we can simply square the correlation coefficient:</p>
<p><span class="math display">\[
R^2 = r^2
\]</span></p>
<p>In study time example, <span class="math inline">\(R^2\)</span> = 0.63² = 0.4 –&gt; we accounted for 40% of the overall variance in grades!</p>
</div>
<div class="fragment">
<p>More generally, we can calculate <span class="math inline">\(R^2\)</span> with the Sum of Squared Variances:</p>
<p><span class="math display">\[
R^2 = \frac{SS_{model}}{SS_{total}} = 1-\frac{SS_{error}}{SS_{total}}
\]</span></p>
</div>
<div class="fragment">
<p>With a sample of sufficient size, it is possible to get highly significant values that still explain very little of the total variance (i.e., little <em>practical</em> significance despite <em>statistical</em> significance)</p>
<aside class="notes">
<p><span class="math inline">\(R^2\)</span> is the name of the Goodness of Fit stat!</p>
<p>A small R² tells us that even though a model might be significant, it may only explain a small amount of information in the DV</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section>
<section id="fitting-more-complex-models" class="slide level2">
<h2>Fitting More Complex Models</h2>
<p>Often we want to know the effects of <em>multiple variables</em> (IVs) on some outcome.</p>
<p>Example:<br>
Some students have taken a very similar class before, so there might not only be the effect of <code>studyTime</code> on <code>grades</code>, but also of having taken a <code>priorClass</code>.</p>
<div class="fragment">
<div class="columns">
<div class="column">
<p>We can built a model that takes both into account by simply adding the “weight” and the IV (<code>priorClass</code>) to the model:</p>
<p><span class="math inline">\(\hat{y} = \hat{\beta_1}*studyTime + \hat{\beta_2}*priorClass + \hat{\beta_0}\)</span></p>
<div>
<ul>
<li class="fragment">To model <code>priorClass</code>, i.e.&nbsp;whether each individual has taken a previous class or not, we use <strong>dummy coding</strong> (0=no, 1=yes).</li>
<li class="fragment">This means, for those who have <em>not</em> taken a class, the whole part of the equation (<span class="math inline">\(\hat{\beta_2} * priorClass\)</span>) will be zero - we will add it for the others.</li>
<li class="fragment"><span class="math inline">\(\hat{\beta_2}\)</span> is thus the difference in means between the two groups!</li>
<li class="fragment"><span class="math inline">\(\hat{\beta_1}\)</span> is the regression slope of <code>studyTime</code> across data points/regardless of whether someone has taken a class before.</li>
</ul>
</div>
</div><div class="column">
<p>If we plot the data, we can see that both IVs seem to have an effect on grades:</p>
<div class="cell">
<div class="cell-output-display">
<p><img data-src="W10_GLM_files/figure-revealjs/unnamed-chunk-7-1.png" width="480"></p>
</div>
</div>
</div>
</div>
<aside class="notes">
<p>How can we tell from the plot that both IVs might have an effect?</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section>
<section id="interactions-between-variables" class="slide level2">
<h2>Interactions Between Variables</h2>
<p>We previously assumed that the effect of <code>studyTime</code> on <code>grade</code> was the same for both groups - but sometimes we expect that this regression slope differs per group!</p>
<p>E.g., due to prior knowledge from another class, it may be <em>easier</em> to profit from studying the new materials (i.e., steeper slope). Or it may be <em>harder</em> due to diminishing marginal returns (i.e., flatter slope).</p>
<div class="fragment">
<p><br>
This is what we call an <strong>interaction</strong>: The effect of one variable depends on the value of another variable.</p>
<p>Thus, <code>priorClass</code> can have a <strong>main effect</strong> on <code>grade</code> (i.e., independent of <code>studyTime</code>): “I already know more, so I don’t need to study”.<br>
But it can also <strong>interact</strong> with <code>studyTime</code>: “Due to my prior knowledge, I can study more efficiently.”</p>
</div>
</section>
<section id="interaction-example" class="slide level2">
<h2>Interaction Example</h2>
<p>Example: What is the effect of caffeine on public speaking?</p>
<p><br>
</p>
<div class="columns">
<div class="column" style="width:60%;">
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a><span class="co"># perform linear regression with caffeine as independent variable</span></span>
<span id="cb5-2"><a href="#cb5-2"></a>lmResultCaffeine <span class="ot">&lt;-</span> <span class="fu">lm</span>(speaking <span class="sc">~</span> caffeine, <span class="at">data =</span> df)</span>
<span id="cb5-3"><a href="#cb5-3"></a><span class="fu">summary</span>(lmResultCaffeine)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = speaking ~ caffeine, data = df)

Residuals:
    Min      1Q  Median      3Q     Max 
-33.096 -16.024   5.014  16.453  26.979 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)  -7.4132     9.1653  -0.809    0.429
caffeine      0.1676     0.1508   1.111    0.281

Residual standard error: 19.19 on 18 degrees of freedom
Multiple R-squared:  0.06419,   Adjusted R-squared:  0.0122 
F-statistic: 1.235 on 1 and 18 DF,  p-value: 0.2811</code></pre>
</div>
</div>
</div><div class="column" style="width:40%;">
<div class="cell">
<div class="cell-output-display">
<p><img data-src="W10_GLM_files/figure-revealjs/unnamed-chunk-10-1.png" width="384"></p>
</div>
</div>
</div>
</div>
<div class="fragment">
<p>There doesn’t seem to be a “direct” (bivariate) effect:</p>
</div>
</section>
<section id="interaction-example-two-main-effects" class="slide level2">
<h2>Interaction Example: Two main effects</h2>
<p>What if we have the hypothesis that <code>anxiety</code> also affects public speaking?</p>
<p><br>
</p>
<div class="columns">
<div class="column" style="width:60%;">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = speaking ~ caffeine + anxiety, data = df)

Residuals:
    Min      1Q  Median      3Q     Max 
-32.968  -9.743   1.351  10.530  25.361 

Coefficients:
                  Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)       -12.5812     9.1967  -1.368    0.189
caffeine            0.1313     0.1446   0.908    0.377
anxietynotAnxious  14.2328     8.2324   1.729    0.102

Residual standard error: 18.21 on 17 degrees of freedom
Multiple R-squared:  0.2041,    Adjusted R-squared:  0.1105 
F-statistic:  2.18 on 2 and 17 DF,  p-value: 0.1436</code></pre>
</div>
</div>
</div><div class="column" style="width:40%;">
<div class="cell">
<div class="cell-output-display">
<p><img data-src="W10_GLM_files/figure-revealjs/unnamed-chunk-12-1.png" width="384"></p>
</div>
</div>
</div>
</div>
<div class="fragment">
<p>The new model is still not significant. This is due to the fact that we only look at <strong>additive effects</strong> (main effects). But neither caffeine nor anxiety alone/independently predict public speaking performance.</p>
</div>
<div class="fragment">
<p>From the plot, however, it looks like the effect of caffeine is indeed different for the two anxiety groups: Increasing for non-anxious people and decreasing for anxious ones.</p>
<p>In other words: We need to have a model that allows to fit different regression <em>slopes</em> to both groups.</p>
<aside class="notes">
<p>explain additive effects: look at average caffeine effect, then add mean for anxiety groups (but: both not significant here!)</p>
<p>problem of independent main effects: also if you bring together two findings from two different papers =&gt; no information about interaction of predictors</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section>
<section id="interaction-example-full-model" class="slide level2">
<h2>Interaction Example: Full model</h2>
<p>To allow for different slopes for each group (i.e.&nbsp;for the effect of caffeine to vary between the anxiety groups), we have to model the <em>interaction</em> as well.</p>
<div class="columns">
<div class="column" style="width:60%;">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = speaking ~ caffeine + anxiety + caffeine:anxiety, 
    data = df)

Residuals:
    Min      1Q  Median      3Q     Max 
-11.385  -7.103  -0.444   6.171  13.458 

Coefficients:
                            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)                 17.43085    5.43012   3.210 0.005461 ** 
caffeine                    -0.47416    0.09664  -4.906 0.000158 ***
anxietynotAnxious          -43.44873    7.79141  -5.576 4.17e-05 ***
caffeine:anxietynotAnxious   1.08395    0.12931   8.382 3.01e-07 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 8.085 on 16 degrees of freedom
Multiple R-squared:  0.8524,    Adjusted R-squared:  0.8247 
F-statistic:  30.8 on 3 and 16 DF,  p-value: 7.014e-07</code></pre>
</div>
</div>
</div><div class="column" style="width:40%;">
<div class="cell">
<div class="cell-output-display">
<p><img data-src="W10_GLM_files/figure-revealjs/unnamed-chunk-14-1.png" width="384"></p>
</div>
</div>
</div>
</div>
<div class="fragment">
<p>The model is now significant! There is an <em>interaction</em> between <code>caffeine</code> and <code>anxiety</code>. Interestingly, the <em>main effects</em> are also significant now even though they were not in the previous models (because the residual variance has been reduced drastically from 18 to 8 by the highly significant interaction).</p>
<p>Note: <code>speaking ~ caffeine * anxiety</code> is shorthand for <code>speaking ~ caffeine + anxiety + caffeine:anxiety</code></p>
</div>
</section>
<section id="convert-glm-to-anova" class="slide level2">
<h2>Convert GLM to ANOVA</h2>
<p>The interpretation of the coefficients of a GLM when interactions are included is not as straight forward compared to an ANOVA!</p>
<div class="fragment">
<p>If you want to report the “typical” ANOVA table with main effects and the general interaction:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1"></a><span class="fu">anova</span>(lmResultInteraction)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Response: speaking
                 Df Sum Sq Mean Sq F value   Pr(&gt;F)    
caffeine          1  454.8   454.8  6.9578 0.017911 *  
anxiety           1  991.5   991.5 15.1678 0.001288 ** 
caffeine:anxiety  1 4593.4  4593.4 70.2662 3.01e-07 ***
Residuals        16 1045.9    65.4                     
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
</div>
<div class="fragment">
<p>Note: The <em>p</em>-values are different between the GLM and the ANOVA outputs because effects including factors are coded slightly differently (dummy vs.&nbsp;effect coding):</p>
<p>Dummy coding uses the first level as a default and compares the remaining levels to it (<span class="math inline">\(0\)</span> vs.&nbsp;<span class="math inline">\(1\)</span>).<br>
Effect coding takes the overall mean as an abstract comparison (<span class="math inline">\(-.5\)</span> vs.&nbsp;<span class="math inline">\(+.5\)</span>).<br>
This difference is resembled in the output tables as <code>anxietynotAnxious</code> (GLM) vs.&nbsp;<code>anxiety</code> (ANOVA).</p>
<aside class="notes">
<p>interpretation coefficients:</p>
<p>intercept: intercept of anxious group!</p>
<p>intercept not anxious: difference intercept anxious vs.&nbsp;notanxious</p>
<p>slope anxious: only for the anxious group!</p>
<p>slope not anxious: diff in slopes</p>
<p>no main effects!!!</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section>
<section id="model-comparison" class="slide level2">
<h2>Model Comparison</h2>
<p>Sometimes, we want to compare two (<em>nested</em>!) models to see which one fits the data better.</p>
<p>We can do so by using the <code>anova()</code>* function in R:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1"></a><span class="fu">anova</span>(lmResultCafAnx, lmResultInteraction)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Model 1: speaking ~ caffeine + anxiety
Model 2: speaking ~ caffeine + anxiety + caffeine:anxiety
  Res.Df    RSS Df Sum of Sq      F   Pr(&gt;F)    
1     17 5639.3                                 
2     16 1045.9  1    4593.4 70.266 3.01e-07 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>This shows that Model 2, incl.&nbsp;the interaction, is to be preferred.</p>
<div class="fragment">
<p><em>Note</em>: We can only meaningfully use this method with so-called nested models, which means that the simpler (<em>reduced</em>) model only contains variables also included in the more complex (<em>full</em>) model.</p>

<aside class="notes">
<p>Wald compares the ratio of squared errors to an F-distribution (sound familiar from ANOVA?), while likelihood ratio compares the ratio of likelihoods to a χ2 distribution</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
<aside><div>
<p>*Yes, it is <em>kind of</em> an ANOVA as well, in that (a ratio of) squared errors is compared to an <span class="math inline">\(F\)</span>-distribution…</p>
</div></aside></section>
<section id="criticizing-our-model-and-checking-assumptions" class="slide level2">
<h2>Criticizing Our Model and Checking Assumptions</h2>
<p>“Garbage in, garbage out” - we have to make sure our model is properly specified!</p>
<div class="fragment">
<p><em>Properly specified</em> = having included the appropriate IVs.</p>
</div>
<div class="fragment">
<p>The model also needs to satisfy the <strong>assumptions</strong> of the statistical method (= GLM).</p>
<p>One important assumption of the GLM is that <em>the residuals are normally distributed</em>.</p>
<p>This assumption can be violated by a not properly specified model or because the data are inappropriate for the statistical model.</p>
</div>
<div class="fragment">
<p>We can use a <strong>Q-Q plot</strong>, which represents the quantiles of two distributions/variables (e.g., the data and a normal distribution of the same data) against each other.</p>
<p>If the data points diverge substantially from the line (especially in the extremes), we can conclude that the residuals are not normally distributed.</p>
</div>
</section>
<section id="model-diagnostics" class="slide level2">
<h2>Model Diagnostics</h2>
<p>To check the assumptions, we can easily run a function for model diagnostics (incl.&nbsp;Q-Q plots) in R. The function, <code>check_model()</code>, is included in the <code>performance</code> package by the <a href="https://easystats.github.io/easystats/index.html"><em>easystats</em></a> team (who make great packages for everything related to statistical modeling!)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1"></a><span class="co"># install.packages("easystats")</span></span>
<span id="cb13-2"><a href="#cb13-2"></a><span class="fu">library</span>(performance)</span>
<span id="cb13-3"><a href="#cb13-3"></a></span>
<span id="cb13-4"><a href="#cb13-4"></a><span class="fu">check_model</span>(lmResultInteraction)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>

</div>
<img data-src="W10_GLM_files/figure-revealjs/unnamed-chunk-17-1.png" width="960" class="r-stretch"><aside class="notes">
<p>We’re not going into detail about all these diagnostics (and hard to see!), but it is always a good idea to run diagnostics/check assumptions for your models!</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="remark-predicting-in-a-statistical-context" class="slide level2">
<h2>Remark: “Predicting” in a Statistical Context</h2>
<p>We neither mean “predicting before seeing the data/in the future” nor mean to imply <em>causality</em>!</p>
<div class="fragment">
<p>It simply refers to fitting a model to the data: We estimate (or predict) values for the DV (<span class="math inline">\(\hat{y}\)</span>) and the IVs are often referred to as <em>predictors</em>.</p>
<aside class="notes">
<p>Related to: predicting future values</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section></section>
<section>
<section id="multivariate-statistics" class="title-slide slide level1 center">
<h1>Multivariate Statistics</h1>
<p><em>Multivariate</em> = involving more than one (dependent) variable.</p>
<p>Usually, the distinction between dependent and independent variables is not very strict (rather depends on the model than on the data itself). In the following section, we are interested in how a number of variables relate to one another (no clear predictor vs.&nbsp;criterion).</p>
<div>
<ol type="1">
<li class="fragment"><p><strong>Clustering</strong>: Understand the structure that exists in the data, find clusters of observations or variables that are similar.<br>
=&gt; From dimensions to categories</p></li>
<li class="fragment"><p><strong>Dimensionality reduction</strong>: Reduce a large set of variables to fewer, retaining as much information as possible.<br>
=&gt; From many dimensions to fewer dimensions</p></li>
</ol>
</div>
<div class="fragment">
<p>These two methods belong to the class of <em>unsupervised learning</em>. Before, we have only dealt with <em>supervised learning</em> (e.g., regression, ANOVA). There are also methods for multivariate, supervised learning (e.g., MANOVA).</p>
<p>Note: Unsupervised learning techniques are very <em>explorative</em> in nature. It is a different approach to learning from data compared to hypothesis testing. Explorative methods are usually used in science to create a first insight into new phenomena that can develop into hypotheses further down the line.</p>
<aside class="notes">
<p>Supervised: we know the value of the DV that we’re trying to predict (try to find best model predictions).</p>
<p>Unsupervised: we don’t have specific value to predict, we try to discover (patterns that help understand). Requires some assumptions about pattern.</p>
<p>--&gt; does not necessarily have a “right” answer!</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section>
<section id="multivariate-data-an-example" class="slide level2">
<h2>Multivariate Data: An Example</h2>
<p>How do different aspects of psychological function (self-control etc.) relate to one another?</p>
<p>10h battery of cognitive tests and surveys, N = 522, 9 measures of interest!</p>
<p>Measures:</p>
<ul>
<li><p><em>Response inhibition</em>: ability to quickly stop an action (measured with the stop-signal task, measure is called <em>stop-signal reaction time (SSRT)</em> - we have 4 different versions of this measure).</p></li>
<li><p><em>Impulsivity</em>: tendency to make decisions on impulse, without regard of potential consequences (<em>UPPS-P</em> survey, assesses 5 facets of impulsivity).</p></li>
</ul>
</section>
<section id="visualizing-multivariate-data" class="slide level2">
<h2>Visualizing Multivariate Data</h2>
<p>Hard (impossible?) for us to visualize more than three dimensions/variables.</p>

<img data-src="W10_GLM_files/figure-revealjs/unnamed-chunk-19-1.png" width="768" class="r-stretch quarto-figure-center"><p class="caption">Scatterplot of matrices for the nine variables in the self-control dataset. The diagonal elements in the matrix show the histogram for each of the individual variables. The lower left panels show scatterplots of the relationship between each pair of variables, and the upper right panel shows the correlation coefficient for each pair of variables.</p><aside class="notes">
<p>What do you see?</p>
<p>each row/col –&gt; single variable<br>
diagonal: dist each var<br>
lower triangle: scatterplot each pair, regression line –&gt; relationship<br>
upper: correlation coefficient</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="heatmap" class="slide level2">
<h2>Heatmap</h2>
<p>Visualize correlations:</p>

<img data-src="W10_GLM_files/figure-revealjs/hmap-1.png" width="768" class="r-stretch quarto-figure-center"><p class="caption">Heatmap of the correlation matrix for the nine self-control variables. The brighter yellow areas in the top left and bottom right highlight the higher correlations within the two subsets of variables.</p><p>We can see clear clusters: SSRT and UPPS have greater intercorrelations than correlations with the other measure.</p>
</section>
<section id="heatmap-2" class="slide level2">
<h2>Heatmap 2</h2>
<p>Heatmaps are especially helpful if we have a large number of variables, such as in neuroimaging! Below you can see the <em>functional connectivity</em> of &gt;300 brain regions:</p>

<img data-src="images/Heatmap2.png" width="445" class="r-stretch quarto-figure-center"><p class="caption">Heatmap of correlation coefficients of brain activity between 316 regions of the left hemisphere of a single individual. Yellow: strong positive correlations, blue: strong negative correlations</p><aside class="notes">
<p>large blocks of pos corr: major connected networks in the brain</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="clustering" class="slide level2">
<h2>Clustering</h2>
<p><strong>Clustering</strong>: Identifying groups of related observations or variables within a dataset, based on the similarity of the values of the observations.</p>
<div class="fragment">
<p><strong>Similarity</strong>: Distance between values.</p>
<p><strong>Euclidean Distance</strong>: Length of the line that connects two data points:</p>
<div class="cell">
<div class="cell-output-display">
<p><img data-src="W10_GLM_files/figure-revealjs/unnamed-chunk-20-1.png" width="288"></p>
</div>
</div>
<p><span class="math display">\[
d(x,y) = \sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}
\]</span></p>
</div>
<div class="fragment">
<p>Euclidean Distance is sensitive to variability in both variables –&gt; <em>scale</em> data before! (e.g., z-transformation using R’s <code>scale</code> function)</p>
<aside class="notes">
<p>Clustering: finding set of groups that have the lowest distance between their members.</p>
<p>Euclidean Dist: Pythagorean theorem<br>
–&gt; can be extended to more than two dimensions!</p>
<p>Scale: calculate z-score, standardizing</p>
<p>Example: Relation between height and weight =&gt; it shouldn’t make a difference if we rescale the data from m to cm or from kg to pounds.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section>
<section id="k-means-clustering" class="slide level2">
<h2>K-Means Clustering</h2>
<p><strong>K-means clustering</strong>: Identifies a set of cluster centers &amp; then assigns each data point to the cluster whose center is the closest (Euclidean Distance!).</p>
<div>
<ol type="1">
<li class="fragment">Decide on value for <em>K</em>, the number of clusters to be found (e.g.&nbsp;based on previous knowledge/expectations).</li>
<li class="fragment">Come up with <em>k</em> locations for the centers - or <em>centroids</em> - of the clusters (e.g.&nbsp;choose data points at random to start with).</li>
<li class="fragment">Compute Euclidean distance of each data point to each centroid.</li>
<li class="fragment">Assign each point to a cluster, based on closest distance to centroid.</li>
<li class="fragment">Recompute centroid by averaging the location of all points assigned to that cluster.</li>
<li class="fragment">Repeat steps 1-5 until a stable solution is found (<em>iterative</em> process).</li>
</ol>
</div>
</section>
<section id="example-latitudelongitude-data" class="slide level2">
<h2>Example: Latitude/Longitude Data</h2>
<div class="columns">
<div class="column">
<p>Here we can see the starting points (black squares) and end points (big colored dots) for each cluster, as well as the final cluster assignment of each data point (color):</p>
<div class="cell">
<div class="cell-output-display">
<p><img data-src="W10_GLM_files/figure-revealjs/unnamed-chunk-21-1.png" width="960"></p>
</div>
</div>
</div><div class="column">
<p>We can see that there is a reasonable overlap between clusters and continents.</p>
<p>We can further investigate this overlap with the <strong>confusion matrix</strong>, which compares membership of each cluster with the actual continents for each country:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>      
labels AF AS EU NA OC SA
     1  5  1 36  0  0  0
     2  3 24  0  0  0  0
     3  0  0  0  0  0  7
     4  0  0  0 15  0  4
     5  0 10  0  0  6  0
     6 35  0  0  0  0  0</code></pre>
</div>
</div>
<p>Note: usually we don’t know the ground truth (i.e.&nbsp;which continent) in unsupervised learning!<br>
=&gt; confusion matrix cannot be estimated</p>
<p>Note 2: Every time we run the iterative process, we will get a different result if we use random starting points. Make sure the result is robust, e.g.&nbsp;by running the Clustering algorithm several times.)</p>
</div>
</div>
<aside class="notes">
<ul>
<li>Cluster 1 contains all European countries, as well as countries from northern Africa and Asia.</li>
</ul>
<!-- -->
<ul>
<li><p>Cluster 2 contains contains Asian countries as well as several African countries.</p></li>
<li><p>Cluster 3 contains countries from the southern part of South America.</p></li>
<li><p>Cluster 4 contains all of the North American countries as well as northern South American countries.</p></li>
<li><p>Cluster 5 contains Oceania as well as several Asian countries</p></li>
<li><p>Cluster 6 contains all of the remaining African countries.</p></li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="hierarchical-clustering" class="slide level2">
<h2>Hierarchical Clustering</h2>
<p><strong>Hierarchical Clustering:</strong> Also uses distances to determine clusters but also visualizes relationships in <em>dendrograms</em>.</p>
<div class="columns">
<div class="column">
<p>The most common procedure is <strong>agglomerative clustering</strong>:</p>
<div>
<ol type="1">
<li class="fragment">Every data point is treated as its own cluster.</li>
<li class="fragment">Two clusters with the least distance (e.g.&nbsp;<em>average linkage</em>) between them are combined.</li>
<li class="fragment">Repeat 1 &amp; 2 until only one cluster is left.</li>
<li class="fragment">Visualize, decide on a cutoff for the amount of reasonable clusters.</li>
</ol>
</div>
</div><div class="column">
<div class="cell">
<div class="cell-output-display">
<p><img data-src="W10_GLM_files/figure-revealjs/unnamed-chunk-23-1.png" width="960"></p>
</div>
</div>
<p>Colored lines: different cutoffs.</p>
</div>
</div>
<div class="fragment">
<p>There seems to be a high degree of similarity within each variable set (SSRT and UPPS) compared to between sets.<br>
=&gt; The first split separates UPPS vs.&nbsp;SSRT perfectly.</p>
<p>Within UPPS, sensation seeking stands out as the most different to the rest.</p>
<aside class="notes">
<p>average linkage: average of all distances between each data point in each of two clusters.</p>
<p>Can read diagram from left to right: One supercluster that is split up more and more. Or right to left: Individual points that get joint together into bigger and bigger clusters.</p>
<p>colored lines: different cutoff values</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section>
<section id="dimensionality-reduction" class="slide level2">
<h2>Dimensionality Reduction</h2>
<p>We often measure different variables that are highly similar to each other, e.g.&nbsp;because they are supposed to measure the same <em>construct</em>.</p>
<p>Although we might measure a particular number of variables (= <em>dimensionality</em> of data set), there may be fewer independent sources of underlying information!</p>
<p><strong>Dimensionality reduction</strong>: Reduce the number of variables by creating composite variables that reflect the underlying information.</p>
</section>
<section id="principal-component-analysis-pca" class="slide level2">
<h2>Principal Component Analysis (PCA)</h2>
<p>Aim: Find a lower-dimensional (linear) description of a set of variables (that still accounts for the maximum possible information/variance in the dataset).</p>
<p>Variance: Combination of signal + noise –&gt; find strongest common signal between variables!</p>
<div class="fragment">
<p><strong>1st Component</strong>: explains most variance between variables, 2nd component: maximum of remaining variance - but uncorrelated with 1st…</p>
</div>
<div class="fragment">
<div class="columns">
<div class="column">
<div class="cell">
<div class="cell-output-display">
<p><img data-src="W10_GLM_files/figure-revealjs/unnamed-chunk-24-1.png" width="384"></p>
</div>
</div>
</div><div class="column">
<p><strong>Green arrow:</strong> 1st component, follows direction of max. variance<br>
<strong>Red arrow</strong>: 2nd component, perpendicular to 1st =&gt; uncorrelated!</p>
<p>We can run a PCA on more than two variables!</p>
</div>
</div>
<aside class="notes">
<p>obtain as many components as there are variables (assuming that there are more observations than there are variables)</p>
<p>in practice: find a small number of components that can explain a large portion of the variance.</p>
<p>1st component: similar to regression line, but minimizes perpendicular distance points to line (not vertical!)</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div>
</section>
<section id="pca-2" class="slide level2">
<h2>PCA 2</h2>
<p>If we calculate a PCA on the impulsivity data, we see that there are two components (in the <em>scree plot</em>) that account for quite some variance.</p>
<p>We can also look at the variable <em>loadings</em>, which show which variable “goes into” which component to better specify what that component represents. Here we can see that one components represents (=captures variance related to) the SSRT variables, the other the UPPS.</p>
<div class="columns">
<div class="column">
<div class="cell">
<div class="cell-output-display">
<p><img data-src="W10_GLM_files/figure-revealjs/unnamed-chunk-25-1.png" width="960"></p>
</div>
</div>
</div><div class="column">
<div class="cell">
<div class="cell-output-display">
<p><img data-src="W10_GLM_files/figure-revealjs/unnamed-chunk-26-1.png" width="960"></p>
</div>
</div>
</div>
</div>
<aside class="notes">
<p>Scree plot: Sometimes used to make decisions on number of components (eigenvalues plotted)</p>
<p>loadings: sign is arbitrary</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="factor-analysis-fa" class="slide level2">
<h2>Factor Analysis (FA)</h2>
<p>PCA is useful for reducing the dimensionality of a dataset.<br>
The components are per definition uncorrelated –&gt; sometimes this is a limitation.<br>
PCA also doesn’t account for measurement error –&gt; possibly difficult to interpret loadings.</p>
<div class="fragment">
<p><strong>Exploratory Factor Analysis</strong>: can also be used for dimensionality reduction.</p>
<p>Idea: Each observed variable is created through a combination of contributions from a <em>latent</em> variable + measurement error. (<em>latent</em>: can’t be directly observed!)</p>
</div>
<div class="fragment">
<p><em>How do different measures relate to underlying factor (that gives rise to these measures)?</em></p>
</div>
</section>
<section id="fa-2" class="slide level2">
<h2>FA 2</h2>
<div class="columns">
<div class="column">
<div class="cell">
<div class="cell-output-display">
<p><img data-src="W10_GLM_files/figure-revealjs/unnamed-chunk-27-1.png" width="384"></p>
</div>
</div>
</div><div class="column">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>
Factor analysis with Call: fa(r = observed_df, nfactors = 3)

Test of the hypothesis that 3 factors are sufficient.
The degrees of freedom for the model is 7  and the objective function was  0.04 
The number of observations was  200  with Chi Square =  7.96  with prob &lt;  0.34 

The root mean square of the residuals (RMSA) is  0.01 
The df corrected root mean square of the residuals is  0.03 

Tucker Lewis Index of factoring reliability =  0.993
RMSEA index =  0.026  and the 10 % confidence intervals are  0 0.094
BIC =  -29.13</code></pre>
</div>
<div class="cell-output-display">
<p><img data-src="W10_GLM_files/figure-revealjs/unnamed-chunk-28-1.png" width="960"></p>
</div>
</div>
</div>
</div>
<p><strong>RMSEA</strong> (root mean square error of approximation): Measure of model fit, should be &lt; .08.</p>
<p>Use (lowest) <strong>SABIC</strong> (sample-size adjusted Bayesian information criterion) to compare models with different number of factors.</p>
<aside class="notes">
<p>We can “hand over” <strong>3 factors</strong></p>
<p><strong>RMSEA</strong> quantifies how far predicted covariances (between data) are from actual covariances</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section id="thanks" class="title-slide slide level1 center">
<h1>Thanks!</h1>
<p>Learning objectives:</p>
<ul>
<li>Describe the concept of the <em>general linear model/linear regression</em> and apply it to a dataset</li>
<li>Understand <em>clustering</em> and <em>dimensionality reduction,</em> incl.&nbsp;the difference between k-means and hierarchical clustering as well as PCA and FA</li>
</ul>
<p>Next:</p>
<ul>
<li>R Session on the General Linear Model</li>
<li>Linear Mixed Models</li>
</ul>

<div class="footer footer-default">

</div>
</section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="site_libs/revealjs/plugin/search/search.js"></script>
  <script src="site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'smaller': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': true,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        text: function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>