[
  {
    "objectID": "W9_FirstAnalysisR.html#set-up",
    "href": "W9_FirstAnalysisR.html#set-up",
    "title": "09 Statistical Analyses in R",
    "section": "Set Up",
    "text": "Set Up\n\nOpen RStudio and load your Biostats R project. Create a new script called DataAnalysis1.R.\nInstall and load new packages you’ll need:\n\n\nlibrary(car)\nlibrary(apa)\nlibrary(effectsize)\nlibrary(confintr)\nlibrary(afex)\nlibrary(performance)\nlibrary(emmeans)\nlibrary(pwr)\nlibrary(lsr)\nlibrary(report)\nlibrary(tidyverse)",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#one-sample-chi²-test",
    "href": "W9_FirstAnalysisR.html#one-sample-chi²-test",
    "title": "09 Statistical Analyses in R",
    "section": "One Sample Chi²-Test",
    "text": "One Sample Chi²-Test\n\nlibrary(tidyverse) \n\n# Input data into R\nlever_presses &lt;- tibble(levers=c(rep(\"blue\", 5), rep(\"green\", 4), rep(\"red\", 11))) %&gt;% #data in usual format\n  count(levers) #convert to a frequency table (most useful for tables)\nlever_presses_wide &lt;- lever_presses %&gt;% \n  pivot_wider(names_from=\"levers\", values_from=\"n\") #wide format (needed for chisq.test function)\n\n# run Chi² test\nchi2_lever &lt;- chisq.test(lever_presses_wide) \n#chi2_lever &lt;- chisq.test(tibble(blue=5, green=4, red=11)) #enter data directly as summary table\n\nchi2_lever %&gt;% apa::chisq_apa() #output results\n\nchi^2(2) = 4.30, p = .116",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#one-sample-chi²-test-expected-values-residuals",
    "href": "W9_FirstAnalysisR.html#one-sample-chi²-test-expected-values-residuals",
    "title": "09 Statistical Analyses in R",
    "section": "One Sample Chi²-Test: Expected Values & Residuals",
    "text": "One Sample Chi²-Test: Expected Values & Residuals\n\n# add expected count and residuals to data\nlever_presses %&gt;% mutate(expected = chi2_lever$expected, \n                         diff = n - expected,\n                         residuals = chi2_lever$residuals)\n\n# A tibble: 3 × 5\n  levers     n expected  diff residuals\n  &lt;chr&gt;  &lt;int&gt;    &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1 blue       5     6.67 -1.67    -0.645\n2 green      4     6.67 -2.67    -1.03 \n3 red       11     6.67  4.33     1.68 \n\n\n\nIs sample size not important for significance here? \\[\\chi^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\] More observations =&gt; easier to see greater absolute difference between observed and expected values =&gt; gets squared and therefore “outcompetes” denominator (what about expected reductions in sampling error?)",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#chi²-test-2",
    "href": "W9_FirstAnalysisR.html#chi²-test-2",
    "title": "09 Statistical Analyses in R",
    "section": "Chi²-Test 2",
    "text": "Chi²-Test 2\nWe can also run a Chi²-test for two variables, such as if we want to know whether the lever press distributions differ between two (or more) groups.\nLet’s say we have a treatment and a control group and we record the different lever presses:\n\n\n\nGroup\nBlue\nGreen\nRed\nTotals\n\n\n\n\nTreatment\n3\n12\n5\n20\n\n\nControl\n5\n4\n11\n20\n\n\nTotals\n8\n16\n16\n40\n\n\n\nRemember: We use the assumption of independence to calculate the expected values.\n\n\nlever_presses2 = tibble(group=\"treatment\", blue=3, green=12, red=5) %&gt;% \n  bind_rows(tibble(group=\"control\", blue=5, green=4, red=11)) #clearest way to manually input data\n#for long data, you create the frequency table identically to previous slide but with: count(group, levers)\n\nchisq.test(lever_presses2 %&gt;% column_to_rownames(\"group\")) %&gt;% apa::chisq_apa()\n\nchi^2(2) = 6.75, p = .034",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#assumptions-of-chi²-tests",
    "href": "W9_FirstAnalysisR.html#assumptions-of-chi²-tests",
    "title": "09 Statistical Analyses in R",
    "section": "Assumptions of Chi²-Tests",
    "text": "Assumptions of Chi²-Tests\n\nRandom sample\nCategorical variables, i.e., counts within (combinations of) groups\nExpected cell count: &gt;5 counts per cell\nIndependence: Each observation is independent of the others, e.g. there are no repeated measurements/paired data (within-subjects data are correlated!)\n\n\nIn the case of the last analysis, we got a warning because the expected cell sizes were too small. In this case, it is better to use Fisher’s exact test:\n\nfisher.test(lever_presses2 %&gt;% column_to_rownames(\"group\"))\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  lever_presses2 %&gt;% column_to_rownames(\"group\")\np-value = 0.04168\nalternative hypothesis: two.sided",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#t-test-setup",
    "href": "W9_FirstAnalysisR.html#t-test-setup",
    "title": "09 Statistical Analyses in R",
    "section": "t-test setup",
    "text": "t-test setup\nTo run a t-Test, let’s first simulate data. What happens here?\n\nset.seed(31415)\nsim_data_t &lt;- tibble(\n  group = rep(c(\"treatment\", \"control\"), each=20),\n  reaction_times = c(rnorm(20, 400, 100), rnorm(20, 450, 100))) #poorly documented code for practice",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#t-test-formula-notation",
    "href": "W9_FirstAnalysisR.html#t-test-formula-notation",
    "title": "09 Statistical Analyses in R",
    "section": "t-Test: Formula Notation",
    "text": "t-Test: Formula Notation\nWe can use the formula notation to run the t-test. This notation usually looks like this:\ndependent variable ~ independent variable.\nReplace the NULLs:\n\nt.test(NULL ~ NULL,\n       data = NULL,\n       alternative = NULL,\n       paired = NULL)",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#t-test-formula-notation-1",
    "href": "W9_FirstAnalysisR.html#t-test-formula-notation-1",
    "title": "09 Statistical Analyses in R",
    "section": "t-Test: Formula Notation",
    "text": "t-Test: Formula Notation\nWe can use the formula notation to run the t-test. This notation usually looks like this:\ndependent variable ~ independent variable.\nReplace the NULLs:\n\nt.test(reaction_times ~ group,\n       data = sim_data_t,\n       alternative = \"greater\", #depends on ALPHABETICAL order of groups in data! (if not coded as factor)\n       #paired = FALSE # this is the default, so no need to specify it\n)\n\n\n    Welch Two Sample t-test\n\ndata:  reaction_times by group\nt = 1.9841, df = 34.42, p-value = 0.02763\nalternative hypothesis: true difference in means between group control and group treatment is greater than 0\n95 percent confidence interval:\n 10.02639      Inf\nsample estimates:\n  mean in group control mean in group treatment \n               468.0592                400.3289",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#t-test-formula-notation-2",
    "href": "W9_FirstAnalysisR.html#t-test-formula-notation-2",
    "title": "09 Statistical Analyses in R",
    "section": "t-Test: Formula Notation",
    "text": "t-Test: Formula Notation\n\nt.test(reaction_times ~ group,\n       data = sim_data_t,\n       alternative = \"greater\", #depends on ALPHABETICAL order of groups in data! (if not coded as factor)\n       #paired = FALSE # this is the default, so no need to specify it\n)\n\n\n    Welch Two Sample t-test\n\ndata:  reaction_times by group\nt = 1.9841, df = 34.42, p-value = 0.02763\nalternative hypothesis: true difference in means between group control and group treatment is greater than 0\n95 percent confidence interval:\n 10.02639      Inf\nsample estimates:\n  mean in group control mean in group treatment \n               468.0592                400.3289 \n\n\nAs you can see in the output, R automatically chose to run Welch’s t-test, which does not assume homogeneity of variance in contrast to Student’s t-test. For the latter, you can add the function parameter var.equal = TRUE\n\nWhen changing the name “treatment” to “a”, the results change:\n\nt.test(reaction_times ~ group,\n       data = sim_data_t %&gt;% mutate(group = ifelse(group==\"treatment\", \"a\", group)),\n       alternative = \"greater\", #depends on order of groups in data! 1st group &gt; 2nd group\n       var.equal = TRUE) %&gt;% apa::t_apa()\n\nt(38) = -1.98, p = .973, d = -0.63",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#t-test-with-filter",
    "href": "W9_FirstAnalysisR.html#t-test-with-filter",
    "title": "09 Statistical Analyses in R",
    "section": "t-Test with filter",
    "text": "t-Test with filter\nYou can also supply two vectors of numerical values for the groups:\n\nt.test(x = sim_data_t %&gt;% filter(group==\"treatment\") %&gt;% pull(reaction_times),\n       y = sim_data_t %&gt;% filter(group==\"control\") %&gt;% pull(reaction_times),\n       alternative = \"less\") #more intuitive now because you can filter for treatment first\n\n\n    Welch Two Sample t-test\n\ndata:  sim_data_t %&gt;% filter(group == \"treatment\") %&gt;% pull(reaction_times) and sim_data_t %&gt;% filter(group == \"control\") %&gt;% pull(reaction_times)\nt = -1.9841, df = 34.42, p-value = 0.02763\nalternative hypothesis: true difference in means is less than 0\n95 percent confidence interval:\n      -Inf -10.02639\nsample estimates:\nmean of x mean of y \n 400.3289  468.0592 \n\n\nThis makes it easier to think about the direction of the alternative hypothesis because you choose which group is considered first.",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#t-test-apa-package",
    "href": "W9_FirstAnalysisR.html#t-test-apa-package",
    "title": "09 Statistical Analyses in R",
    "section": "t-Test: apa package",
    "text": "t-Test: apa package\nMore useful output with apa package (only for Student’s t-tests):\n\nt.test(x = sim_data_t %&gt;% filter(group==\"treatment\") %&gt;% pull(reaction_times),\n       y = sim_data_t %&gt;% filter(group==\"control\") %&gt;% pull(reaction_times),\n       alternative = \"less\", \n       var.equal = TRUE) %&gt;% \n  apa::t_apa(es_ci = TRUE) #optional: confidence interval around effect size\n\nt(38) = -1.98, p = .027, d = -0.63 [-1.26; 0.01]",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#t-test-paired-samples",
    "href": "W9_FirstAnalysisR.html#t-test-paired-samples",
    "title": "09 Statistical Analyses in R",
    "section": "t-Test: paired samples",
    "text": "t-Test: paired samples\nFor paired t-tests, you have to work with the wide format of data (advantage: missing values become explicit):\n\nsim_data_t_wide = sim_data_t %&gt;% mutate(subject=rep.int(1:(n()/2), 2)) %&gt;% \n  pivot_wider(names_from=\"group\", values_from=\"reaction_times\", id_cols = subject)\nt.test(x = sim_data_t_wide %&gt;% pull(treatment),\n       y = sim_data_t_wide %&gt;% pull(control),\n       alternative = \"less\", \n       paired = TRUE) %&gt;% \n  apa::t_apa(es_ci = TRUE) #optional: confidence interval around effect size\n\nt(19) = -1.98, p = .031, d = -0.44 [-0.90; 0.02]\n\n\nYou can also use the wide format for the independent samples t-test (instead of formula notation or filtering). You choose 😊.",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#assumptions-of-t-tests",
    "href": "W9_FirstAnalysisR.html#assumptions-of-t-tests",
    "title": "09 Statistical Analyses in R",
    "section": "Assumptions of t-Tests",
    "text": "Assumptions of t-Tests\nBefore we run a t-test, we also want to check the assumptions for violations:\n\nThe dependent variable is continuous (otherwise: chi²-test)\nThe data are independent (otherwise: paired sample t-test)\nThe variance between the groups is homogeneous (only for Student’s t-test, R uses Welch’s test by default)\nThe residuals are normally distributed for each group (otherwise: wilcox.test)\n\n\nOftentimes, the last assumption is misquoted as: “The dependent variable needs to be normally distributed”.\nIn fact, only its sampling distribution needs to be (blue vs. grey distribution in the lecture on sampling [direct link]), which will always be the case for big enough samples due to the central limit theorem.",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#assumptions-of-t-tests-normality",
    "href": "W9_FirstAnalysisR.html#assumptions-of-t-tests-normality",
    "title": "09 Statistical Analyses in R",
    "section": "Assumptions of t-Tests: Normality",
    "text": "Assumptions of t-Tests: Normality\nTest for normality of residuals (for both groups separately): If points fall along the line nicely, assumption is met.\nTreatment group:\n\n\ntreatment &lt;- sim_data_t %&gt;%\n  filter(group == \"treatment\") %&gt;%\n  mutate(group_resid = \n           reaction_times - mean(reaction_times)) %&gt;%\n  pull(group_resid)\n\n#base R QQ plot\nqqnorm(treatment)\nqqline(treatment)",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#assumptions-of-t-tests-normality-1",
    "href": "W9_FirstAnalysisR.html#assumptions-of-t-tests-normality-1",
    "title": "09 Statistical Analyses in R",
    "section": "Assumptions of t-Tests: Normality",
    "text": "Assumptions of t-Tests: Normality\nTest for normality of residuals (for both groups separately): If points fall along the line nicely, assumption is met.\nControl group group:\n\n\ncontrol &lt;- sim_data_t %&gt;%\n  filter(group == \"control\") %&gt;%\n  mutate(group_resid = \n           reaction_times - mean(reaction_times)) %&gt;%\n  pull(group_resid)\n\n#car's version highlighting (and returning) problematic values\ncar::qqPlot(control)\n\n\n\n\n\n\n\n\n\n[1] 18  4",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#assumptions-of-t-tests-normality-2",
    "href": "W9_FirstAnalysisR.html#assumptions-of-t-tests-normality-2",
    "title": "09 Statistical Analyses in R",
    "section": "Assumptions of t-Tests: Normality",
    "text": "Assumptions of t-Tests: Normality\nAlternatively, we can also run a Shapiro-Wilk test to check for deviations from normality:\n\nshapiro.test(x = treatment)\n\n\n    Shapiro-Wilk normality test\n\ndata:  treatment\nW = 0.91403, p-value = 0.0761\n\nshapiro.test(x = control)\n\n\n    Shapiro-Wilk normality test\n\ndata:  control\nW = 0.96812, p-value = 0.7147\n\n\nIf the test is non-significant, then we can conclude that normality of residuals is not violated.\n⇒ Shapiro-Wilk tests for significant deviations from normality.\n\n\nTransform your data to try and normalise the distribution. Not usually recommended these days but some still use it.\nUse a non-parametric test. The non-parametric equivalent of the independent t-test is the Mann-Whitney and the equivalent of the paired-samples t-test is the Wilcoxon signed-ranks test. Though more modern permutation tests are better.\nDo nothing. Delacre, Lakens & Leys, 2017 argue that with a large enough sample (&gt;30), the Welch test is robust to deviations from assumptions. With very large samples normality is even less of an issue, so design studies with large samples.",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#mehr-song-spelke-2016",
    "href": "W9_FirstAnalysisR.html#mehr-song-spelke-2016",
    "title": "09 Statistical Analyses in R",
    "section": "Mehr, Song, & Spelke (2016)",
    "text": "Mehr, Song, & Spelke (2016)\nIn this dataset, the authors examined whether infants exposed to certain songs would recognize strangers singing these lullabies as part of their social group. Parents sang certain lullabies to their infants for 1-2 weeks. During the experiment, the infants looked at videos of two strangers: First the strangers were just smiling (baseline phase), then they would sing either the familiar or an unfamiliar lullaby. Finally, the infants again saw the videos of the strangers smiling (test phase). Eye-tracking (duration looked at each stranger) was measured.\n\nLoad the file into your Environment. Run the code and explain what happens:\n\ngaze &lt;- read_csv(\"Mehr Song and Spelke 2016 Experiment 1.csv\") %&gt;%\n  filter(exp1 == 1) %&gt;%\n  rename(baseline = Baseline_Proportion_Gaze_to_Singer,\n         test = Test_Proportion_Gaze_to_Singer) %&gt;% \n  select(id, baseline, test)",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#assumptions-of-the-paired-samples-t-test",
    "href": "W9_FirstAnalysisR.html#assumptions-of-the-paired-samples-t-test",
    "title": "09 Statistical Analyses in R",
    "section": "Assumptions of the Paired-Samples t-Test",
    "text": "Assumptions of the Paired-Samples t-Test\n\nThe data are continuous.\nAll participants should appear in both conditions/groups.\nThe residuals are normally distributed.\n\n\nA paired-samples t-test actually tests whether the difference between two measurements is significantly different from 0 (= no difference/effect).\nIn our example data, this means that the test values are subtracted from the baseline values, and this difference is used as data.\nTo test the assumption that residuals are normally distributed, we thus calculate the residuals as follow:\n\ngaze_residual &lt;- gaze %&gt;%\n  mutate(diff = baseline - test) %&gt;%\n  mutate(group_resid = diff - mean(diff))",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#assumptions-of-the-paired-samples-t-test-1",
    "href": "W9_FirstAnalysisR.html#assumptions-of-the-paired-samples-t-test-1",
    "title": "09 Statistical Analyses in R",
    "section": "Assumptions of the Paired-Samples t-Test",
    "text": "Assumptions of the Paired-Samples t-Test\n\n\n\n[1] 22 29\n\n\n\n    Shapiro-Wilk normality test\n\ndata:  gaze_residual$group_resid\nW = 0.97818, p-value = 0.7451",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#descriptives-visualization",
    "href": "W9_FirstAnalysisR.html#descriptives-visualization",
    "title": "09 Statistical Analyses in R",
    "section": "Descriptives & Visualization",
    "text": "Descriptives & Visualization\nFor the visualization, we need the data in long format (this is identical for between-subject groups):\n\n\ngaze_tidy &lt;- gaze %&gt;%\n  pivot_longer(names_to = \"phase\", \n               values_to = \"looking_time\", \n               cols = c(baseline, test))\n\n# boxplot\ngaze_tidy %&gt;% \n  ggplot(aes(x=phase, y=looking_time)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nWe can also calculate the means and SDs per phase:\n\n\ngaze_tidy %&gt;% \n  summarize(.by = phase,\n            mean_looking = mean(looking_time),\n            sd_looking = sd(looking_time),\n            n = n())\n\n\n# A tibble: 2 × 4\n  phase    mean_looking sd_looking     n\n  &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt;\n1 baseline        0.521      0.177    32\n2 test            0.593      0.179    32",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#paired-samples-t-test-in-r",
    "href": "W9_FirstAnalysisR.html#paired-samples-t-test-in-r",
    "title": "09 Statistical Analyses in R",
    "section": "Paired Samples t-Test in R",
    "text": "Paired Samples t-Test in R\nAny ideas how you would specify the paired samples t-test in R?\n\nwith(gaze, t.test(x = NULL, y = NULL,\n                  paired = NULL,\n                  alternative = NULL))\n\n\n\nwith(gaze, t.test(x = baseline, y = test,\n                  paired = TRUE,\n                  alternative = \"two.sided\"))\n\n\n    Paired t-test\n\ndata:  baseline and test\nt = -2.4164, df = 31, p-value = 0.02175\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.13349698 -0.01129217\nsample estimates:\nmean difference \n    -0.07239458",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#effect-size-for-the-t-test",
    "href": "W9_FirstAnalysisR.html#effect-size-for-the-t-test",
    "title": "09 Statistical Analyses in R",
    "section": "Effect Size for the t-Test",
    "text": "Effect Size for the t-Test\nYou can (and should!) of course calculate and report effect sizes for your test statistics to get an impression of how practically relevant the effect is.\nFor the t-tests, you would calculate Cohen’s d (e.g., using the effectsize package):\n\nwith(gaze, effectsize::cohens_d(baseline, test, paired = TRUE))\n\nCohen's d |         95% CI\n--------------------------\n-0.43     | [-0.79, -0.06]\n\n\n\n\nOr just use the apa package and you get everything in one go:\n\nwith(gaze, #the with function allows to call columns as if they were variables (but pipe function doesn't work with it)\n     t.test(baseline, test, paired = TRUE)) %&gt;% \n  apa::t_apa(es_ci = TRUE)\n\nt(31) = -2.42, p = .022, d = -0.43 [-0.79; -0.06]",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#summary-optional-activity",
    "href": "W9_FirstAnalysisR.html#summary-optional-activity",
    "title": "09 Statistical Analyses in R",
    "section": "Summary: Optional Activity",
    "text": "Summary: Optional Activity\n\nMost things are similar between independent and dependent sample t-tests\nMake sure to include paired = TRUE for repeated measures to get correct results\nRecommendation: Use apa::t_apa() with es.ci = TRUE to get (most of) the information you need\nIt is often a good idea to also report means and standard deviations per group\n(summarize with .by argument)\nPlotting: Unfortunately, (between subjects) confidence intervals are not diagnostic for the significance of dependent samples. Instead, we need the confidence interval around the paired differences (i.e., the within subject changes).",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#kinds-of-error-variance-in-paired-samples",
    "href": "W9_FirstAnalysisR.html#kinds-of-error-variance-in-paired-samples",
    "title": "09 Statistical Analyses in R",
    "section": "Kinds of Error Variance in paired samples",
    "text": "Kinds of Error Variance in paired samples\n\nUse Notes Canvas (paint brush icon on bottom left) to draw worst possibility of paired differences in “Raw Data” and resulting increase in within-subjects error variance while between-subjects variance remains fixed.\n\n\n\nPfister & Janczyk (2013), Fig. 1",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#correlation-test",
    "href": "W9_FirstAnalysisR.html#correlation-test",
    "title": "09 Statistical Analyses in R",
    "section": "Correlation Test",
    "text": "Correlation Test\nWe might be interested in whether there is a relationship between the two measures of gaze, i.e., whether those children who looked at the stranger more at baseline would also look more at the follow-up test (here: indicating stability of preferences).\n\nSimilar to the paired t-Test, the continuous variables are also “paired” within subjects. Thus, we can use a similar syntax to the previous optional activity of the paired t-test:\n\ncor.test(x = gaze %&gt;% pull(baseline), \n         y = gaze %&gt;% pull(test), \n         method = \"pearson\", #default\n         alternative = \"two.sided\") %&gt;% #default\n  apa::cor_apa(r_ci = TRUE)\n\nr(30) = .55 [.24; .75], p = .001\n\n\nNote: We don’t have to indicate paired = TRUE because correlations only work for paired values.\n\nWe mainly use this dataset so that you don’t have to load another one, but in practice you would either run a t-test or a correlation, not necessarily both!\nThe t-tests answers whether there is a change across all participants between the two time points, the correlation answers the question whether those who score high at one time point would also score high at the next (regardless of overall level).",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#correlations-write-up",
    "href": "W9_FirstAnalysisR.html#correlations-write-up",
    "title": "09 Statistical Analyses in R",
    "section": "Correlations: Write Up",
    "text": "Correlations: Write Up\nYou can even use report() to get an automatic suggestion of how to report the results (works with a lot of different models!).\n\n# library(report)\n# with(gaze, cor.test(x = baseline, \n#                     y = test, \n#                     method = \"pearson\", \n#                     alternative = \"two.sided\")) %&gt;% \n#   report()\n\n\nWho wants to write a package that inputs data & analysis results into ChatGPT? :D",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#correlations-notes",
    "href": "W9_FirstAnalysisR.html#correlations-notes",
    "title": "09 Statistical Analyses in R",
    "section": "Correlations: Notes",
    "text": "Correlations: Notes\nThere are also some assumptions that need to be checked:\n\nAre the data continuous? (for ordinal values: Spearman’s rho)\nIs there a data point for each participant on both variables? (paired values)\nAre the residuals normally distributed?\nDoes the relationship between variables appear linear?\nDoes the spread have homoscedasticity? (Variance of residuals should be constant across x-axis)\nNote: This is very hard to judge by eye and is not the same as the confidence band around the regression line to show constant width. In fact, the latter will always be larger near the ends of the regression line due to how it is computed.\n\nPlease see the text book for how to test these assumptions.\nYou should - as always - also report the descriptive statistics (such as mean and SD of both variables).\nYou can also report and visualize multiple correlations at once, using a scatterplot matrix or heatmaps. Check out e.g. the corrplot package!",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#one-way-anova",
    "href": "W9_FirstAnalysisR.html#one-way-anova",
    "title": "09 Statistical Analyses in R",
    "section": "One-Way ANOVA",
    "text": "One-Way ANOVA\nFor this activity, we will use data from a study about memory of traumatic events (see the textbook for details). In short, the authors of the paper were interested to find out whether:\n\nreconsolidation - the process during which memories become malleable when recalled - can be blocked using a cognitive task and whether such an approach can reduce these unbidden intrusions.\n\n\nDownload the data James Holmes_Expt 2_DATA.csv. This time, put it in a subfolder of your project called “Data”.\nAdd a column to the dataframe called subject that equals the row_number(), which will act as a participant ID.\nrename(): Days_One_to_Seven_Image_Based_Intrusions_in_Intrusion_Diary to intrusions.\nSelect only the columns subject, Condition and intrusions.\nChange the variable Condition from numeric to a factor using as.factor()",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#one-way-anova-1",
    "href": "W9_FirstAnalysisR.html#one-way-anova-1",
    "title": "09 Statistical Analyses in R",
    "section": "One-Way ANOVA",
    "text": "One-Way ANOVA\n\nDownload the data James Holmes_Expt 2_DATA.csv. This time, put it in a subfolder of your project called “Data”.\nAdd a column to the dataframe called subject that equals the row_number(), which will act as a participant ID.\nrename(): Days_One_to_Seven_Image_Based_Intrusions_in_Intrusion_Diary to intrusions.\nSelect only the columns subject, Condition and intrusions.\nChange the variable Condition from numeric to a factor using as.factor()\n\n\nlibrary(tidyverse)\n\ndat &lt;- read_csv(\"Data/James Holmes_Expt 2_DATA.csv\") %&gt;% \n  rownames_to_column(\"subject\") %&gt;% #mutate(subject = 1:n()) %&gt;% \n  rename(intrusions = Days_One_to_Seven_Image_Based_Intrusions_in_Intrusion_Diary) %&gt;% \n  select(subject, Condition, intrusions) %&gt;% \n  mutate(Condition = as.factor(Condition))\n\n\nwe will today only look at one-way anovas! Next week we will cover the case when we have more than one IV/predictor!",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#one-way-anova-2",
    "href": "W9_FirstAnalysisR.html#one-way-anova-2",
    "title": "09 Statistical Analyses in R",
    "section": "One-Way ANOVA",
    "text": "One-Way ANOVA\nCreate summary/descriptive statistics and visualize the data.\nAs summary statistics, we want the mean, SD, and SE.\n\nsum_dat &lt;- dat %&gt;%\n  summarize(mean = mean(intrusions),\n            sd = sd(intrusions),\n            se = confintr::se_mean(intrusions), #no native R function :(\n            .by = Condition)\nprint(sum_dat)\n\n# A tibble: 4 × 4\n  Condition  mean    sd    se\n  &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 1          5.11  4.23 0.996\n2 2          1.89  1.75 0.411\n3 3          3.89  2.89 0.681\n4 4          4.83  3.33 0.785\n\n\nNote: The names of the factor levels are missing. If we wanted to plot the data, we should have added them in the previous step. For brevity, we will not do it this time.",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#one-way-anova-3",
    "href": "W9_FirstAnalysisR.html#one-way-anova-3",
    "title": "09 Statistical Analyses in R",
    "section": "One-Way ANOVA",
    "text": "One-Way ANOVA\n\nRun the ANOVA using lm() and formula notation.\n\n\nmod1 &lt;- lm(intrusions ~ Condition, data = dat)\nanova(mod1)\n\nAnalysis of Variance Table\n\nResponse: intrusions\n          Df Sum Sq Mean Sq F value  Pr(&gt;F)  \nCondition  3 114.82  38.273  3.7948 0.01409 *\nResiduals 68 685.83  10.086                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nUsing afex::aov_ez:\n\n\nlibrary(afex)\nmod &lt;- aov_ez(id = \"subject\", # the column containing the subject IDs\n              dv = \"intrusions\", # the DV \n              between = \"Condition\", # the between-subject variable\n              es = \"pes\", # can output an effect size! we want partial eta-squared\n              type = 3, # there are both reasons for 2 and 3 (not covered here)\n              include_aov = TRUE, # needed for some calculations with emmeans but takes longer\n              data = dat)\nanova(mod)\n\nAnova Table (Type 3 tests)\n\nResponse: intrusions\n          num Df den Df    MSE      F     ges  Pr(&gt;F)  \nCondition      3     68 10.086 3.7948 0.14341 0.01409 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#checking-the-assumptions",
    "href": "W9_FirstAnalysisR.html#checking-the-assumptions",
    "title": "09 Statistical Analyses in R",
    "section": "Checking the Assumptions",
    "text": "Checking the Assumptions\n\nlibrary(performance)\n\ncheck_model(mod1) # doesn't work for ezANOVA output!",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#checking-the-assumptions-1",
    "href": "W9_FirstAnalysisR.html#checking-the-assumptions-1",
    "title": "09 Statistical Analyses in R",
    "section": "Checking the Assumptions",
    "text": "Checking the Assumptions\n\n# \"manually\" check normality of residuals \n\nqqPlot(mod$aov$residuals)\n\n\n[1]  3 57\n\nshapiro.test(mod$aov$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mod$aov$residuals\nW = 0.87739, p-value = 4.252e-06",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#checking-the-assumptions-2",
    "href": "W9_FirstAnalysisR.html#checking-the-assumptions-2",
    "title": "09 Statistical Analyses in R",
    "section": "Checking the Assumptions",
    "text": "Checking the Assumptions\n\n# check homogeneity of variance\ntest_levene(mod)\n\nWarning: Variances differ between groups (Levene's Test, p = 0.039).\n\n\nBoth assumptions are not met!\nBut ANOVAS are quite robust to (minor) deviations…\nIf the assumptions are violated more, you could…\n- run a non-parametric test (Kruskall-Wallis for between-subjects designs or Friedman for repeated measures)\n- transform the data (see Field et al., 2009)\n- use bootstrapping (see Field et al., 2009)",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#post-hoc-tests",
    "href": "W9_FirstAnalysisR.html#post-hoc-tests",
    "title": "09 Statistical Analyses in R",
    "section": "Post-Hoc Tests",
    "text": "Post-Hoc Tests\nSo now we know that there are differences between the Conditions, but we don’t know yet which groups differ from each other. We could thus calculate pairwise comparisons or post-hoc t-tests to compare each condition to the others by filtering the data (so that only two conditions remain) and running t-tests.\nA more convenient way is to use the emmeans() function from the package with the same name. We can also adjust the tests for multiple comparisons directly.\nWe could also define specific contrasts to test a priori (i.e., based on hypotheses). But we will skip this here.",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#post-hoc-tests-1",
    "href": "W9_FirstAnalysisR.html#post-hoc-tests-1",
    "title": "09 Statistical Analyses in R",
    "section": "Post-Hoc Tests",
    "text": "Post-Hoc Tests\n\nlibrary(emmeans)\nmod %&gt;% emmeans(pairwise ~ Condition, adjust = \"bonferroni\") # also works with mod1!\n\n$emmeans\n Condition emmean    SE df lower.CL upper.CL\n 1           5.11 0.749 68    3.617     6.60\n 2           1.89 0.749 68    0.395     3.38\n 3           3.89 0.749 68    2.395     5.38\n 4           4.83 0.749 68    3.340     6.33\n\nConfidence level used: 0.95 \n\n$contrasts\n contrast                estimate   SE df t.ratio p.value\n Condition1 - Condition2    3.222 1.06 68   3.044  0.0199\n Condition1 - Condition3    1.222 1.06 68   1.155  1.0000\n Condition1 - Condition4    0.278 1.06 68   0.262  1.0000\n Condition2 - Condition3   -2.000 1.06 68  -1.889  0.3787\n Condition2 - Condition4   -2.944 1.06 68  -2.781  0.0420\n Condition3 - Condition4   -0.944 1.06 68  -0.892  1.0000\n\nP value adjustment: bonferroni method for 6 tests \n\n\n\nShould we adjust for multiple comparisons? It depends. There are good reasons for either.",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#anova-effect-sizes",
    "href": "W9_FirstAnalysisR.html#anova-effect-sizes",
    "title": "09 Statistical Analyses in R",
    "section": "ANOVA: Effect Sizes",
    "text": "ANOVA: Effect Sizes\nThe most common effect size estimate for an ANOVA is partial eta squared \\(\\eta_p^2\\) (as we calculated with afex::aov_ez before). We get one per factor and it summarizes all pairwise effects within it.\n\nWe could also calculate Cohen’s d for each pairwise comparison within the factor but this is tedious and gets confusing quickly (1 factor with 5 levels = 10 effects; 3 factors with 5 levels each = 30 effects). It’s still sad that emmeans doesn’t output it as one additional column.",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#anova-power",
    "href": "W9_FirstAnalysisR.html#anova-power",
    "title": "09 Statistical Analyses in R",
    "section": "ANOVA: Power",
    "text": "ANOVA: Power\nEffect sizes are important to calculate the statistical power of your study before conducting it. Use an estimated effect size based on prior research:\n\nlibrary(pwr)\npwr.anova.test(k = 4, f = .4, sig.level = .05, power = .8) #we leave out the n parameter to let it be calculated\n\n\n     Balanced one-way analysis of variance power calculation \n\n              k = 4\n              n = 18.04262\n              f = 0.4\n      sig.level = 0.05\n          power = 0.8\n\nNOTE: n is number in each group\n\n\nNote: f is “Cohen’s f”. You can convert your \\(\\eta_p^2\\) to (partial) f using effectsize package:\n\neffectsize::eta2_to_f(.15)\n\n[1] 0.420084",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#write-up",
    "href": "W9_FirstAnalysisR.html#write-up",
    "title": "09 Statistical Analyses in R",
    "section": "Write Up",
    "text": "Write Up\nOnce again, the apa package helps us here - if we used afex::aov_ez instead of lm 😅:\n\nmod %&gt;% apa::anova_apa()\n\n       Effect                                              \n1 (Intercept) F(1, 68) = 110.29, p &lt; .001, petasq = .62 ***\n2   Condition F(3, 68) =   3.79, p = .014, petasq = .14 *  \n\n\n\n\nmod %&gt;% emmeans(\"Condition\") %&gt;% pairs(adjust=\"none\") #follow up t-tests without adjustment\n\n contrast                estimate   SE df t.ratio p.value\n Condition1 - Condition2    3.222 1.06 68   3.044  0.0033\n Condition1 - Condition3    1.222 1.06 68   1.155  0.2523\n Condition1 - Condition4    0.278 1.06 68   0.262  0.7938\n Condition2 - Condition3   -2.000 1.06 68  -1.889  0.0631\n Condition2 - Condition4   -2.944 1.06 68  -2.781  0.0070\n Condition3 - Condition4   -0.944 1.06 68  -0.892  0.3755\n\n\nLooking at contrasts including condition 1 (control group): Only condition 2 different.\nLet’s get the associated effect size of this specific contrast:\n\n\n\nlibrary(lsr)\ncohensD(intrusions ~ Condition, \n        data = filter(dat, Condition %in% c(1,2)) %&gt;% droplevels())\n\n[1] 0.9964172",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#write-up-1",
    "href": "W9_FirstAnalysisR.html#write-up-1",
    "title": "09 Statistical Analyses in R",
    "section": "Write Up",
    "text": "Write Up\n\n\n       Effect                                              \n1 (Intercept) F(1, 68) = 110.29, p &lt; .001, petasq = .62 ***\n2   Condition F(3, 68) =   3.79, p = .014, petasq = .14 *  \n\n\n contrast                estimate   SE df t.ratio p.value\n Condition1 - Condition2    3.222 1.06 68   3.044  0.0033\n Condition1 - Condition3    1.222 1.06 68   1.155  0.2523\n Condition1 - Condition4    0.278 1.06 68   0.262  0.7938\n Condition2 - Condition3   -2.000 1.06 68  -1.889  0.0631\n Condition2 - Condition4   -2.944 1.06 68  -2.781  0.0070\n Condition3 - Condition4   -0.944 1.06 68  -0.892  0.3755\n\n\n[1] 0.9964172\n\n\n\nThere was a significant difference between groups in overall intrusion frequency in daily life, \\(F(3, 68) = 3.79, p = 0.014, \\eta_p^2 = .14\\). Pairwise comparisons demonstrated that relative to the no-task control group, only those in the reactivation-plus-Tetris group, \\(t(68) = 3.04, p &lt; 0.01, d = 1.00\\), experienced significantly fewer intrusive memories…",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#null-hypothesis-significance-testing",
    "href": "W7_Hypothesis.html#null-hypothesis-significance-testing",
    "title": "07 Hypothesis Testing",
    "section": "Null Hypothesis Significance Testing",
    "text": "Null Hypothesis Significance Testing\nExample: We have two groups (treatment and control). We also have a hypothesis: The treatment group has lower scores on measure X (e.g., symptoms). We have the data (X for both groups), now what?\n\nWe take the hypothesis (treatment = lower X than control) and negate it (Treatment not lower/equal X compared to control). This is our null hypothesis.\nThen we look at the data and determine how likely they would be if the null hypothesis were true.\nI.e., we want to know the conditional probability: \\(P(Data|H_0)\\)\nIf the data are very unlikely we reject the null hypothesis in favor of the alternative hypothesis (our hypothesis).\n(If the data are not very unlikely, we stick with - or fail to reject - the null hypothesis.)\n\n\nHow would you compare the two groups? Calculate the likelihood that there is a reduction in X between the groups? No, more complicated! And counterintuitive!",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#the-process-of-nhst",
    "href": "W7_Hypothesis.html#the-process-of-nhst",
    "title": "07 Hypothesis Testing",
    "section": "The Process of NHST",
    "text": "The Process of NHST\nTo be more precise, we can break down the process of null hypothesis testing in six steps:\n\nFormulate a hypothesis that embodies our prediction (before seeing the data)\nSpecify null and alternative hypotheses that reflect the hypothesis formulated in step 1\nCollect some data relevant to the hypothesis\nFit a model to the data that represents the alternative hypothesis and compute a test statistic\nCompute the probability of the observed value of that statistic assuming that the null hypothesis is true\nAssess the “statistical significance” of the result\n\n\nLet’s go through these steps, using the NHANES dataset and the research question: Is physical activity related to body mass index (BMI)?",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#step-1-formulate-a-hypothesis-of-interest",
    "href": "W7_Hypothesis.html#step-1-formulate-a-hypothesis-of-interest",
    "title": "07 Hypothesis Testing",
    "section": "Step 1: Formulate a Hypothesis of Interest",
    "text": "Step 1: Formulate a Hypothesis of Interest\nHypothesis in natural language:\n\n“BMI is greater for people who do not engage in physical activity than for those who do.”\n\nask for hypothesis?",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#step-2-specify-the-null-and-alternative-hypotheses",
    "href": "W7_Hypothesis.html#step-2-specify-the-null-and-alternative-hypotheses",
    "title": "07 Hypothesis Testing",
    "section": "Step 2: Specify the Null and Alternative Hypotheses",
    "text": "Step 2: Specify the Null and Alternative Hypotheses\nNow we engage in a more technical specification.\n\nRemember: The null hypothesis (\\(H_0\\)) is the baseline against which we test our hypothesis of interest.\nThe alternative hypothesis (\\(H_A\\)) describes what we expect if there is an effect.\nNHST works under the assumption that the \\(H_0\\) is true (unless the evidence shows otherwise).\n\n\nWe also have to decide whether we want to test a non-directional (\\(A \\neq B\\)) or directional (\\(A&gt;B\\) or \\(A&lt;B\\)) hypothesis.\nWhat do we specify if we hypothesize that “BMI is greater…”?\n\n\n\\(H_A = BMI_{inactive} &gt; BMI_{active}\\)\n\\(H_0 = BMI_{inactive} \\le BMI_{active}\\)\n\nTest against \\(H_0\\): What would we expect the data to look like if there was no effect?\nNon-directional: no direction! :D Directional: prior knowledge",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#step-3-collect-data",
    "href": "W7_Hypothesis.html#step-3-collect-data",
    "title": "07 Hypothesis Testing",
    "section": "Step 3: Collect Data",
    "text": "Step 3: Collect Data\nFor this example, we sample 250 individuals from the NHANES dataset.\n\n\n\nSummary of BMI data for active versus inactive individuals\n\n\nPhysActive\nN\nmean\nsd\n\n\n\n\nNo\n131\n30.1942\n8.9851\n\n\nYes\n119\n26.6386\n5.2499\n\n\n\n\n\n\n\n\\(BMI &gt; 75 kg/m^2\\)?\n→ over 243 kg @ 1.8 m height\nVery high but possible",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#step-4-fit-a-model",
    "href": "W7_Hypothesis.html#step-4-fit-a-model",
    "title": "07 Hypothesis Testing",
    "section": "Step 4: Fit a Model",
    "text": "Step 4: Fit a Model\nWe want to compute a test statistic that helps us decide whether to reject \\(H_0\\) or not.\n\nThe model we fit needs to quantify (= provide the test statistic) the amount of evidence in favor of \\(H_A\\) relative to the variability of the data.\nThe test statistic will have a probability distribution, allowing us to determine how likely our observed value of the statistic is under \\(H_0\\).\n\n\nIn general, we want to relate an effect (e.g., a mean or a difference of means) to the amount of uncertainty in the data (e.g., the SEM).",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#step-4-fit-a-model-1",
    "href": "W7_Hypothesis.html#step-4-fit-a-model-1",
    "title": "07 Hypothesis Testing",
    "section": "Step 4: Fit a Model",
    "text": "Step 4: Fit a Model\nIn this example, we need a test statistic that tests the difference between two (independent) means (we have one BMI mean for each group): The t statistic.\n\\[t = \\frac{\\bar{X_1} - \\bar{X_2}}{\\sqrt{\\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}}}\\]\n\\(\\bar{X_1}\\) and \\(\\bar{X_2}\\) are the means of the two group, \\(S_1^2\\) and \\(S_2^2\\) are the estimated variances of the groups,\n\\(n_1\\) and \\(n_2\\) are the sizes of the two groups.\n\n\\(\\sqrt{\\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}}\\) is something like the pooled (“averaged”) SEM of both groups.\n\nThe t statistic is appropriate for comparing the means of two groups when the sample sizes are relatively small and the population standard deviation is unknown.\n\\(\\sqrt{\\frac{S_1^2}{n_1}}\\) alone would be the SEM of subsample 1. But we have to add first before we take the square root.\nReason for adding: The variance of a difference between (or sum of) two independent variables is the sum of the variances of each individual variable (\\(Var(A−B)=Var(A)+Var(B)\\))\none can view the the t statistic as a way of quantifying how large the difference between groups is in relation to the sampling variability of the difference between means",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#the-t-distribution",
    "href": "W7_Hypothesis.html#the-t-distribution",
    "title": "07 Hypothesis Testing",
    "section": "The t Distribution",
    "text": "The t Distribution\nThe t statistic is distributed according to the t distribution, which looks similar to a normal distribution (the more degrees of freedom, the more “normal”).\nDegrees of freedom for the independent samples t test: \\(observations - 2\\) = \\(n_1 + n_2 - 2\\) (when the groups are the same size).\nDegrees of freedom: values that can freely vary when estimating parameters. Usually sample size minus values that you already calculated (e.g. means for the test statistic).\n\nIf the group sizes are unequal: \\(\\mathrm{d.f.} = \\frac{\\left(\\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}\\right)^2}{\\frac{\\left(S_1^2/n_1\\right)^2}{n_1-1} + \\frac{\\left(S_2^2/n_2\\right)^2}{n_2-1}}\\)\nFortunately, R does all these calculations for us :)\n\nDF: we have calculated two means and have thus given up two DFs (these are fixed already)\nWill be smaller if sample sizes unequal (here 241.12 vs 248 for equal)\nDegrees of freedom are the number of independent values that a statistical analysis can estimate. You can also think of it as the number of values that are free to vary as you estimate parameters",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#the-t-distribution-1",
    "href": "W7_Hypothesis.html#the-t-distribution-1",
    "title": "07 Hypothesis Testing",
    "section": "The t Distribution",
    "text": "The t Distribution",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#step-5-determine-the-probability-of-the-observed-result-under-the-null-hypothesis",
    "href": "W7_Hypothesis.html#step-5-determine-the-probability-of-the-observed-result-under-the-null-hypothesis",
    "title": "07 Hypothesis Testing",
    "section": "Step 5: Determine the Probability of the Observed Result under the Null Hypothesis",
    "text": "Step 5: Determine the Probability of the Observed Result under the Null Hypothesis\nWe do not check likelihood of the alternative distribution or likelihood that the null hypothesis is true, but rather:\nHow likely is it, given that we assume \\(H_0\\) is true, to observe a statistic at least as extreme as the one we observed.\n⇒ We need to know the distribution of the expected statistic, assuming \\(H_0\\) is true. Then we can calculate how (un-)likely it is to find the statistic (or a more extreme value) we found in our data.",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#step-5-determine-the-probability-of-the-observed-result-under-the-null-hypothesis-1",
    "href": "W7_Hypothesis.html#step-5-determine-the-probability-of-the-observed-result-under-the-null-hypothesis-1",
    "title": "07 Hypothesis Testing",
    "section": "Step 5: Determine the Probability of the Observed Result under the Null Hypothesis",
    "text": "Step 5: Determine the Probability of the Observed Result under the Null Hypothesis\n\n\ncounter-intuitive: We check the nulldistribution not the one of \\(H_A\\)! But we also don’t check how likely it is that \\(H_0\\) is true, but rather the likelihood under the null hypothesis of observing a statistic at least as extreme as the one we observed.\nat least as extreme: Prob of each particular value = 0\ntry to find out how weird statistic found is (or weirder) –&gt; count all weird(er) possibilities",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#a-simple-example",
    "href": "W7_Hypothesis.html#a-simple-example",
    "title": "07 Hypothesis Testing",
    "section": "A Simple Example",
    "text": "A Simple Example\nIs a coin biased if we flip a coin 100x and we get 70 heads?\n\\(H_0: P(heads) \\le 0.5\\) and \\(H_A: P(heads) &gt; 0.5\\)\nTest statistic = number of heads counted.\nHow likely is it that we would observe 70 or more heads if the coin is unbiased (chance of 50% for heads)?",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#a-simple-example-1",
    "href": "W7_Hypothesis.html#a-simple-example-1",
    "title": "07 Hypothesis Testing",
    "section": "A Simple Example",
    "text": "A Simple Example\nIf we flip a (fair) coin 100 times, we would get the following distribution (100’000 replications):\n\nIt is very unlikely to get 70 heads if the coin is fair!\n\nfair coin: null distribution",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#p-value",
    "href": "W7_Hypothesis.html#p-value",
    "title": "07 Hypothesis Testing",
    "section": "P-Value",
    "text": "P-Value\nLet’s go back to our BMI example.\nWe first need to calculate the t statistic:\n\n\n\nSummary of BMI data for active versus inactive individuals\n\n\nPhysActive\nN\nmean\nsd\n\n\n\n\nNo\n131\n30.2\n9.0\n\n\nYes\n119\n26.6\n5.2\n\n\n\n\n\n\\[t = \\frac{\\bar{X_1} - \\bar{X_2}}{\\sqrt{\\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}}}\\]\n\\[t = \\frac{30.2 - 26.6}{\\sqrt{\\frac{9.0^2}{131} + \\frac{5.2^2}{119}}} = 3.86\\]",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#p-value-1",
    "href": "W7_Hypothesis.html#p-value-1",
    "title": "07 Hypothesis Testing",
    "section": "P-Value",
    "text": "P-Value\n\\[t = 3.86\\]\nThe question is: What is the likelihood that we would find a t statistic of this size or more extreme given the number of degrees of freedom and if the true difference between the groups is zero.\nWe can use the t distribution to calculate this probability. We just need the degrees of freedom, which are \\(DF = 241.12\\), and we can then use all these values (e.g. in a function in R):\n\npt(3.86, df=241.12, lower.tail = F)\n\n[1] 7.282672e-05\n\n\nThis small probability tells us that our observed t value is relatively unlikely if \\(H_0\\) is really true.",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#p-value-one--vs.-two-sided",
    "href": "W7_Hypothesis.html#p-value-one--vs.-two-sided",
    "title": "07 Hypothesis Testing",
    "section": "P-Value: One- vs. Two-Sided",
    "text": "P-Value: One- vs. Two-Sided\nPreviously, we calculated the p-Value for a directional hypothesis. In this case, we only looked at the upper tail probability. With a non-directional hypothesis, we would want to account for both tail probabilities, i.e. how likely it is that a \\(t &gt; 3.86\\) OR \\(t &lt; -3.86\\) is found. In this case, we can simply multiply the previous p-Value by 2 (since it is a symmetric distribution):\n\npt(3.86, df=241.12, lower.tail = F) * 2\n\n[1] 0.0001456534",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#p-value-using-randomization",
    "href": "W7_Hypothesis.html#p-value-using-randomization",
    "title": "07 Hypothesis Testing",
    "section": "P-Value using Randomization",
    "text": "P-Value using Randomization\nWe can also use our simulation skills to determine the null distribution!\n\nWe can randomly rearrange (or permute) data so that no relationship is present, e.g. assigning group membership to the participants randomly. In this case, \\(H_0\\) should thus be true.\nWe would do this a large amount of times (e.g. 10’000), calculate the t statistics for each iteration, and draw a histogram to show the distribution.",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#p-values-using-randomization",
    "href": "W7_Hypothesis.html#p-values-using-randomization",
    "title": "07 Hypothesis Testing",
    "section": "P-Values using Randomization",
    "text": "P-Values using Randomization\n\n# create function to shuffle BMI data\nshuffleBMIstat &lt;- function() {\n  bmiDataShuffled &lt;- \n    NHANES_sample %&gt;%\n    select(BMI, PhysActive) %&gt;%\n    mutate(\n      BMI = sample(BMI) #randomly shuffle BMI values\n    )\n  # compute the difference\n  simResult &lt;- t.test( #t.test function is more convenient than pt function!\n    BMI ~ PhysActive,\n    data = bmiDataShuffled,\n  )\n  return(simResult$statistic)\n}\n# run function 10'000 times and save output\nnRuns &lt;- 10000\nmeanDiffSimDf &lt;- tibble(meanDiffSim = replicate(nRuns, shuffleBMIstat()))\n#run t test of actual data\nbmtTTest &lt;- \n  t.test(\n  BMI ~ PhysActive,\n  data = NHANES_sample,\n  alternative = \"greater\"\n)\n#compare actual data with simulation\nbmiPvalRand &lt;- \n  mean(meanDiffSimDf$meanDiffSim &gt;= bmtTTest$statistic)",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#p-values-using-randomization-1",
    "href": "W7_Hypothesis.html#p-values-using-randomization-1",
    "title": "07 Hypothesis Testing",
    "section": "P-Values using Randomization",
    "text": "P-Values using Randomization\n\nThe blue line is the observed t statistic. We can calculate a p-Value by counting how many of the simulated t-values are at least as extreme as our observed one and dividing it by the number of simulations. The p-value obtained from randomization (0.000000) is kind of similar to the one obtained using the t distribution (0.000075).\n\nUsing simulations to get the null distribution can be helpful if the assumptions (normal distribution in each group) are violated or if we don’t know the theoretical distribution of the test statistic!\n\nexchangeability: We can use permutations if all observsations are distributed in the same way, such that we can shuffle them without changing the overall distribution.\nNot the case if we have dependent observations, e.g. siblings…",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#step-6-assess-the-statistical-significance-of-the-result",
    "href": "W7_Hypothesis.html#step-6-assess-the-statistical-significance-of-the-result",
    "title": "07 Hypothesis Testing",
    "section": "Step 6: Assess the “Statistical Significance” of the Result",
    "text": "Step 6: Assess the “Statistical Significance” of the Result\nIs the p-value determined small enough to reject the null hypothesis (and thus conclude that the alternative hypothesis is true)?\n\nTraditionally, we reject \\(H_0\\) if the p-value is less than 0.05. (Fisher’s approach)\n\n\n(Either there is an effect/\\(H_A\\) is true or there is a small chance (5%) that there is actually no effect but we coincidentally found such a large value → false positive)\n\n\nNeyman-Pearson approach: In the long run, we will know how often we are wrong:\n\n\\(\\alpha = .05\\) (false positives or Type I error: We reject \\(H_0\\) although it is correct),\n\\(\\beta = .2\\) (false negatives or Type II error: We accept \\(H_0\\) although it is wrong),\nWe will be correct if we reject \\(H_0\\) when it is wrong (there is actually a difference/an effect) or if we do not reject \\(H_0\\) when it is correct (and there is no difference between groups).\n\nIn both cases, a significance level of \\(\\alpha = .05\\) is usually used.\n\nHow much evidence do we require?\n0.05 Fisher never intended it to be fixed\nBefore computers, tables were used, and all tables had .05 in it!\nFisher: Evidence for hypothesis, NP: long-run error rate",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#what-does-a-significant-result-not-mean",
    "href": "W7_Hypothesis.html#what-does-a-significant-result-not-mean",
    "title": "07 Hypothesis Testing",
    "section": "What does a significant result (not) mean?",
    "text": "What does a significant result (not) mean?\nThere is a lot of discussion about the usefulness of using \\(\\alpha = .05\\) as well as about the interpretation of a significant result/certain p-value!\n\nA p-value of .01 does….\n\nNOT mean that the probability that \\(H_0\\) is true is 1%!\n\nWe tested \\(P(data|H_0)\\) not \\(P(H_0|data)\\)!\n\nNOT mean that the probability that you’re making a wrong decision is 1%!\n\nThis would also be \\(P(H_0|data)\\)! p-values are probabilities of data (under \\(H_0\\)), not probabilities of hypotheses! And we cannot easily use Bayes to turn the condition because we would need additional information like the prior probability of an alternative hypothesis being true.\n\nNOT mean that you would get the same significance 99% of the time if you repeated the study.\n\nThe p-value is a statement about the likelihood of one particular dataset under the null.\n\nNOT mean that you found a practically important effect.\n\nDifference between statistical significance and practical significance! Effect sizes are important here. (Statistical significance depends on sample size!)",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#multiple-testing",
    "href": "W7_Hypothesis.html#multiple-testing",
    "title": "07 Hypothesis Testing",
    "section": "Multiple Testing",
    "text": "Multiple Testing\nNowadays, we often have huge datasets in neuroscience, e.g. collecting brain imaging data of thousands of voxels or quantifying the entire genome.\n\nLet’s look at genome-wide associations studies (GWAS). We have more than a million places in where the genome could differ. If we want to know whether schizophrenia was associated with any of these differences, we would do ~1’000’000 tests! If we simply used \\(\\alpha \\le .05\\) as a threshold, we would get a lot of (\\(1'000'000 * .05 = 50'000\\) 😱) false positives, even if no true effect is present at all.\n\n\nIn this case, we have a lot of dependent tests, which form a family of tests. In such a case, we need to control the family-wise error rate, e.g. by fixing it to a total of \\(\\alpha \\le .05\\) (i.e. the probability of making any Type I error in our study is controlled at .05).\n\n\nOne option is to use the Bonferroni correction, in which we divide .05 by the number of tests (e.g. 1.000.000) and use the new value (\\(\\alpha \\le .000005\\)) as threshold for each individual test.\n\n\nThis is extremely conservative and often results in false negative test results.\n\n\nFor an interesting example what can happen when not correcting for multiple comparisons, see this dead fish showing significant brain activity (Link).",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#confidence-intervals",
    "href": "W7_Hypothesis.html#confidence-intervals",
    "title": "07 Hypothesis Testing",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\nSingle value statistic (e.g. t-value, mean…) = point estimate\n\nWe know from the sampling error discussion that each point estimate comes with some uncertainty, described by the standard error.\nRemember, the SEM (standard error of the mean) was calculated with the sample standard deviation \\(\\hat{\\sigma}\\) and the square root of the sample size \\(n\\):\n\\[SEM = \\frac{\\hat{\\sigma}}{\\sqrt{n}}\\]\n\\(n\\) is generally under our control (\\(\\hat{\\sigma}\\) is unknown but fixed*), and we can thus decrease our uncertainty by increasing the sample size.\n\n\n\nWe can more directly describe our uncertainty with confidence intervals (CI), which provides a range of values for our parameter estimate that are consistent with our data! The wider the CI, the more uncertain we are about our estimate.\n\n\n* In practice, we can acquire homogeneous samples (like students) or heterogeneous samples (like extreme groups). This will, however, influence our generalizability.",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#confidence-intervals-2",
    "href": "W7_Hypothesis.html#confidence-intervals-2",
    "title": "07 Hypothesis Testing",
    "section": "Confidence Intervals 2",
    "text": "Confidence Intervals 2\nBecause the CI depends on the SEM, which decreases with sample size, the CI also gets narrower with increasing sample size:\n\n\nif we sample the whole population, we know the population parameter and there is no uncertainty at all!\nRange of possible values (estimate) in concordance with the data",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#confidence-intervals-3",
    "href": "W7_Hypothesis.html#confidence-intervals-3",
    "title": "07 Hypothesis Testing",
    "section": "Confidence Intervals 3",
    "text": "Confidence Intervals 3\nJust like p-values, confidence intervals can be confusing because they are counter-intuitive: A 95% CI for a statistic does NOT mean that we can have 95% confidence that the true parameter falls within this interval!\nIt is, again, the long-run probability: It will contain the true population parameter 95% of the time in the long-run.\nLet’s sample 100 times with \\(n = 250\\) from the NHANES data and calculate CIs. We use the NHANES mean as true score (dashed line) and check how often the CI misses to include it: 5% of the time.\n\n\nbut: new experiment = new estimate (under exact same conditions would work)!",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#calculating-the-ci",
    "href": "W7_Hypothesis.html#calculating-the-ci",
    "title": "07 Hypothesis Testing",
    "section": "Calculating the CI",
    "text": "Calculating the CI\nWe calculate the CI as follows:\n\\(CI = \\text{point estimate} \\pm \\text{critical value} * \\text{standard error}\\)\nThe “critical value” depends on the sampling distribution. Most of the time, we will use the normal distribution.\n\nCI depends on the confidence level (95%, critical value), the sample size and the variability in the data (both SE)",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#ci-using-the-normal-distribution",
    "href": "W7_Hypothesis.html#ci-using-the-normal-distribution",
    "title": "07 Hypothesis Testing",
    "section": "CI using the Normal Distribution",
    "text": "CI using the Normal Distribution\nThe critical value are the values of the standard normal distribution that capture 95% (in case of a 95% CI) of the distribution, i.e. the 2.5th and 97.5th percentile.\n\nqnorm(p=c(.025,.975))\n\n[1] -1.959964  1.959964\n\n\nThe CI of the mean would thus be:\n\\(CI = \\bar{X} \\pm 1.96*SE\\)\nOur mean weight in the NHANES sample was 79.92 kg and the SE was \\(\\frac{SD_{weight}}{\\sqrt{n}} = 1.35\\) (for a random \\(n=250\\) subsample)*.\n\nThe lower boundary of the CI of the mean would then be \\(CI = 79.92 - 1.96 * 1.35 = 77.28\\) and the upper \\(CI = 79.92 + 1.96 * 1.35 = 82.56\\). We would write this as [77.28, 82.56].\n\n* In practice, both the mean and standard deviation will be subject to sampling error, i.e., CIs will differ both in location and size despite having the same sample size (cf. plot 2 slides ago)",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#ci-using-the-t-distribution",
    "href": "W7_Hypothesis.html#ci-using-the-t-distribution",
    "title": "07 Hypothesis Testing",
    "section": "CI using the t Distribution",
    "text": "CI using the t Distribution\nIf we don’t know the population standard deviation, which is usually the case, it is more appropriate to use the t distribution.\nIn this case, we use the critical value of the t distribution:\n\nqt(p = c(.025, .975), 250) #t distribution depends on sample size! =&gt; n = 250\n\n[1] -1.969498  1.969498\n\n\nFor the NHANES weight example, the CI would be: \\(79.92 \\pm 1.97 * 1.35 = [77.15, 82.58]\\).\nThe CI for a t distribution is always larger than for a normal distribution. In practice, this difference is negligible at \\(n \\ge 30\\) (1.984 vs. 1.960).\n\nThe t distribution is wider than the normal distribution (especially for smaller samples), which means that the CI will be slightly wider -&gt; extra uncertainty smaller samples.\npopulation parameter hast a fixed value, so it either falls into CI or not. (Doesn’t make sense to talk about probability of it)",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#ci-using-the-bootstrap",
    "href": "W7_Hypothesis.html#ci-using-the-bootstrap",
    "title": "07 Hypothesis Testing",
    "section": "CI using the Bootstrap",
    "text": "CI using the Bootstrap\nIf we can’t assume normality or don’t know the sampling distribution, we can also use the bootstrap to compute the CI.\n\nReminder: bootstrap = resampling with replacement, using the data itself as the sampling distribution!\n\n\nIf we use an R function for bootstrapping (boot()), we get CI estimates that are fairly close to the ones calculated:\n\nmeanWeight &lt;- function(df, foo) {\n  return(mean(df[foo, ]$Weight))\n}\nbs &lt;- boot(NHANES_sample, meanWeight, 1000)\n# use the percentile bootstrap\nbootci &lt;- boot.ci(bs, type = \"perc\")\nprint(bootci)\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 1000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = bs, type = \"perc\")\n\nIntervals : \nLevel     Percentile     \n95%   (78.41, 83.81 )  \nCalculations and Intervals on Original Scale",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#ci-comparison",
    "href": "W7_Hypothesis.html#ci-comparison",
    "title": "07 Hypothesis Testing",
    "section": "CI comparison",
    "text": "CI comparison\n\n\n\nMethod\nCI\n\n\n\n\nnormal distribution\n[77.28, 82.56]\n\n\nt distribution\n[77.15, 82.58]\n\n\nbootstrap\n[78.41, 83.81]\n\n\n\n\nNote: CIs from the normal and t distribution are always symmetrical around the mean (here: 79.92), bootstrapped intervals need not be.",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#relationship-of-cis-to-hypothesis-tests",
    "href": "W7_Hypothesis.html#relationship-of-cis-to-hypothesis-tests",
    "title": "07 Hypothesis Testing",
    "section": "Relationship of CIs to Hypothesis Tests",
    "text": "Relationship of CIs to Hypothesis Tests\nIf the CI does not include the value of the null hypothesis (usually 0), then the associated two-sided one sample test would be significant.\n\nIf we want to compare two conditions, it gets trickier.\n\nIf each mean is contained within the CI of the other mean, then there’s definitely no significant difference.\nIf there is no overlap between CIs, then there is certainly a significant difference (two-sidedly).\nIf the CIs overlap (but don’t contain the other mean), it depends on the relative variability of the two variables\n\nIn general, avoid this “eyeball test” and look at the p value! (or learn to plot CIs for mean differences here)\nNote: Slightly overlapping CIs can still be significant (e.g., one sided hypothesis)\nNote 2: It is possible (but not common) to report one-sided CIs.",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#effect-sizes",
    "href": "W7_Hypothesis.html#effect-sizes",
    "title": "07 Hypothesis Testing",
    "section": "Effect Sizes",
    "text": "Effect Sizes\nPractical significance!\nWe need a standard way to describe the size of an effect.\nAn effect size is a standardized measurement that compares the size of an effect to e.g. the variability of the statistic. This is also referred to as signal-to-noise ratio.\nThere are many different variants of effect sizes!",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#cohens-d",
    "href": "W7_Hypothesis.html#cohens-d",
    "title": "07 Hypothesis Testing",
    "section": "Cohen’s d",
    "text": "Cohen’s d\nCohen’s d is used to quantify the difference between two means, in terms of their SD:\n\\[d = \\frac{\\bar{X_1} - \\bar{X}_2}{s}\\]\nwhere \\(\\hat{X_1}\\) and \\(\\hat{X_2}\\) are the means of the two groups and \\(s\\) is the pooled SD:\n\\[s = \\sqrt{\\frac{(n_1 - 1)s^2_1 + (n_2 - 1)s^2_2 }{n_1 +n_2 -2}}\\]\nwhich is a combination of both groups’ variances (\\(s_1^2\\) and \\(s_2^2\\)) weighted by their degrees of freedom\n(\\(n_1-1\\) and \\(n_2-1\\)).\n\nNote that this is very similar to the t statistic, only the denominator differs:\nt = SEM, d = SD of the data\n–&gt; d will not grow with sample size but remain stable!",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#cohens-d-1",
    "href": "W7_Hypothesis.html#cohens-d-1",
    "title": "07 Hypothesis Testing",
    "section": "Cohen’s d",
    "text": "Cohen’s d\nThere is a commonly used interpretation of Cohen’s d (although it is criticized to use these cutoffs!):\n\n\n\nInterpetation of Cohen’s d\n\n\nd\nInterpretation\n\n\n\n\n0.0 - 0.2\nnegligible\n\n\n0.2 - 0.5\nsmall\n\n\n0.5 - 0.8\nmedium\n\n\n&gt; 0.8\nlarge",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#cohens-d-2",
    "href": "W7_Hypothesis.html#cohens-d-2",
    "title": "07 Hypothesis Testing",
    "section": "Cohen’s d",
    "text": "Cohen’s d\nEven with a large effect of \\(d = 1.78\\) (as in the NHANES data set), the distributions still overlap greatly!\n\n\nSmall effect but huge total impact: Psychosocial stress due to Covid-19 (deployed to a whole population)",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#pearsons-r",
    "href": "W7_Hypothesis.html#pearsons-r",
    "title": "07 Hypothesis Testing",
    "section": "Pearson’s r",
    "text": "Pearson’s r\nPearson’s r is a correlation coefficient, and thus a measure of the strength of a linear relationship between two continuous variables.\nr can vary from -1 to 1: -1 is a perfect negative relationship, 0 no (linear) relationship, and 1 a perfect positive relationship. Try your skills eye-balling the size of a correlation: https://www.guessthecorrelation.com/\n\n\nmore on correlations later in the semester!",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#odds-ratio",
    "href": "W7_Hypothesis.html#odds-ratio",
    "title": "07 Hypothesis Testing",
    "section": "Odds Ratio",
    "text": "Odds Ratio\nFor binary variables, the odds ratio is a useful effect size.\nOdds describes the relative likelihood of some event happening versus not happening:\n\\[\n\\text{odds of A} = \\frac{P(A)}{P(\\neg{A})}\n\\]\nOdds ratio is simply the ratio of two odds, i.e. \\(\\frac{\\text{odds of A}}{\\text{odds of B}}\\).",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#odds-ratio-example",
    "href": "W7_Hypothesis.html#odds-ratio-example",
    "title": "07 Hypothesis Testing",
    "section": "Odds Ratio Example",
    "text": "Odds Ratio Example\n\n\n\nLung cancer occurrence separately for current smokers and those who have never smoked\n\n\nStatus\nNeverSmoked\nCurrentSmoker\n\n\n\n\nNo Cancer\n2883\n3829\n\n\nCancer\n220\n6784\n\n\n\n\n\n\\[OR = \\frac{\\frac{220}{220+2883}}{\\frac{6784}{6784+3829}} = 23.22 \\]\nThe odds ratio of 23.22 tells us that the odds of developing lung cancer in smokers are roughly 23x higher than that of non-smokers!",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#statistical-power",
    "href": "W7_Hypothesis.html#statistical-power",
    "title": "07 Hypothesis Testing",
    "section": "Statistical Power",
    "text": "Statistical Power\nRemember: Type I and Type II error!\nTolerance for Type I errors set to \\(\\alpha = 0.05\\), which is very low → we want to avoid this error!\nWhat about Type II errors?\n\nType II = failing to reject \\(H_0\\) although an effect exists (often set at \\(\\beta = 0.20\\), i.e., a statistical power of \\(80\\%\\)).\nBut \\(\\beta\\) also depends on the effect size: The likelihood of finding a large effect is higher than finding a small effect (at constant \\(n\\))!\n\n\nStatistical power is the complement of the Type II error:\nThe likelihood of finding a positive result given that it exits!\n\\[power = 1 - \\beta\\]\n\nType I: false positives\nType II: false negatives",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#statistical-power-1",
    "href": "W7_Hypothesis.html#statistical-power-1",
    "title": "07 Hypothesis Testing",
    "section": "Statistical Power",
    "text": "Statistical Power\nStatistical power is affected by three factors:\n\nsample size (larger n = more power)\neffect size (larger effect = more power)\nType I error rate (smaller Type I error = less power)",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#statistical-power-2",
    "href": "W7_Hypothesis.html#statistical-power-2",
    "title": "07 Hypothesis Testing",
    "section": "Statistical Power",
    "text": "Statistical Power\n\nThe black dotted line denotes the standard 80% power that is often aimed at.\n\nEven with \\(n = 96\\), we have only little power to detect a small effect (\\(d = 0.2\\); solid red line): Only ~25% of studies would find the true effect. This means doing such a study would be futile.",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#statistical-power-3",
    "href": "W7_Hypothesis.html#statistical-power-3",
    "title": "07 Hypothesis Testing",
    "section": "Statistical Power",
    "text": "Statistical Power\nTo avoid conducting underpowered studies, we would do a power analysis before we even run the study - to determine the necessary sample size for a well-powered study that would be able to find an effect if the effect is true.\nFurthermore, positive findings from an underpowered study are more likely to be false positive!\n\nMore on that in Chapter 18 of ST21!",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W5_Probability.html#probability-theory",
    "href": "W5_Probability.html#probability-theory",
    "title": "05 Probability",
    "section": "Probability Theory",
    "text": "Probability Theory\nDefinitions:\n\nExperiment: Activity that produces outcome\nSample space: Set of possible outcomes for an experiment\nEvent: Subset of the sample space, an outcome\n\n\n\nExperiment: e.g. roll a die\nSample space: six-sided die: {1,2,3,4,5,6}\nEvent: e.g. 3\n\n\nHand out dice, coins etc to pairs.\nAsk what Experiment, Sample Space and Event is in each case.",
    "crumbs": [
      "05 Probability"
    ]
  },
  {
    "objectID": "W5_Probability.html#probability-theory-2",
    "href": "W5_Probability.html#probability-theory-2",
    "title": "05 Probability",
    "section": "Probability Theory 2",
    "text": "Probability Theory 2\nLet’s say we have a variable \\(X\\) that contains \\(N\\) independent events:\n\\[\nX = E_1, E_2, …, E_n\n\\]\nThe probability of a certain event (event \\(i\\)) is then formally written as:\n\\[\nP(X = E_i) \\]\n\nFormal features of probability theory:\n\nProbability can’t be negative.\nThe total probability of outcomes in the sample space is 1.\nThe probability of any individual event can’t be greater than 1.\n\n\nWhat is N and E’s in dice/coins case?\nDo the 3 features make sense in their own example? Height e.g. is difficult",
    "crumbs": [
      "05 Probability"
    ]
  },
  {
    "objectID": "W5_Probability.html#determine-probabilities",
    "href": "W5_Probability.html#determine-probabilities",
    "title": "05 Probability",
    "section": "Determine Probabilities",
    "text": "Determine Probabilities\nHow would you determine probabilities? E.g. how likely is it that you roll a 6 or toss head? (Think about your own example!)\n\n\nPersonal belief (not very scientific!)\nEmpirical frequency\n\nLaw of large numbers\n\nClassical probability\n\n\npersonal belief: What would have been? Which vaccination is best (opinion)\nempirical: count events from the past, divide by possible events (rain days from all days)\n–&gt; which year(s)? The more data, the better\nLaw of large numbers: The more times you repeat an experiment, the less likely you get extreme values.",
    "crumbs": [
      "05 Probability"
    ]
  },
  {
    "objectID": "W5_Probability.html#classical-probability",
    "href": "W5_Probability.html#classical-probability",
    "title": "05 Probability",
    "section": "Classical Probability",
    "text": "Classical Probability\nRules of probability\n\nWhat is the probability of an event not happening? (E.g. not rolling a 6)\n\nSubtraction: Probability of some event (A) not happening = 1- probability that it happens:\n\n\\(P(\\neg A) = 1 - P(A)\\)\n\n\nWhat is the probability of two events happening together, i.e. rolling a 3 and a 4 or tossing two heads?\n\nIntersection: The probability of a conjoint event/that both A and B will occur (\\(\\cap\\)):\n\n\\(P(A \\cap B) = P(A) * P(B)\\) (if A and B are independent!)\n\n\nWhat is the probability of either of two events occuring, e.g. rolling a 3 or a 4?\n\nAddition: Probability of either of two events occurring (\\(\\cup\\)):\n\n\\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\)\nWe add both but subtract the intersection, prevents us from counting intersection twice!\n\n\n\n\nAsk for every point how they would try to figure it out with dice/coins\n\\(\\neg A\\) = “not A”, derives from Axioms above: Sum must be 1\n\\(\\cap\\) = or; \\(\\cup\\) = and\naddition: difference 1 vs. 2 dice!",
    "crumbs": [
      "05 Probability"
    ]
  },
  {
    "objectID": "W5_Probability.html#classical-probability-2",
    "href": "W5_Probability.html#classical-probability-2",
    "title": "05 Probability",
    "section": "Classical Probability 2",
    "text": "Classical Probability 2\nProbability of getting at least one 6 within two dice rolls: 11x success out of 36 possibilities: \\(\\frac{11}{36} = 30.1\\%\\)\n\nEach cell in this matrix represents an outcome of throws of two dice (rows = one die, columns = other die). Cells in red represent the cells with a six.\nDon’t count 6,6 twice!\nFor example, go to book\nProbability is important for statistics, so it is necessary to go through the rules once\n–&gt; necessary to draw inferences from data! How representative are data for population?",
    "crumbs": [
      "05 Probability"
    ]
  },
  {
    "objectID": "W5_Probability.html#conditional-probability",
    "href": "W5_Probability.html#conditional-probability",
    "title": "05 Probability",
    "section": "Conditional Probability",
    "text": "Conditional Probability\nHow likely is an event given that another event has occurred?\n\\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\]\n“The conditional probability of A given B is the joint probability divided by the overall probability of B”.\n\nExample: The conditional probability of being infected with Covid-19, given a positive test result (it could be a false positive!). This will be illustrated in more detail in conjunction with Bayes’ Rule.\n\nHow likely to roll a 6 if previously a 5? NO, independent events!\nHow likely is it that you pass the class if you have taken the course?\nProbability that both things are true given that the one being conditioned upon is true",
    "crumbs": [
      "05 Probability"
    ]
  },
  {
    "objectID": "W5_Probability.html#independence",
    "href": "W5_Probability.html#independence",
    "title": "05 Probability",
    "section": "Independence",
    "text": "Independence\nStarting point: \\[P(A|B) = \\frac{P(A \\cap B)}{P(B)}\\] For independence: \\[ P(A \\cap B) = P(A) * P(B) \\] This means: \\[P(A|B) = \\frac{P(A)*P(B)}{P(B)} = P(A)\\]\n=&gt; Independence = Knowing the value of one variable doesn’t tell us anything about the value of the other\nBut if the two variables are dependent, the conditional probability \\(P(A|B)\\) will differ from the overall probability \\(P(A)\\).\n\nComparing conditional and overall prob might be helpful to determine whether variables are independent.\nEx: physical activity and mental health.\nUse conditional probability in most cases!",
    "crumbs": [
      "05 Probability"
    ]
  },
  {
    "objectID": "W5_Probability.html#exercises",
    "href": "W5_Probability.html#exercises",
    "title": "05 Probability",
    "section": "Exercises",
    "text": "Exercises\n\nThere have been 10 parties so far. Anna has gone to 5 of them, Barbara to 8. How likely do you expect each Anna and Barbara to go to the next party?\n\n\n\\[ P(A) = \\frac{5}{10} = 50\\%; P(B) = \\frac{8}{10} = 80\\% \\]\n\n\n\nOut of the 10 parties, to how many have both Anna and Barbara been under the assumption that they went to parties independently? (Or how likely is it that both Anna and Barbara will go to the next party?)\n\n\n\n\\[ P(A \\cap B) = P(A) * P(B) = .5 * .8 = 40\\% \\]\n\n\n\nYou learn that, in fact, Anna and Barbara have both been present at 5 parties. From this information, would you expect that Anna and Barbara are a) friends, b) don’t like each other, c) neither?\n\n\n\nAnna and Barbara have both been present at 5 parties but should have been only at 4 given independence. Thus, they were there together more often than “by chance”, indicating that they may have arranged to go together. Hence, they may be friends. (If this increment from 4 to 5 parties is also statistically significant will be answered in the upcoming lectures.)\n\n\n\nYou are late to the 11th party - everyone else is already there. You enter the apartment and see Barbara. How likely do you think Anna will also be there?\n\n\n\n\\[ P(A|B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{50\\%}{80\\%} = 62.5\\% \\] 62.5% is not huge but bigger than the prior probability to find Anna at a party of \\(P(A) = 50\\%\\)!\n\n\n\nYou are late to the 11th party - everyone else is already there. You enter the apartment and see Anna. How likely do you think Barbara will also be there?\n\n\n\n\\[ P(B|A) = \\frac{P(A \\cap B)}{P(A)} = \\frac{50\\%}{50\\%} = 100\\% \\] We have never seen Anna at a party without Barbara (both \\(P(A)\\) and \\(P(A \\cap B)\\) are 50%). Thus, we are pretty sure to find Barbara once we see Anna (unless the pattern changes).\n\n\nImagine Anna and Barbara hate each other such they would never (or very unlikely) go to the same party. Then, \\(P(A \\cap B) &lt; P(A) * P(B)\\). If they like each other, \\(P(A \\cap B) &gt; P(A) * P(B)\\).",
    "crumbs": [
      "05 Probability"
    ]
  },
  {
    "objectID": "W5_Probability.html#bayes-rule",
    "href": "W5_Probability.html#bayes-rule",
    "title": "05 Probability",
    "section": "Bayes’ Rule",
    "text": "Bayes’ Rule\nOften we know \\(P(B|A)\\) but really want to know \\(P(A|B)\\)!\nExample: From the test manual, we know the probability of getting a positive Covid test when we actually have Covid, \\(P(positive|Covid)\\). But we usually want to know the probability of having Covid once we tested positive, \\(P(Covid|positive)\\).\n\nThis reversed conditional probability can be calculated using Bayes’ Rule:\n\\[P(A|B) = \\frac{P(A) * P(B|A)}{P(B)}\\]\n\n\n\nIf we have two outcomes, we can expand using:\n\\[P(B) = P(A \\cap B) + P(\\neg A \\cap B) = P(A) * P(B|A) + P(\\neg A) * P(B|\\neg A)\\]\nUpdated Bayes’ Rule:\n\\[P(A|B) = \\frac{P(A)*P(B|A)}{P(A)*P(B|A) + P(\\neg A)*P(B|\\neg A)}\\]",
    "crumbs": [
      "05 Probability"
    ]
  },
  {
    "objectID": "W5_Probability.html#bayes-rule-2",
    "href": "W5_Probability.html#bayes-rule-2",
    "title": "05 Probability",
    "section": "Bayes’ Rule 2",
    "text": "Bayes’ Rule 2\nExample: Let’s try to find out:\n\\[P(Covid|positive) = \\frac{P(Covid) * P(positive|Covid)}{P(positive)}\\]\nTests can’t be 100% correct, there are always false positives and false negatives. But let’s say the sensitivity of the test \\(P(positive|Covid)\\) is 95% and the specificity \\(P(negative|healthy)\\) is 75%.\n\nWe’d also need the prevalence of Covid, \\(P(Covid)\\), which is (let’s say) 10%.\nFinally, we plug in \\(P(pos) = P(Covid) * P(pos|Covid) + P(healthy) * P(pos|healthy)\\). So that would be\n\\[P(positive) = .1 * .95 * + (1-.1) * (1-.95) = .14\\]\nBringing it together, we get:\n\\[P(Covid|positive) = \\frac{.1 * .95}{.14} = .679\\]\nIf we test positive, we’d thus are actually infected with a probability of 67.9%!\n\n\n(But before, we only had 10%, i.e. \\(P(Covid)\\))",
    "crumbs": [
      "05 Probability"
    ]
  },
  {
    "objectID": "W5_Probability.html#learning-from-data",
    "href": "W5_Probability.html#learning-from-data",
    "title": "05 Probability",
    "section": "Learning from Data",
    "text": "Learning from Data\nThe terms in Bayes’ Rule have some specific names:\n\\[P(Covid|positive) = \\frac{P(Covid) * P(positive|Covid)}{P(positive)}\\]\n\nThe prevalence \\(P(Covid)\\) in our example is also called the prior probability (before we have any further information, e.g. the test result).\nAfter we collected new evidence (= test result), we have the likelihood: \\(P(positive|Covid)\\), which is the sensitivity of the test.\n\\(P(positive)\\) is the marginal likelihood (overall likelihood positive tests across infected and healthy individuals).\nFinally, \\(P(Covid|test)\\) is the posterior probability (after accounting for the new observation).\n\n\\[\nP(B|A) = \\frac{P(A|B)}{P(A)} * P(B)\n\\]\n\\(P(A|B)/P(A)\\) = how likely the data are given B relative to overall marginal likelihood (how likely a pos rest if Covid relative to how likely it is to have a pos. test in general)\n\\(P(B)\\) = how likely we thought it was to have Covid before we knew the test result",
    "crumbs": [
      "05 Probability"
    ]
  },
  {
    "objectID": "W5_Probability.html#sum-up",
    "href": "W5_Probability.html#sum-up",
    "title": "05 Probability",
    "section": "Sum Up",
    "text": "Sum Up\nModels and probability are central to statistics, as we will see.\nThere are two intepretations of probability: Frequentist and Bayesian.\nFrequentists interpret probability as the long-run frequencies (e.g. how many people end up getting Covid).\nBayesians interpret probability as a degree of belief. How likely is it to catch Covid if you go out now? Based on beliefs and knowledge.\n\nFreq: Difficult to wrap ones’ head around if an event occurs only once.\nBayes: Bit more subjective",
    "crumbs": [
      "05 Probability"
    ]
  },
  {
    "objectID": "W5_Probability.html#the-uniform-distribution",
    "href": "W5_Probability.html#the-uniform-distribution",
    "title": "05 Probability",
    "section": "The Uniform Distribution",
    "text": "The Uniform Distribution\nIn a uniform distribution, each possible outcome has an equal chance of occurring.\n\nIf we have a hat with 12 paper slips with names, each name has an equal chance (\\(p = \\frac{1}{12} \\approx .08\\)) of being drawn:",
    "crumbs": [
      "05 Probability"
    ]
  },
  {
    "objectID": "W5_Probability.html#the-binomial-distribution",
    "href": "W5_Probability.html#the-binomial-distribution",
    "title": "05 Probability",
    "section": "The Binomial Distribution",
    "text": "The Binomial Distribution\nThe binomial (“two categories”) distribution is used for discrete data with two possible outcomes (e.g., flipping a coin). It models the number of successes being observed (e.g., heads), given the probability of success (0.5 for fair coins) and the number of observations (flips of a coin, e.g., 10).\n\nHow many heads (successes) should we expect and with what probability?\nWe can simulate 10 coin flips (or dice) each 10.000 times and count the number of heads (out of the 10). We can use this distribution to work out the probability of different outcomes, e.g., getting at least 3 heads (or 6s) out of 10 tosses (dice rolls).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsuccess: whatever you want, also an “artificial” dichotomization like “roll a 6” vs. “roll no 6”\nadd up probabilities &gt;=3 or 1 - P(X &lt;= 2)",
    "crumbs": [
      "05 Probability"
    ]
  },
  {
    "objectID": "W5_Probability.html#the-normal-distribution",
    "href": "W5_Probability.html#the-normal-distribution",
    "title": "05 Probability",
    "section": "The Normal Distribution",
    "text": "The Normal Distribution\nThe normal distribution is very common in statistics (i.e., in the real world). It (roughly) reflects the probability of any value occurring for a continuous variable, such as height.\n\nNormal distribution of height\nThe normal distribution is always symmetrical\n=&gt; equal probability of observations above and below the mean.\n=&gt; the mean, median, and mode are all equal!",
    "crumbs": [
      "05 Probability"
    ]
  },
  {
    "objectID": "W5_Probability.html#normal-distribution-2",
    "href": "W5_Probability.html#normal-distribution-2",
    "title": "05 Probability",
    "section": "Normal Distribution 2",
    "text": "Normal Distribution 2\nWe can also use simulations to approximate a normal distribution. This simulation shows that increasing the sample size will get closer to a normal distribution:\n\nA simulation of an experiment collecting height data from 5000 participants.",
    "crumbs": [
      "05 Probability"
    ]
  },
  {
    "objectID": "W5_Probability.html#using-the-uniform-distribution",
    "href": "W5_Probability.html#using-the-uniform-distribution",
    "title": "05 Probability",
    "section": "Using the Uniform Distribution",
    "text": "Using the Uniform Distribution\nWe can use runif for a uniform distribution of continuous (numerical) values or\nsample for a uniform distribution of discrete (numerical or text) values.\n\nDraw a random decimal number between 0 and 1\nDraw 100 random decimal numbers between 0 and 10 and calculate their mean.\nDraw 50 random integer numbers between 1 and 10 and calculate their mean.\nDraw who may have the first turn during board game night: Anna, Barbara, Christina, or Dana.\nProduce a random order of all the names of Anna, Barbara, Christina, and Dana.\n\n\n\n#1\nrunif(n=1) #default parameters are already set to min=0 and max=1\n\n[1] 0.2050952\n\n#2\nrunif(n=100, max=10) %&gt;% mean()\n\n[1] 4.833934\n\n#3\nsample(1:10, size=50, replace=T) %&gt;% mean()\n\n[1] 4.88\n\n#4\nsample(c(\"Anna\", \"Barbara\", \"Christina\", \"Dana\"), size=1)\n\n[1] \"Anna\"\n\n#5\nsample(c(\"Anna\", \"Barbara\", \"Christina\", \"Dana\")) #by default, sample draws all elements in random order\n\n[1] \"Christina\" \"Anna\"      \"Barbara\"   \"Dana\"",
    "crumbs": [
      "05 Probability"
    ]
  },
  {
    "objectID": "W5_Probability.html#using-the-binomial-distribution",
    "href": "W5_Probability.html#using-the-binomial-distribution",
    "title": "05 Probability",
    "section": "Using the Binomial Distribution",
    "text": "Using the Binomial Distribution\n\n\n\n\ndbinom(): the density distribution gives you the probability of exactly \\(x_i\\) successes given the number of trials and the probability of success on a single trial: \\(P(X = x_i)\\) (e.g., what’s the probability of flipping 8/10 heads with a fair coin?)\n\n\n\n\npbinom(): the (cumulative) probability distribution gives you the cumulative probability of getting a maximum of \\(x_i\\) successes: \\(P(X \\le x_i)\\) (e.g., getting 5 or fewer heads out of 10 flips).\nqbinom(): the quantile function gives you the number of success (x-axis) corresponding to a given cumulative probability: \\(X(P = P_i)\\) (e.g., A maximum of how many heads do you have to expect if you want at least an event probability of 25%?). This is the inverse function of pbinom().\n\nNote: Be aware of the difference between success probability \\(p\\), the probability of the density distribution \\(P(X = x_i)\\), and the probability of the cumulative probability distribution \\(P(X \\le x_i)\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat’s the probability of getting exactly 5 heads on 10 flips?\nWhat’s the probability of getting 0 to 2 heads on 10 flips?\nWhat’s the probability of getting at least 8 heads on 10 flips?",
    "crumbs": [
      "05 Probability"
    ]
  },
  {
    "objectID": "W5_Probability.html#using-the-binomial-distribution-2",
    "href": "W5_Probability.html#using-the-binomial-distribution-2",
    "title": "05 Probability",
    "section": "Using the Binomial Distribution 2",
    "text": "Using the Binomial Distribution 2\nNow in R:\n\nWhat’s the probability of getting exactly 5 heads on 10 flips?\nWhat’s the probability of getting 0 to 2 heads on 10 flips?\nWhat’s the probability of getting at least 8 heads on 10 flips?\n\n\n\n#1\ndbinom(x = 5, size = 10, prob = 0.5)\n\n[1] 0.2460938\n\n#2 (indirect way)\ndbinom(x = 0:2, size=10, prob=0.5) %&gt;% sum()\n\n[1] 0.0546875\n\n#2 (direct way)\npbinom(q = 2, size = 10, prob = 0.5) #P(X &lt;= q)\n\n[1] 0.0546875\n\n#3 (careful: minus 1)\npbinom(q = 8-1, size = 10, prob = 0.5, lower.tail = F) #P(X &gt; q) = 1 - P(X &lt;= q)\n\n[1] 0.0546875\n\n\n\n\nNote: The binomial distribution is only symmetrical for \\(p = 50\\%\\).\nThat’s why “a maximum of 2 heads” (0, 1, or 2) has the same probability as “at least 8 heads” (8, 9, or 10).\n\n\nx: the number of ‘heads’ of which we want to know the probability.\nsize: the number of trials (flips) we are simulating; in this case, 10 flips.\nprob: the probability of ‘heads’ on one trial. 50% far a fair coin.",
    "crumbs": [
      "05 Probability"
    ]
  },
  {
    "objectID": "W5_Probability.html#using-the-binomial-distribution-3",
    "href": "W5_Probability.html#using-the-binomial-distribution-3",
    "title": "05 Probability",
    "section": "Using the Binomial Distribution 3",
    "text": "Using the Binomial Distribution 3\nNow let’s use the quantile function qbinom()!\nImagine a friend wants to bet you on tossing a coin and bets that it will be tails. You suspect she has a coin that is not fair and it will be more likely that it turns up as tails.\nYour friend agrees that you can toss the coin 10 times to test it before you have to give your bet.\nyou want to find out whether the coin is fair and ask yourself: What is the minimum number of heads that is acceptable if it is fair?\nWe choose a probability so low that it is unlikely to get a result lower than that if the coin was fair. We will use a typical value for statistical significance: 0.05 (or in 5% of cases we will find a lower value by chance if the coin was fair).\n\n\nqbinom(p = .05, size = 10, prob = .5)\n\n[1] 2\n\n\nIn this case, the probability of success is now called prob because p is now used for the probability cut-off we want to set. This is unnecessarily confusing :(\n\n\nIf we run the code, we get a value of 2. This means that 2 heads is the first time that the cumulative probability function reaches at least 5% . Thus, if we get less than two heads out of the ten tosses, we could conclude that the coin is likely biased (there is only a 5% chance that this would happen if the coin was fair). You would probably not bet with your friend!\n\n\nNote: This is a bad way to test the fairness of a coin (it’s just for illustration of qbinom)! Rather demand that you win at tails (if the coin is fair, your friend shouldn’t mind).",
    "crumbs": [
      "05 Probability"
    ]
  },
  {
    "objectID": "W5_Probability.html#using-the-normal-distribution",
    "href": "W5_Probability.html#using-the-normal-distribution",
    "title": "05 Probability",
    "section": "Using the Normal Distribution",
    "text": "Using the Normal Distribution\nFor every probability distribution, R provides similar functions starting with d, p, or q. For the normal distribution, those are:\n\ndnorm(): density function, for calculating the density (not probability!) of a specific value. Only useful for plotting.\npnorm(): cumulative probability or distribution function, for calculating the probability of getting at least (or at most) a specific value.\nqnorm(): quantile function, for calculating the specific value associated with a given cumulative probability.\n\n\nFor the next activities, we will use means and SDs of height from the Scottish Health Survey (2008).",
    "crumbs": [
      "05 Probability"
    ]
  },
  {
    "objectID": "W5_Probability.html#using-the-normal-distribution-2",
    "href": "W5_Probability.html#using-the-normal-distribution-2",
    "title": "05 Probability",
    "section": "Using the Normal Distribution 2",
    "text": "Using the Normal Distribution 2\nCalculate the probability of meeting a Scottish woman who is as tall or taller than the average Scottish man.\nWhich function would you use?\nHint: You want to know how likely it is that you get a value as extreme or extremer than a specific value (the average height of men) within the distribution for women.\nWhat we know:\n\naverage female height = 163.8, SD = 6.931\naverage male height = 176.2, SD = 6.748\nWe want to know “at least as tall as”\n\n\nWe need the pnorm() function. Fill in the values instead of the NULLs.\n\npnorm(q = NULL, mean = NULL, sd = NULL, lower.tail = NULL)\n\n\n\n\npnorm(q = 176.2, mean = 163.8, sd = 6.931, lower.tail = FALSE)\n\n[1] 0.03680228\n\n\n\n\nNote: For continuous distributions, we don’t have to distinguish between “taller than” and “at least as tall”. \\(P(X \\le x_i) = P(X &lt; x_i)\\)! (Because the probability of one specific value like 176.2000000 m is exactly 0)\n\n\nAlso note: The SD of the distribution of males is not relevant for this question.\n\nDon’t do this:\n\npnorm(q = 176.2, mean = 163.8, sd = 6.931, lower.tail = F) + \n  dnorm(x = 176.2, mean = 163.8, sd = 6.931)\n\n[1] 0.04841892\n\n\nYou cannot add a probability and a density together! Just pnorm(q = 176.2, mean = 163.8, sd = 6.931, lower.tail = F) is the correct answer!\nWhen we say “What’s the probability of a woman being 1.80 m tall?”, we actually mean: “What’s the probability of a person being between 1.795 and 1.805 m tall?” (since height is usually measured within steps of 1 cm). We can calculate this, e.g. for Scottish women, using: pnorm(q = 180 + c(-.5, .5), mean = 163.8, sd = 6.931) %&gt;% diff() = 0.3%",
    "crumbs": [
      "05 Probability"
    ]
  },
  {
    "objectID": "W5_Probability.html#using-the-normal-distribution-3",
    "href": "W5_Probability.html#using-the-normal-distribution-3",
    "title": "05 Probability",
    "section": "Using the Normal Distribution 3",
    "text": "Using the Normal Distribution 3\nFiona is a very tall Scottish woman (181.12 cm) who will only date men who are as tall or taller than her. What is the probability of Fiona finding a taller man?\nWhat we know:\n\naverage female height = 163.8, SD = 6.931\naverage male height = 176.2, SD = 6.748\nWe want to know “tall or taller”\nFiona’s height = 181.12\n\n\n\npnorm(q = 181.12, mean = 176.2, sd = 6.748, lower.tail = FALSE)\n\n[1] 0.2329687\n\n\n\n\nConclusion: Fiona shrinks her dating pool to roughly a quarter and may thus consider abandoning beauty standards imposed by society. (Same advice for men, of course)\n\n\n\n\nHow tall would a Scottish man have to be in order to be in the tallest 5% of the height distribution for Scottish men?\n\n\n\nqnorm(p = .05, mean = 176.2, sd = 6.748, lower.tail = FALSE)\n\n[1] 187.2995",
    "crumbs": [
      "05 Probability"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#accessing-variablescolumns",
    "href": "W3_DataWranglingR.html#accessing-variablescolumns",
    "title": "03 Data Wrangling",
    "section": "Accessing Variables/Columns",
    "text": "Accessing Variables/Columns\nWhen wrangling your data in R, you often want to access/use different columns, e.g. to calculate new ones. There are a number of ways you can do that:\n\n# create a small data set for this example:\ntestdata &lt;- data.frame(a = c(1, 2, 3),  # c() creates a vector!\n                       b = c(\"a\", \"b\", \"c\"),\n                       c = c(4, 5, 6),\n                       d = c(7, 8, 9),\n                       e = c(10, 11, 12))\n\nprint(testdata)\n\n  a b c d  e\n1 1 a 4 7 10\n2 2 b 5 8 11\n3 3 c 6 9 12\n\nstr(testdata)\n\n'data.frame':   3 obs. of  5 variables:\n $ a: num  1 2 3\n $ b: chr  \"a\" \"b\" \"c\"\n $ c: num  4 5 6\n $ d: num  7 8 9\n $ e: num  10 11 12\n\n\n\ndata.frame() = function to create a data.frame, which is what holds a data set! (tibbles..)\nc() = function to make a vector. A vector is just like one single column of a data frame: It can hold several values, but all of the same type.",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#accessing-variablescolumns-2",
    "href": "W3_DataWranglingR.html#accessing-variablescolumns-2",
    "title": "03 Data Wrangling",
    "section": "Accessing Variables/Columns 2",
    "text": "Accessing Variables/Columns 2\nWhen wrangling your data in R, you often want to access/use different columns, e.g. to calculate new ones. There are a number of ways you can do that:\n\n# in baseR, we access elements of a data.frame with square brackets\ntestdata[1, 2] # get cell that is in first row and second column\n\n[1] \"a\"\n\ntestdata[1:2, 4:5] # use a colon to create ranges of values: first two rows and column numbers 4 and 5\n\n  d  e\n1 7 10\n2 8 11\n\n# we can leave one part empty to select ALL available columns/rows\ntestdata[1:2, ] # first two rows, all columns\n\n  a b c d  e\n1 1 a 4 7 10\n2 2 b 5 8 11\n\ntestdata[, 4:5] # columns number 4 and 5, all rows\n\n  d  e\n1 7 10\n2 8 11\n3 9 12\n\n\n\nsubsetting: rows, columns –&gt; leave empty!\nSelect range!\nUse either name or index of column!",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#accessing-variablescolumns-3",
    "href": "W3_DataWranglingR.html#accessing-variablescolumns-3",
    "title": "03 Data Wrangling",
    "section": "Accessing Variables/Columns 3",
    "text": "Accessing Variables/Columns 3\nWhen wrangling your data in R, you often want to access/use different columns, e.g. to calculate new ones. There are a number of ways you can do that:\n\n# it is usually better to access columns by their column name:\ntestdata[c(\"d\", \"e\")] # columns with names \"d\" and \"e\", all rows\n\n  d  e\n1 7 10\n2 8 11\n3 9 12\n\n# access a column only:\ntestdata[[\"a\"]] # double square brackets to get a vector (not a data.frame)\n\n[1] 1 2 3\n\ntestdata$a # short notation to get column \"a\" as a vector\n\n[1] 1 2 3\n\n\n\nbetter avoid the comma when accessing by column name:\n\n\n  a b\n1 1 a\n2 2 b\n3 3 c\n\n\n[1] 1 2 3\n\n\n  a b\n1 1 a\n2 2 b\n3 3 c\n\n\n  a\n1 1\n2 2\n3 3\n\n\n[1] 1 2 3\n\n\n=&gt; consistent data format without leading comma",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#accessing-variablescolumns-4",
    "href": "W3_DataWranglingR.html#accessing-variablescolumns-4",
    "title": "03 Data Wrangling",
    "section": "Accessing Variables/Columns 4",
    "text": "Accessing Variables/Columns 4\nWhen wrangling your data in R, you often want to access/use different columns, e.g. to calculate new ones. There are a number of ways you can do that:\n\n# tidy versions (see next slides)\nlibrary(tidyverse) # load tidyverse (if not already done)\npull(testdata, a) # same as testdata$a but can be used better in pipes (see next slide)\n\n[1] 1 2 3\n\nselect(testdata, a, b) # get column(s) as a data.frame; no c() needed!\n\n  a b\n1 1 a\n2 2 b\n3 3 c",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#tidyverse-2",
    "href": "W3_DataWranglingR.html#tidyverse-2",
    "title": "03 Data Wrangling",
    "section": "Tidyverse 2",
    "text": "Tidyverse 2\nBase R:\noutput_data1 &lt;- function1(data)\noutput_data2 &lt;- function2(output_data1, param1)\noutput_data3 &lt;- function3(output_data2, param2, param3)\n\nOr:\noutput_data &lt;- function3(function2(function1(data), param1), param2, param3)\n\n\nTidyverse:\noutput_data &lt;- data %&gt;% function1() %&gt;% function2(param1) %&gt;% function3(param2, param3)\n\n\nYou can insert a pipe %&gt;% (including spaces) by pressing Ctrl + Shift + M\n\n\nThe shortcut for the pipe (and other useful things like the assignment operator) can be adjusted in Tools -&gt; Modify Keyboard Shortcuts...\n\n\n\n%&gt;% is called the pipe. It takes the output of whatever happens to its left and “hands it over” to the right.\nSince R 4.1.0, there’s also a new base-R-pipe: |&gt;. It is very similar, but has a slightly limited functionality (see here).",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#tidyverse-3",
    "href": "W3_DataWranglingR.html#tidyverse-3",
    "title": "03 Data Wrangling",
    "section": "Tidyverse 3",
    "text": "Tidyverse 3\nlibrary(tidyverse) will load a number of packages, such as dplyr, ggplot2, readr, forcats, tibble etc., which are all usefuls for data wrangling.\nWe will work mainly with functions from the dplyr package, but also use readr to read in data. We will also use ggplot2 to visualize data.\nThe most important dplyr functions for data wrangling are:\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nselect()\nInclude or exclude certain columns (variables)\n\n\nfilter()\nInclude or exclude certain rows (observations)\n\n\nmutate()\nCreate new columns (variables)\n\n\nsummarize()\nCreate new columns that aggregate data/create summary variables for groups of observations (data frame will become smaller)\n\n\ngroup_by()\nOrganize the rows (observations) into groups\n\n\narrange()\nChange the order of rows (observations)\n\n\n\n\nfunction names very self-explanatory!\nWe don’t create new observations in R - this is job of the data acquisition - we just read the existing data",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#setting-up-libraries",
    "href": "W3_DataWranglingR.html#setting-up-libraries",
    "title": "03 Data Wrangling",
    "section": "Setting up libraries",
    "text": "Setting up libraries\n\nOpen your Biostats R project.\nCreate a new R script and save it, e.g. as “DataWrangling1.R”.\nInsert code to make sure the packages “tidyverse” and “babynames” are installed and loaded.\n\n\n\n# install.packages(\"tidyverse\")\n# install.packages(\"babynames\")\n\nlibrary(babynames)\nlibrary(tidyverse)\n\n\nload tidyverse last, otherwise functions with same name will be masked from package that is loaded first. Since we often need tidyverse functions, it’s safest to load it last!",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#look-at-the-data",
    "href": "W3_DataWranglingR.html#look-at-the-data",
    "title": "03 Data Wrangling",
    "section": "Look at the Data",
    "text": "Look at the Data\n\nType the word babynames into your console pane and press enter. What kind of information do you get?\n\n“A tibble: 1,924,665 x 5”\n\ntibble is an extension of the data.frame with more convenient output (e.g., values rounded to significant digits)\n~1.9 million rows/observations\n5 columns/variables\n\n\nWhat kind of columns/variables do we have?\n\ndbl = double/numeric (can take decimals)\nchr = character/string (letters or words)\nint = integer (only whole numbers)\n\n\n\nask first for 1 and 2",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#selecting-variables-of-interest",
    "href": "W3_DataWranglingR.html#selecting-variables-of-interest",
    "title": "03 Data Wrangling",
    "section": "Selecting Variables of Interest",
    "text": "Selecting Variables of Interest\nUse select() to choose only the columns year, sex, name, and prop and store it as a new tibble called babynames_reduced.\nRemember that you can run ?select in the console if you need help about, e.g., input/arguments to the function.\n\n\n# my favorite:\nbabynames_reduced &lt;- \n  babynames %&gt;% \n  select(year, sex, name, prop)\n\n# or alternatively:\nbabynames_reduced &lt;- \n  babynames %&gt;% \n  select(-n) # remove columns by using -\n\nRemoving columns vs. selecting columns: Results may change if the data get updated!\n\n\nSimilar to optional spaces for better readability, R allows for optional line breakes. You can try out what works best for you or look up some style guides.\n\n\n\nIt is encouraged to use many line breakes for better readability. Check out the Tidyverse Style Guide for suggestions.",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#arranging-data",
    "href": "W3_DataWranglingR.html#arranging-data",
    "title": "03 Data Wrangling",
    "section": "Arranging Data",
    "text": "Arranging Data\nChange the order of the data (oberservations/rows)!\n\nUsing arrange(), try sorting the data according to the names column. What happens?\nHow can you sort a column in a descending fashion? Check out the help file (?arrange).\nLet’s sort by year descendingly and within each year, sort names alphabetically.\n\n\n\nsort_asc &lt;- babynames %&gt;% arrange(name)\n\nsort_desc &lt;- babynames %&gt;% arrange(desc(year)) \n\nbabynames %&gt;% arrange(desc(year), name) \n\n# A tibble: 1,924,665 × 5\n    year sex   name          n       prop\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;      &lt;dbl&gt;\n 1  2017 M     Aaban        11 0.0000056 \n 2  2017 F     Aabriella     6 0.0000032 \n 3  2017 M     Aadam        18 0.00000917\n 4  2017 M     Aadan         8 0.00000407\n 5  2017 M     Aadarsh      15 0.00000764\n 6  2017 M     Aaden       240 0.000122  \n 7  2017 M     Aadesh        7 0.00000357\n 8  2017 M     Aadhav       31 0.0000158 \n 9  2017 M     Aadhavan      6 0.00000306\n10  2017 M     Aadhi        10 0.00000509\n# ℹ 1,924,655 more rows\n\n\n\nremember to save data in new tibble/data frame!",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#filter-observations",
    "href": "W3_DataWranglingR.html#filter-observations",
    "title": "03 Data Wrangling",
    "section": "Filter Observations",
    "text": "Filter Observations\nWe have already used select() to keep only certain variables (columns), but often we also want to keep only certain observations (rows), e.g. babies born in the year 2000 and later.\nWe use the function filter() for this.\n\nLook at the following code and think about what it might do.\n\nbabynames %&gt;% \n  filter(year &gt; 2000)\n\n\n\n\n\n# A tibble: 562,156 × 5\n    year sex   name          n    prop\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;   &lt;dbl&gt;\n 1  2001 F     Emily     25055 0.0127 \n 2  2001 F     Madison   22164 0.0112 \n 3  2001 F     Hannah    20712 0.0105 \n 4  2001 F     Ashley    16526 0.00835\n 5  2001 F     Alexis    16401 0.00828\n 6  2001 F     Sarah     15896 0.00803\n 7  2001 F     Samantha  15862 0.00801\n 8  2001 F     Abigail   14807 0.00748\n 9  2001 F     Elizabeth 14784 0.00747\n10  2001 F     Olivia    13978 0.00706\n# ℹ 562,146 more rows\n\n\nThe data starts at 2001! :(",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#boolean-expressions",
    "href": "W3_DataWranglingR.html#boolean-expressions",
    "title": "03 Data Wrangling",
    "section": "Boolean Expressions",
    "text": "Boolean Expressions\nThe second argument, year &gt; 2000, is a Boolean or logical expression, which means that it results in a value of either TRUE or FALSE. filter() runs this expression and then removes all values/rows that contain FALSE.",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#boolean-expressions-2",
    "href": "W3_DataWranglingR.html#boolean-expressions-2",
    "title": "03 Data Wrangling",
    "section": "Boolean Expressions 2",
    "text": "Boolean Expressions 2\n\nBoolean expressions\n\n\n\n\n\n\n\nOperator\nName\nis TRUE if and only if\n\n\n\n\nA &lt; B\nless than\nA is less than B\n\n\nA &lt;= B\nless than or equal\nA is less than or equal to B\n\n\nA &gt; B\ngreater than\nA is greater than B\n\n\nA &gt;= B\ngreater than or equal\nA is greater than or equal to B\n\n\nA == B\nequivalence\nA exactly equals B\n\n\nA != B\nnot equal\nA does not exactly equal B\n\n\nA %in% B\nin\nA is an element of vector B\n\n\n\n\n\nA double equality sign == is a comparison, a single equals = is a variable or parameter assignment.\nThis is why R users like to make the distinction even bigger by using &lt;- for variable assignment (your environment in the top right pane) and = for parameter assignment in functions (a hidden so-called local environment only visible to the function).\nAlso, there are slight differences between &lt;- and = for variable assignment, see here.",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#filter-some-more-1",
    "href": "W3_DataWranglingR.html#filter-some-more-1",
    "title": "03 Data Wrangling",
    "section": "Filter some more 1",
    "text": "Filter some more 1\n\nKeep only those observations with the name “Mary”.\nDiscard all observations with name “Mary” and keep only those from year &gt; 2000.\nKeep only those with names of former Queens (Mary, Elizabeth, Victoria).\nDiscard the ones with the Queen names!\n\n\nFirst task:\n\nmarys &lt;- \n  babynames %&gt;% \n  filter(name == \"Mary\")",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#filter-some-more-2",
    "href": "W3_DataWranglingR.html#filter-some-more-2",
    "title": "03 Data Wrangling",
    "section": "Filter some more 2",
    "text": "Filter some more 2\n\nKeep only those observations with the name “Mary”.\nDiscard all observations with name “Mary” and keep only those from year &gt; 2000.\nKeep only those with names of former Queens (Mary, Elizabeth, Victoria).\nDiscard the ones with the Queen names!\n\nSecond task:\nThis might be difficult because you have two expressions, name != \"Mary\" and year &gt; 2000. You can simply add several expressions separated by commas in filter (commas are treated like a “logical and” &):\n\nno_marys_young &lt;- \n  babynames %&gt;% \n  filter(name != \"Mary\", year &gt; 2000)",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#filter-some-more-3",
    "href": "W3_DataWranglingR.html#filter-some-more-3",
    "title": "03 Data Wrangling",
    "section": "Filter some more 3",
    "text": "Filter some more 3\n\nKeep only those observations with the name “Mary”.\nDiscard all observations with name “Mary” and keep only those from year &gt; 2000.\nKeep only those with names of former Queens (Mary, Elizabeth, Victoria).\nDiscard the ones with the Queen names!\n\nThird task:\n\nqueens &lt;- \n  babynames %&gt;% \n  filter(\n    name == \"Mary\" | # the vertical line is a logical OR\n    name == \"Elizabeth\" | \n    name == \"Victoria\"\n  ) \n\n\nA better shorthand exists with the operator %in%:\n\nqueens &lt;- \n  babynames %&gt;% \n  filter(name %in% c(\"Mary\", \"Elizabeth\", \"Victoria\"))",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#filter-some-more-4",
    "href": "W3_DataWranglingR.html#filter-some-more-4",
    "title": "03 Data Wrangling",
    "section": "Filter some more 4",
    "text": "Filter some more 4\n\nKeep only those observations with the name “Mary”.\nDiscard all observations with name “Mary” and keep only those from year &gt; 2000.\nKeep only those with names of former Queens (Mary, Elizabeth, Victoria).\nDiscard the ones with the Queen names!\n\nFourth task:\nThis is very tricky! You could use three filters in a row with:\nname != \"Mary\", name != \"Elizabeth\", name != \"Victoria\".\nThere is no function “not in” but you can negate the result in two ways:\n\nno_queens &lt;- \n  babynames %&gt;% \n  filter(!name %in% c(\"Mary\", \"Elizabeth\", \"Victoria\")) # ! is a negation (\"not\")\n\nno_queens &lt;- \n  babynames %&gt;% \n  filter(name %in% c(\"Mary\", \"Elizabeth\", \"Victoria\") == FALSE)\n\n\nCareful with precedence! %in% is evaluated before !:\n!(name %in% c(\"Mary\", \"Elizabeth\", \"Victoria\"))\n=&gt; I prefer to add == FALSE in the end",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#your-first-plot",
    "href": "W3_DataWranglingR.html#your-first-plot",
    "title": "03 Data Wrangling",
    "section": "Your First Plot",
    "text": "Your First Plot\nIn your script, insert and run the following code:\n\nbabynames %&gt;% \n  filter(\n    sex == \"F\", # only female babies\n    name %in% c(\"Emily\", \"Kathleen\", \"Alexandra\", \"Beverly\") # reduce to these 4 names\n  ) %&gt;% \n  ggplot(aes(x = year, y = prop, colour = name)) +\n  geom_line(linewidth = 2) # plot data as a line (with increased size)\n\n\n\nAlter the code to check for male babies with the same names (change sex == \"F\" to sex == \"M\").\nOptional: Plot the absolute number n instead of the relative proportion prop.",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#create-new-variables",
    "href": "W3_DataWranglingR.html#create-new-variables",
    "title": "03 Data Wrangling",
    "section": "Create New Variables",
    "text": "Create New Variables\nIf we want to create variables that do not exist yet (i.e. by calculating values, combining other variables, etc.), we can use mutate()!\n\nAdd a variable called “country” that contains the value “USA” for all observations\n\n\n\nbaby_where &lt;- \n  babynames %&gt;% \n  mutate(country = \"USA\")\n\n\n\nBut mutate is much more powerful and can create variables that differ per observation, depending on other values in the tibble/data frame:",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#create-new-variables-2",
    "href": "W3_DataWranglingR.html#create-new-variables-2",
    "title": "03 Data Wrangling",
    "section": "Create New Variables 2",
    "text": "Create New Variables 2\n\nCreate a variable that denotes the decade a baby was born:\n\n\n\n# we can only use floor to round down to full numbers =&gt; divide year by 10, floor it, and then multiply by 10 again\nbaby_decades &lt;- \n  babynames %&gt;% \n  mutate(decade = floor(year / 10) * 10) # round(year, -1) works but not floor(year, -1) :(\n\n\n\n# A tibble: 10 × 2\n    year decade\n   &lt;dbl&gt;  &lt;dbl&gt;\n 1  1900   1900\n 2  1914   1910\n 3  1931   1930\n 4  1943   1940\n 5  1946   1940\n 6  1949   1940\n 7  1952   1950\n 8  1964   1960\n 9  1988   1980\n10  2017   2010",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#summarizing",
    "href": "W3_DataWranglingR.html#summarizing",
    "title": "03 Data Wrangling",
    "section": "Summarizing",
    "text": "Summarizing\nThe goal of data wrangling is often to summarize (or aggregate) the data, e.g. to have an average value per condition. Sometimes you’d also want to calculate descriptive statistics to report.\n\nYou can do so using the function summarize():\n\n# run the filter function just like above again:\ndat &lt;- \n  babynames %&gt;% \n  filter(\n    name %in% c(\"Emily\", \"Kathleen\", \"Alexandra\", \"Beverly\"), \n    sex == \"F\"\n  )\n\n# summarize the data, calculating the number of oberservations:\ndat_sum &lt;- dat %&gt;% summarize(total = sum(n))\ndat_sum\n\n# A tibble: 1 × 1\n    total\n    &lt;int&gt;\n1 2161374",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#summarizing-2",
    "href": "W3_DataWranglingR.html#summarizing-2",
    "title": "03 Data Wrangling",
    "section": "Summarizing 2",
    "text": "Summarizing 2\n\ndat_sum\n\n# A tibble: 1 × 1\n    total\n    &lt;int&gt;\n1 2161374\n\n\nAs you can see, a new variable named total is created, which contains the total number of observations (in this case, it is different from the number of rows because each row already contains a count n).\nThere’s just one row in the resulting data frame, because summarize() reduces the data frame (to only include the necessary information)!",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#grouping-and-summarizing",
    "href": "W3_DataWranglingR.html#grouping-and-summarizing",
    "title": "03 Data Wrangling",
    "section": "Grouping and Summarizing",
    "text": "Grouping and Summarizing\nOften, we want to summarize data for specific subgroups. For this aim, summarize() has the .by parameter:\n\ngroup_sum &lt;- \n  dat %&gt;% \n  summarize(total = sum(n), .by = name) \n\ngroup_sum\n\n# A tibble: 4 × 2\n  name       total\n  &lt;chr&gt;      &lt;int&gt;\n1 Emily     841491\n2 Kathleen  711605\n3 Beverly   376914\n4 Alexandra 231364",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#grouping-and-summarizing-2",
    "href": "W3_DataWranglingR.html#grouping-and-summarizing-2",
    "title": "03 Data Wrangling",
    "section": "Grouping and Summarizing 2",
    "text": "Grouping and Summarizing 2\nYou can also subgroup by a combination of variables:\n\nbabynames %&gt;% \n  filter(name %in% c(\"Emily\", \"Kathleen\", \"Alexandra\", \"Beverly\")) %&gt;% # we start with the 4 names regardless of sex\n  summarize(\n    total = sum(n),\n    .by = c(name, sex) # and then summarize by name, separated for sex\n  )\n\n# A tibble: 8 × 3\n  name      sex    total\n  &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;\n1 Emily     F     841491\n2 Kathleen  F     711605\n3 Beverly   M       4633\n4 Beverly   F     376914\n5 Alexandra F     231364\n6 Emily     M       1744\n7 Kathleen  M       1692\n8 Alexandra M        859",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#grouping-and-summarizing-3",
    "href": "W3_DataWranglingR.html#grouping-and-summarizing-3",
    "title": "03 Data Wrangling",
    "section": "Grouping and Summarizing 3",
    "text": "Grouping and Summarizing 3\nIn earlier versions, we had to use summarize() together with group_by():\n\ngroup_sum &lt;- dat %&gt;% group_by(name) %&gt;% summarize(total = sum(n)) \n\nWe avoid using group_by() like this because it can have unintended side effects.\nIt is just part of this class because you will likely encounter it in somebody else’s (old) code.\n\nIf you do have to use it, make sure to ungroup() after summarize() (or mutate()) to avoid unintended effects:\n\ngroup_sum &lt;- dat %&gt;% group_by(name) %&gt;% summarize(total = sum(n)) %&gt;% ungroup()\ngroup_sum &lt;- dat %&gt;% group_by(name) %&gt;% summarize(total = sum(n), .groups = \"drop\")\n\n\nUnintended side effects: grouping stays active and affects future calls to summarize or mutate, which may be hundreds of lines of code away!\n=&gt; Fatal when, e.g., calculating z-scores after having summarized the trial-level data into subject-level averages.",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#grouping-and-summarizing-4",
    "href": "W3_DataWranglingR.html#grouping-and-summarizing-4",
    "title": "03 Data Wrangling",
    "section": "Grouping and Summarizing 4",
    "text": "Grouping and Summarizing 4\nUse the baby_decades data frame to calculate the mean and median number of observations, grouped by sex & decade.\n\n\nbaby_decades %&gt;% \n  summarize(\n    mean_year = mean(n),\n    median_year = median(n),\n    .by = c(sex, decade)\n  )\n\n# A tibble: 28 × 4\n   sex   decade mean_year median_year\n   &lt;chr&gt;  &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n 1 F       1880     111.           13\n 2 M       1880     101.           12\n 3 F       1890     128.           13\n 4 M       1890      93.6          12\n 5 F       1900     131.           12\n 6 M       1900      94.4          12\n 7 F       1910     187.           12\n 8 M       1910     181.           12\n 9 F       1920     211.           12\n10 M       1920     227.           13\n# ℹ 18 more rows",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#counting-data",
    "href": "W3_DataWranglingR.html#counting-data",
    "title": "03 Data Wrangling",
    "section": "Counting Data",
    "text": "Counting Data\nThere are several ways to get the number of rows per group. You can use the function n() within a call to summarize() (or mutate()). A shortcut is to use count():\n\ndat %&gt;% summarize(n = n(), .by = name)\n\n# A tibble: 4 × 2\n  name          n\n  &lt;chr&gt;     &lt;int&gt;\n1 Emily       138\n2 Kathleen    138\n3 Beverly     122\n4 Alexandra   117\n\ndat %&gt;% count(name)\n\n# A tibble: 4 × 2\n  name          n\n  &lt;chr&gt;     &lt;int&gt;\n1 Alexandra   117\n2 Beverly     122\n3 Emily       138\n4 Kathleen    138\n\n\nInterestingly, the order of the output may vary. summarize() leaves the data in the original order (i.e., by prop, which (likely) translates to an order by n()). count() arranges the output by the variables for which the counting is done (here: alphabetically by name).",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#bigger-pipes",
    "href": "W3_DataWranglingR.html#bigger-pipes",
    "title": "03 Data Wrangling",
    "section": "Bigger Pipes!",
    "text": "Bigger Pipes!\nSo far we have often saved intermediate steps in tibbles and used those as input for the next function. With the pipe, we can chain several functions and save relevant results only, no need for crowding the environment with intermediate data.frames or tibbles!\n\npipe_summary &lt;- \n  babynames %&gt;%\n  mutate(decade = floor(year / 10) * 10) %&gt;%\n  filter(\n    name %in% c(\"Emily\", \"Kathleen\", \"Alexandra\", \"Beverly\"),\n    sex == \"F\"\n  ) %&gt;%\n  summarize(\n    mean_decade = mean(n),\n    .by = c(name, decade)\n  )\n\nIt’s not easy to decide which intermediate steps to save and which not. Usually, it involves some sort of trial and error. Sometimes you go back and break a pipe apart. Sometimes you get overwhelmed by the number of variables in your environment and create bigger pipes.\nAs a rule of thumb: If an intermediate step is only used once, you should probably delete it (unless it makes the code easier to comprehend).",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#tidy-data",
    "href": "W3_DataWranglingR.html#tidy-data",
    "title": "03 Data Wrangling",
    "section": "Tidy Data",
    "text": "Tidy Data\nTidy data: Data that is easily processed by tidyverse functions (also for visualizations and statistical analyses).\nThree principles:\n\nEach variable has its own column.\nEach observation has its own row.\nEach value has its own cell.",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#tidy-data-wide-vs.-long-format",
    "href": "W3_DataWranglingR.html#tidy-data-wide-vs.-long-format",
    "title": "03 Data Wrangling",
    "section": "Tidy Data: wide vs. long format",
    "text": "Tidy Data: wide vs. long format\n\n\nWide format: Each participant/animal has one row;\nrepeated observations are in several columns\n\n\n\nID\nTime_1\nTime_2\n\n\n\n\na1\n230\n310\n\n\na2\n195\n220\n\n\na3\n245\n290\n\n\n\n\nLong format: Each observation has its own row;\nthere are (usually) several rows per participant\n\n\n\nID\nTime\nValue\n\n\n\n\na1\n1\n230\n\n\na1\n2\n310\n\n\na2\n1\n195\n\n\na3\n2\n220\n\n\na3\n1\n245\n\n\na3\n2\n290\n\n\n\n\n\nWide format implements a sparser representation of the data but less tidy!\nIf you want to convert Time from milliseconds into seconds, what do you have to do in both formats?\n\nData often does not come in this format but is rather messy! That’s why we wrangle.\nTidy data is in between wide and long (you can always go longer! :D)",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#tidy-data-2",
    "href": "W3_DataWranglingR.html#tidy-data-2",
    "title": "03 Data Wrangling",
    "section": "Tidy Data 2",
    "text": "Tidy Data 2\nWhat do you think, which of the following data sets is tidy?\n1:\n\n\n# A tibble: 12 × 4\n   country      year type            count\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;\n 1 Afghanistan  1999 cases             745\n 2 Afghanistan  1999 population   19987071\n 3 Afghanistan  2000 cases            2666\n 4 Afghanistan  2000 population   20595360\n 5 Brazil       1999 cases           37737\n 6 Brazil       1999 population  172006362\n 7 Brazil       2000 cases           80488\n 8 Brazil       2000 population  174504898\n 9 China        1999 cases          212258\n10 China        1999 population 1272915272\n11 China        2000 cases          213766\n12 China        2000 population 1280428583\n\n\n2:\n\n\n# A tibble: 6 × 4\n  country      year  cases population\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\n\n3:\n\n\n# A tibble: 6 × 3\n  country      year rate             \n  &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;            \n1 Afghanistan  1999 745/19987071     \n2 Afghanistan  2000 2666/20595360    \n3 Brazil       1999 37737/172006362  \n4 Brazil       2000 80488/174504898  \n5 China        1999 212258/1272915272\n6 China        2000 213766/1280428583\n\n\n4:\n\n\n# A tibble: 3 × 5\n  country     `1999_cases` `2000_cases` `1999_population` `2000_population`\n  &lt;chr&gt;              &lt;dbl&gt;        &lt;dbl&gt;             &lt;dbl&gt;             &lt;dbl&gt;\n1 Afghanistan          745         2666          19987071          20595360\n2 Brazil             37737        80488         172006362         174504898\n3 China             212258       213766        1272915272        1280428583\n\n\n\n\nThe second table is the tidyest!\nTable 1 has cases and population mixed together in count variable.\nTable 3 mixes them in an awkward character row rate.\nTable 4 is standard wide format.",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#analyzing-the-autism-spectrum-quotient",
    "href": "W3_DataWranglingR.html#analyzing-the-autism-spectrum-quotient",
    "title": "03 Data Wrangling",
    "section": "Analyzing the Autism Spectrum Quotient",
    "text": "Analyzing the Autism Spectrum Quotient\nFor the following activities, we will need the following files:\n\nresponses.csv containing the AQ survey responses to each of the 10 questions for the 66 participants\nqformats.csv containing information on how a question should be coded - i.e. forward or reverse coding\nscoring.csv containing information on how many points a specific response should get; depending on whether it is forward or reverse coded\npinfo.csv containing participant information such as Age, Sex and importantly ID number.",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#set-up",
    "href": "W3_DataWranglingR.html#set-up",
    "title": "03 Data Wrangling",
    "section": "Set Up",
    "text": "Set Up\n\nCreate a new script, e.g. as “DataWrangling3.R” (remember we skipped #2 in the book).\nDownload the data into your project folder:\nresponses.csv\nqformats.csv\nscoring.csv\npinfo.csv\nClear your environment (the brush in the top right pane) and/or restart the R session (Session -&gt; Restart R).\nLoad the four .csv files into your environment, e.g.:\n\n\nlibrary(tidyverse)\nresponses &lt;- read_csv(\"responses.csv\") \nqformats &lt;- read_csv(\"qformats.csv\")\nscoring &lt;- read_csv(\"scoring.csv\")\npinfo &lt;- read_csv(\"pinfo.csv\")",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#look-at-the-data-1",
    "href": "W3_DataWranglingR.html#look-at-the-data-1",
    "title": "03 Data Wrangling",
    "section": "Look at the Data",
    "text": "Look at the Data\nIs the data (responses) in a tidy format?\n\n\n# A tibble: 6 × 11\n     Id Q1                 Q2    Q3    Q4    Q5    Q6    Q7    Q8    Q9    Q10  \n  &lt;dbl&gt; &lt;chr&gt;              &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1    16 Slightly Disagree  Defi… Slig… Defi… Slig… Slig… Slig… Defi… Slig… Slig…\n2    17 Definitely Agree   Slig… Slig… Defi… Defi… Defi… Slig… Slig… Slig… Slig…\n3    18 Definitely Agree   Defi… Slig… Defi… Defi… Defi… Slig… Defi… Defi… Defi…\n4    19 Definitely Agree   Defi… Defi… Slig… Defi… Defi… Slig… Slig… Defi… Slig…\n5    20 Definitely Disagr… Slig… Defi… Slig… Slig… Slig… Slig… Slig… Slig… Slig…\n6    21 Slightly Disagree  Slig… Defi… Slig… Slig… Slig… Defi… Defi… Slig… Slig…\n\n\n\nWhy is it not tidy?\n\nwide format",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#reformatting-the-data",
    "href": "W3_DataWranglingR.html#reformatting-the-data",
    "title": "03 Data Wrangling",
    "section": "Reformatting the Data",
    "text": "Reformatting the Data\nLet’s bring the wide data in a longer, tidy format!\n\nThere are several functions in R to reformat data, but the newest ones are pivot_longer() and pivot_wider().\nRun the code and see what changes:\n\nrlong &lt;- \n  responses %&gt;% \n  pivot_longer(\n    cols = Q1:Q10, # we can select a range of column names\n    # cols = starts_with(\"Q\"), # alternative\n    names_to = \"Question\", \n    values_to = \"Response\"\n  )\n\n\n\nDescribe what the function does, what does the input/the arguments mean?",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#joining-the-data",
    "href": "W3_DataWranglingR.html#joining-the-data",
    "title": "03 Data Wrangling",
    "section": "Joining the Data",
    "text": "Joining the Data\nWe now want to combine the different data sets: We want to have the information how the questionnaire has to be scored included with the items.\nWe can find the scoring information (i.e. how the questions are framed, positive or negative/whether they need to be reversed) in the qformats tibble. Furthermore, we can find how many points are given to each item/response in scoring.\nWe can use the function inner_join() to merge the tibbles into one bigger tibble.\n\nActivity: Replace the NULL values in the below code with the necessary variable names to join rlong and qformats by Question.\n\nrlong2 &lt;- \n  inner_join(x = NULL, y = NULL, by = \"NULL\")\n\n\n\n\nrlong2 &lt;- \n  inner_join(\n    x = rlong, \n    y = qformats, \n    by = \"Question\"\n  )\n\n\nDescribe what happened?\nwhat is forward and reverse scoring?",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#combining-more-data",
    "href": "W3_DataWranglingR.html#combining-more-data",
    "title": "03 Data Wrangling",
    "section": "Combining more Data",
    "text": "Combining more Data\nYou can only join two data frames/tibbles at once.\nNow add the scoring data:\n\nrscores &lt;- \n  rlong2 %&gt;% \n  inner_join(\n    scoring, \n    c(\"QFormat\", \"Response\")\n  )\n\n\nYou can also let the function figure out by itself which columns should be used for joining:\n\nrscores &lt;- inner_join(rlong2, scoring)\n\nJoining with `by = join_by(Response, QFormat)`\n\n\n\n\nAnd if you are happy with the result, copy the information into your code to make the join explicit:\n\nrscores &lt;- inner_join(rlong2, scoring, \n                      by = join_by(Response, QFormat)) #same as by = c(\"QFormat\", \"Response\")",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#calculate-the-questionnaire-scores",
    "href": "W3_DataWranglingR.html#calculate-the-questionnaire-scores",
    "title": "03 Data Wrangling",
    "section": "Calculate the Questionnaire Scores",
    "text": "Calculate the Questionnaire Scores\nHow do we need to group and summarize the data to get a sum score per person? (Ignoring the reverse coding for now!) Add the correct column names instead of the NULL.\n\naq_scores &lt;- \n  rscores %&gt;% \n  summarize(\n    AQ = sum(NULL), \n    .by = NULL\n  )\n\n\n\naq_scores &lt;- \n  rscores %&gt;% \n  summarize(\n    AQ = sum(Score), # sum column Score to obtain AQ scores.\n    .by = Id # separately for each Id (participant)\n  )",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#pipe-it-all-together",
    "href": "W3_DataWranglingR.html#pipe-it-all-together",
    "title": "03 Data Wrangling",
    "section": "Pipe it all together!",
    "text": "Pipe it all together!\n\naq_scores2 &lt;- \n  responses %&gt;% \n  pivot_longer(\n    cols = Q1:Q10,\n    names_to = \"Question\", \n    values_to = \"Response\"\n  ) %&gt;%  \n  inner_join(qformats, \"Question\") %&gt;% \n  inner_join(scoring, c(\"QFormat\", \"Response\")) %&gt;% \n  summarize(AQ = sum(Score), .by = Id)",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#background",
    "href": "W3_DataWranglingR.html#background",
    "title": "03 Data Wrangling",
    "section": "Background",
    "text": "Background\nWe’ll use data from a paper that investigates whether the ability to perform an action influences perception. In particular, the authors wondered whether participants who played Pong would perceive the ball to move faster when they have a small paddle.\n\nDownload the data, create a new script.\nClear the environment if you prefer.\nLook at the data.",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#solutions",
    "href": "W3_DataWranglingR.html#solutions",
    "title": "03 Data Wrangling",
    "section": "Solutions",
    "text": "Solutions\n\nlibrary(\"tidyverse\")\npong_data &lt;- read_csv(\"Data/PongBlueRedBack 1-16 Codebook.csv\") # I put the data into a separate subfolder \"Data\"\nsummary(pong_data)\n\n  Participant     JudgedSpeed      PaddleLength   BallSpeed    TrialNumber    \n Min.   : 1.00   Min.   :0.0000   Min.   : 50   Min.   :2.0   Min.   :  1.00  \n 1st Qu.: 4.75   1st Qu.:0.0000   1st Qu.: 50   1st Qu.:3.0   1st Qu.: 72.75  \n Median : 8.50   Median :1.0000   Median :150   Median :4.5   Median :144.50  \n Mean   : 8.50   Mean   :0.5471   Mean   :150   Mean   :4.5   Mean   :144.50  \n 3rd Qu.:12.25   3rd Qu.:1.0000   3rd Qu.:250   3rd Qu.:6.0   3rd Qu.:216.25  \n Max.   :16.00   Max.   :1.0000   Max.   :250   Max.   :7.0   Max.   :288.00  \n BackgroundColor      HitOrMiss       BlockNumber   \n Length:4608        Min.   :0.0000   Min.   : 1.00  \n Class :character   1st Qu.:0.0000   1st Qu.: 3.75  \n Mode  :character   Median :1.0000   Median : 6.50  \n                    Mean   :0.6866   Mean   : 6.50  \n                    3rd Qu.:1.0000   3rd Qu.: 9.25  \n                    Max.   :1.0000   Max.   :12.00  \n\n# look at the data (can also use summary(), str(), head() etc.)\nglimpse(pong_data)\n\nRows: 4,608\nColumns: 8\n$ Participant     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ JudgedSpeed     &lt;dbl&gt; 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, …\n$ PaddleLength    &lt;dbl&gt; 50, 250, 50, 250, 250, 50, 250, 50, 250, 50, 50, 250, …\n$ BallSpeed       &lt;dbl&gt; 5, 3, 4, 3, 7, 5, 6, 2, 4, 4, 7, 7, 3, 6, 5, 7, 2, 5, …\n$ TrialNumber     &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ BackgroundColor &lt;chr&gt; \"red\", \"blue\", \"red\", \"red\", \"blue\", \"blue\", \"red\", \"r…\n$ HitOrMiss       &lt;dbl&gt; 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, …\n$ BlockNumber     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#solutions-2",
    "href": "W3_DataWranglingR.html#solutions-2",
    "title": "03 Data Wrangling",
    "section": "Solutions 2",
    "text": "Solutions 2\n\nnew_pong_data &lt;- pong_data %&gt;% \n  select(BallSpeed, HitOrMiss, JudgedSpeed, Participant, TrialNumber) %&gt;% \n  arrange(desc(HitOrMiss), desc(JudgedSpeed)) %&gt;% \n  filter(\n    JudgedSpeed == 1,\n    BallSpeed %in% c(\"2\", \"4\", \"5\", \"7\"),\n    HitOrMiss == 0\n  ) %&gt;% \n  filter(TrialNumber &gt; 2) %&gt;% \n  mutate(TrialNumber = TrialNumber -1) \n  \n  # summarize (use old data frame because we removed variables)\npong_data_hits &lt;- \n  pong_data %&gt;% \n  summarize(\n    total_hits = sum(HitOrMiss, na.rm = TRUE),\n    meanhits = mean(HitOrMiss, na.rm = TRUE),\n    .by = c(BackgroundColor, PaddleLength)\n  )",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W1_Intro.html#hello",
    "href": "W1_Intro.html#hello",
    "title": "01a Introduction to Biostatistics",
    "section": "Hello!",
    "text": "Hello!\nWho am I?\n\nWho are you?\n\nWhat is your background?\nDo you have experience with data analysis?\nWhat’s your attitude towards statistics?",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#using-the-slides",
    "href": "W1_Intro.html#using-the-slides",
    "title": "01a Introduction to Biostatistics",
    "section": "Using the Slides",
    "text": "Using the Slides\n\nThese slides are created directly in R with the quarto extension.\nYou can jump to a slide by clicking the three dashes in the bottom left.\nYou can conveniently copy R code from the slides with one click and paste it into your RStudio.\n\n\nprint(\"Hello World\")\n\n[1] \"Hello World\"",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#organizational-issues",
    "href": "W1_Intro.html#organizational-issues",
    "title": "01a Introduction to Biostatistics",
    "section": "Organizational Issues",
    "text": "Organizational Issues\n\n\n\nAttendance is mandatory! (I don’t make the rules :) )\n\nYou may miss one session without giving reasons (recommendation: don’t waste it early!)\nIf you miss additional sessions, please write an email with an explanation (further proof may be required, e.g. doctor’s certificate)\n\n\n\n\n\nThe course will take place in person\n\nOnly for students who are not in Würzburg yet, there is the option to watch pre-recorded videos\n\n\n\n\n\nWe will use these textbooks (Open Educational Resources - freely available online, also linked on WueCampus):\n\nStatistical Thinking for the 21st Century\nFor the R part: Fundamentals of Quantitative Analysis\n(Additional Resource: R for Data Science)",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#contents",
    "href": "W1_Intro.html#contents",
    "title": "01a Introduction to Biostatistics",
    "section": "Contents",
    "text": "Contents\n\nFrom basic probability to (Generalized) Linear Mixed Models\n\nSome things may be repetitive for you but this course aims to provide a common starting position for your next semesters\n\nInput (lecture style) with hands-on R sessions \nIn addition, you should read a few pages in the text books\n(Statistical Thinking for the 21st Century, and possibly Fundamentals of Quantitative Analysis)\nProject: Independently analyze a dataset and hand in a report (exam with pass or fail grading)\n\n\nFor some, e.g. the psychologists, it will be more of a repetition - but you will also learn R.\nSlides might be text heavy → so that you can go through the slides afterwards again (but textbook might also be helpful)",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#project",
    "href": "W1_Intro.html#project",
    "title": "01a Introduction to Biostatistics",
    "section": "Project",
    "text": "Project\n\n\nFind a dataset that can answer a question you are interested in\n\nhttps://ourworldindata.org/\nStatistisches Bundesamt\nYour own, e.g., from an internship\n\n\n\n\n\npreprocess/wrangle it,\nanalyze the data,\nand write a short (min. 2-page) report!\n\nshort intro incl. research question and hypothesis\nmethods (both how the data were acquired and how they are analyzed)\nresults (incl. at least one plot)\nand a short discussion.\n\nAll these parts should be at least half a page long.",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#schedule",
    "href": "W1_Intro.html#schedule",
    "title": "01a Introduction to Biostatistics",
    "section": "Schedule",
    "text": "Schedule\nThe up-to-date version can be found at https://hillea.github.io/biostats/.\n\n\n\n\n\n\n\n\n\n\nSession\nDate\nTopic\nReading\nProject Deadlines\n\n\n\n\n\n14.10.\nNo class\n\nRead chapters and install software\n\n\n01\n21.10.\nGeneral & R Intro\nST21: 1-3, QF: 1-3\nR & RStudio installed\n\n\n02\n28.10.\nModels\nST21: 4, QF: 4-6\n\n\n\n03\n04.11.\nData Wrangling\nST21: 4, QF: 4-6\n\n\n\n04\n11.11.\nData Visualization\nQF: 7\n\n\n\n05\n18.11.\nProbability\nST21: 7-8, QF: 8\nDataset\n\n\n06\n25.11.\nSampling\nST21: 7-8, QF: 8\n\n\n\n07\n02.12.\nHypothesis Testing\nST21: 9-10\n\n\n\n08\n09.12.\nComparing Means & Categories\nST21: 12, 15\nResearch Question & Hypotheses\n\n\n09\n16.12.\nExercises (t-Tests, Chi²)\nST21: 12, 15\n\n\n\n10\n23.12.\n(General) Linear Models\nST21: 12-13\nFirst Analysis Ideas\n\n\n\n30.12. & 06.01.\nHolidays\n\n\n\n\n11\n13.01.\nExercises (GLM)\nST21: 12-13\n\n\n\n12\n20.01.\nLinear Mixed Models\nST21: 14\nAnalysis (with R scripts)\n\n\n13\n27.01.\nR Markdown for Reports\n\n\n\n\n14\n03.02.\nTroubleshooting Your Report\n\nSend Questions via Email\n\n\n\n\nReproducible Research\nST21: 18\nReport (with R Markdown)\n\n\n\n\n\nST21: Statistical Thinking for the 21st Century\nQF: Fundamentals of Quantitative Analysis (QuantFun)",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#why-is-it-important-that-you-know-statistics",
    "href": "W1_Intro.html#why-is-it-important-that-you-know-statistics",
    "title": "01a Introduction to Biostatistics",
    "section": "Why is it important that YOU know statistics?",
    "text": "Why is it important that YOU know statistics?\n\n\nYou’re doing a research master!\n\nResearch = Reading & understanding papers (esp. the analyses)\nDesigning your own experiments, analyze data, interpret results\n\nWe live in an increasingly data-centric world\n\nKnowing how to wrangle and analyze data is a valuable skill\n\nFacts & data literacy matter more than ever!\n\nFake News, “Lying with stats”, Reproducibility Crisis\nBeing able to call bullshit (https://www.callingbullshit.org/)\n\n“I only believe in statistics that I doctored myself” ― Winston S. Churchill\n\nHowever: “It is easy to lie with statistics, but easier to lie without them” ― Frederick Mosteller",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#what-is-statistical-thinking",
    "href": "W1_Intro.html#what-is-statistical-thinking",
    "title": "01a Introduction to Biostatistics",
    "section": "What is Statistical Thinking?",
    "text": "What is Statistical Thinking?\n\n“a systematic way of thinking about how we describe the world and use data [to] make decisions and predictions, all in the context of the inherent uncertainty that exists in the real world.” (Poldrack, Preface of ST21)\n“Statistical thinking is a way of understanding a complex world by describing it in relatively simple terms that nonetheless capture essential aspects of its structure or function, and that also provide us some idea of how uncertain we are about that knowledge.” (Poldrack, Chapter 1)\n\n\nbreak down complexity, include uncertainty",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#why-is-statistical-thinking-important",
    "href": "W1_Intro.html#why-is-statistical-thinking-important",
    "title": "01a Introduction to Biostatistics",
    "section": "Why is Statistical Thinking Important?",
    "text": "Why is Statistical Thinking Important?\n\ndata literacy vs. intuition/heuristics/anecdotal evidence\n\nPublic discourse about Covid-19, migration, etc. (e.g., “50% of people in intensive care are vaccinated”)\n\n\n\n\n\n\n\n\n\n\nBase Rate Fallacy\n\n\n\nexample availability heuristic from book (or any other example where intuition is wrong, i.e. vaccinations/covid…)",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#what-can-statistics-do-for-us",
    "href": "W1_Intro.html#what-can-statistics-do-for-us",
    "title": "01a Introduction to Biostatistics",
    "section": "What can Statistics Do For Us?",
    "text": "What can Statistics Do For Us?\n\nDescribe patterns by summarizing/breaking down data (“descriptive statistics”)\nDecide whether one thing is better than another, given the uncertainty (“inferential statistics”)\nPredict how other people would “behave” (generalize to new observations)\n\n\ndescribe: not useful to look at every single data point/person, but we need s.th. like tendencies/trends…",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#the-big-ideas",
    "href": "W1_Intro.html#the-big-ideas",
    "title": "01a Introduction to Biostatistics",
    "section": "The Big Ideas",
    "text": "The Big Ideas\n\nLearning from data: Update our beliefs\nAggregation: How to summarize the data to draw meaningful conclusions?\nUncertainty: Probabilistic evidence\nSampling from the population: Which people etc. do we select?\n\n\nask for every point what I could mean w/ it?\nLearning from data: gather new knowledge or even just hypotheses\nAggregation: Can’t look at all ind data points, need to find trends etc. (should not go too far! throwing out data)\nUncertainty: stats = tools for making decisions under uncertainty, we can never prove anything but provide evidence, there is no 100% certainty for an outcome\nsampling: how do we represent the population? What is the population? how much data do we need? More is better, but payoff decreases…",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#causality",
    "href": "W1_Intro.html#causality",
    "title": "01a Introduction to Biostatistics",
    "section": "Causality",
    "text": "Causality\nCorrelation does not imply causation… but is a hint!\n\nExample: Smoking = less risk for Parkinson’s disease? (Godwin-Austen et al., 1982; Chen et al., 2010)\n\n\n→ confounding factors?\n\n\ne.g., individual dopaminergic activity ⇒ addiction & motor function\n\n\nRandomized Controlled Trials (RCT) as the solution?\n\nRCT: exp control and manipulation, removes confounds if done well\nAt least some more causal evidence!\nQUESTIONS so far?",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#what-are-data",
    "href": "W1_Intro.html#what-are-data",
    "title": "01a Introduction to Biostatistics",
    "section": "What are Data?",
    "text": "What are Data?\n\nWhat do you think are data?\n\n\n\nqualitative vs. quantitative\n\nqualitative?\n\nopen questions, descriptions… can potentially be coded into categories\n\nquantitative?\n\nnumeric, can be averaged etc.\n\n\n\n\n\nChat → after showing slide! Come up with examples for “Data”\nCollect: Do you have ideas? What are data you encounter in your lives/work etc? What are differences between these data?",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#what-are-data-2",
    "href": "W1_Intro.html#what-are-data-2",
    "title": "01a Introduction to Biostatistics",
    "section": "What are Data? (2)",
    "text": "What are Data? (2)\n\n\nData types\n\ncharacter/string: text (qualitative)\nfactors/categories\ntypes of numbers (quantitative)\n\nbinary: 0 or 1, TRUE or FALSE (logical)\nintegers: whole numbers\nreal numbers: decimals/fractions\n\n\ndiscrete vs. continuous\n\ndiscrete: finite set of particular values (0 or 1, scale from 1 to 10)\ncontinuous: real numbers that fall into particular range (e.g., brain activity, visual analoge scale)\n\nWhat data type is eye color?\n\n\n\neye color can be categorical (e.g., “brown”, “blue”, “green”) or numerical (wave length in nm)",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#what-is-a-data-set",
    "href": "W1_Intro.html#what-is-a-data-set",
    "title": "01a Introduction to Biostatistics",
    "section": "What is a Data Set?",
    "text": "What is a Data Set?\n\na collection of data\nusually organized into rows and columns (like an excel spreadsheet)\n\nrows: participants/animals/cells…\ncolumns: variables!\n\neach variable contains one type of measurement\n\ntable cells = unique observations of variables per participant etc.\n\n\n\nNHANES dataset\npossibly go through columns and ask for data types?",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#what-makes-a-good-measurement",
    "href": "W1_Intro.html#what-makes-a-good-measurement",
    "title": "01a Introduction to Biostatistics",
    "section": "What Makes a Good Measurement?",
    "text": "What Makes a Good Measurement?\n\n\n\nWhat is being measured?\n\nconstructs vs. proxies: need to be well-defined! (Difficult)\nmeasurement error\n\nrandom: e.g., variation in reaction times of same participant across trials\nsystematic: e.g., miscalibrated eye-tracking device\n\n\nDo we have a “gold standard” to compare the measurement to?\n\n\n\nBreak-Out session: Brainstorm what makes a good vs. bad measurement!\nGroup work/brainstorm:\n\nWhat are problems?\nWhich kind of errors/when is data NOT good\nhow can we minimize error?",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#reliability",
    "href": "W1_Intro.html#reliability",
    "title": "01a Introduction to Biostatistics",
    "section": "Reliability",
    "text": "Reliability\nCorrelation of a measurement with “itself”\n\n\nInternal reliability (consistency)\nTest-retest reliability (stability)\nInter-rater reliability (agreement)\n\n\n\nCorrelation with other variables can’t be higher than reliability (cf., Wilmer et al., 2012, Table 1)!",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#validity",
    "href": "W1_Intro.html#validity",
    "title": "01a Introduction to Biostatistics",
    "section": "Validity",
    "text": "Validity\nAre we measuring the construct we’re interested in?\n\nFace validity: Does it intuitively make sense? First reality check!\nConstruct validity\n\nconvergent validity: Related to similar measures that should measure the same construct\ndivergent validity: Is it unrelated to other measures?\n\nPredictive validity: Is it predictive of other outcomes? (e.g., intelligence & job success)",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#validity-reliability",
    "href": "W1_Intro.html#validity-reliability",
    "title": "01a Introduction to Biostatistics",
    "section": "Validity & Reliability",
    "text": "Validity & Reliability\n\nReliability & Validity",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#summarizing-data",
    "href": "W1_Intro.html#summarizing-data",
    "title": "01a Introduction to Biostatistics",
    "section": "Summarizing Data",
    "text": "Summarizing Data\n\n\nThrowing away (some of the) information!\n\nextract the quintessence of the data (important for forming models)\nmake predictions\n\nCounts, frequencies, percentages, averages",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W15_RepResearchR.html#how-we-think-science-should-work",
    "href": "W15_RepResearchR.html#how-we-think-science-should-work",
    "title": "15 Reproducible Research",
    "section": "How we Think Science Should Work",
    "text": "How we Think Science Should Work\n\nYou have a hypothesis\n\nBranding food with popular characters causes children to choose “healthy” food\n\nYou collect some data\n\nChildren can choose between cookie and apple with either Elmo-sticker or control condition\n\nYou do statistics (often to test the null hypothesis)\n\n“The preplanned comparison shows Elmo-branded apples were associated with an increase in a child’s selection of an apple over a cookie, from 20.7% to 33.8% (χ2=5.158; P=.02)” (Wansink, Just, and Payne 2012)\n\nYou make a conclusion based on the data\n\nBranding can increase healthy choices in young children…\n\n\n\n\n\n\nThe Research Cycle (Munafo et.al., 2017)\n\n\n\n= scientific cycle",
    "crumbs": [
      "15 Reproducible Research"
    ]
  },
  {
    "objectID": "W15_RepResearchR.html#how-science-sometimes-actually-works",
    "href": "W15_RepResearchR.html#how-science-sometimes-actually-works",
    "title": "15 Reproducible Research",
    "section": "How Science (Sometimes) Actually Works",
    "text": "How Science (Sometimes) Actually Works\nThe example on the last slide summarized a study by Brian Wansink. He was a very popular eating researcher - until in 2017 some researchers looked at his publications more closely and found a lot of inconsistencies and statistical problems. Wansink refused to share the data.\n\nThere was a Buzzfeed article, which reported\n\nThe p-value was 0.06, just shy of the gold standard cutoff of 0.05. It was a “sticking point,” as he put it in a Jan. 7, 2012, email. … “It seems to me it should be lower,” he wrote, attaching a draft. “Do you want to take a look at it and see what you think. If you can get the data, and it needs some tweeking, it would be good to get that one value below .05.” …\n\n\n\nWansink eventually resigned after a number of his papers had been retracted.",
    "crumbs": [
      "15 Reproducible Research"
    ]
  },
  {
    "objectID": "W15_RepResearchR.html#the-reproducibility-crisis-in-science",
    "href": "W15_RepResearchR.html#the-reproducibility-crisis-in-science",
    "title": "15 Reproducible Research",
    "section": "The Reproducibility Crisis in Science",
    "text": "The Reproducibility Crisis in Science\nIn 2015, the paper “Estimating the reproducibility of psychological science”(Open Science Collaboration, 2015) was published. It showed that out of 100 published studies with originally 97% significant results, only 37% could be replicated (i.e., were also significant in the replication). Also, the average effect size replicated was half of the average original publication.\n\nThis was actually predicted already in 2005 in a paper by the (now in-)famous John Ioannidis. In the paper “Why most published research findings are false”, he argued that the use of Null Hypothesis Significance Testing (NHST) will necessarily lead to high levels of false results.",
    "crumbs": [
      "15 Reproducible Research"
    ]
  },
  {
    "objectID": "W15_RepResearchR.html#positive-predictive-value-and-statistical-significance",
    "href": "W15_RepResearchR.html#positive-predictive-value-and-statistical-significance",
    "title": "15 Reproducible Research",
    "section": "Positive Predictive Value and Statistical Significance",
    "text": "Positive Predictive Value and Statistical Significance\nPositive Predictive Value (PPV): Statistically significant findings that are actually true. \\(P(\\text{Effect true |  significant result})\\)!\nType I error/False positives: How many of the statistically significant findings do we expect to be false? Usually 5% if \\(\\alpha=0.05\\).\nType II error/False negatives: How many of the non-significant findings do we expect to actually be true effects? Usually something like \\(\\beta=0.20\\).\nStatistical Power: How likely is it for our study design to actually find a true effect? I.e., if we have a power of 50%, we would only find a true effect at chance level. Power is the inverse of the Type II error: e.g. \\(\\text{power} = 1\\) \\(- \\beta\\).\nWe can increase power with increasing sample size!\n\n\\[PPV = \\frac{P(\\text{true positive result})}{P(\\text{true positive result}) + P(\\text{false positive result})}\\]\n\\[P(\\text{true positive result}) = P(\\text{H is true}) * Power\\]\n\\[P(\\text{false positive result}) = (1 - P(\\text{H is true})) * \\alpha\\]\nWe don’t know \\(P(\\text{H is true})\\)! But we can assume how likely it is for the specific research field: PPV App",
    "crumbs": [
      "15 Reproducible Research"
    ]
  },
  {
    "objectID": "W15_RepResearchR.html#the-winners-curse",
    "href": "W15_RepResearchR.html#the-winners-curse",
    "title": "15 Reproducible Research",
    "section": "The Winner’s Curse",
    "text": "The Winner’s Curse\nEffect sizes estimated from a significant result are usually an overestimate of the true effect size!\nWe have simulated experiments with a true effect size of \\(.2\\) (red dotted line) and varying statistical power. For every power, we select the highest effect size found (the “winner” in an explorative analysis).\n\nIn the left plot, you can see that estimated effect sizes (sampling error!) are especially overestimated for studies with low power.\nOn the right is a histogram showing effect size estimates for a number of simulated experiments. Non-significant results are shown in red, significant ones in blue.\n\nSignificance depends on effect size and sample size (standard error =&gt; sqrt(n)).\nThis shows us that only if power is high and the effect is large will the ES estimate be close to realistic.",
    "crumbs": [
      "15 Reproducible Research"
    ]
  },
  {
    "objectID": "W15_RepResearchR.html#questionable-research-practices",
    "href": "W15_RepResearchR.html#questionable-research-practices",
    "title": "15 Reproducible Research",
    "section": "Questionable Research Practices",
    "text": "Questionable Research Practices\nBem in “The Compleat Academic: A Career Guide” (published by Darley, Zanna, & Roediger, 2004)\n\nWhich article should you write? There are two possible articles you can write: (1) the article you planned to write when you designed your study or (2) the article that makes the most sense now that you have seen the results. They are rarely the same, and the correct answer is (2).\n\n\nThis is HIGHLY problematic! 🙈\nHARKing: Hypothesizing After the Results are Known\nreframing a post-hoc conclusion as an a priori prediction (in which we have stronger faith).\n\n\n\nAnalyzing data Examine them from every angle. Analyze the sexes separately. Make up new composite indices. If a datum suggests a new hypothesis, try to find further evidence for it elsewhere in the data. If you see dim traces of interesting patterns, try to reorganize the data to bring them into bolder relief. If there are participants you don’t like, or trials, observers, or interviewers who gave you anomalous results, drop them (temporarily). Go on a fishing expedition for something — anything — interesting. No, this is not immoral.\n\n\n\np-hacking: trying different analyses until one finds a significant result.\n-&gt; Increases false positive rate!\n\nHARKing: moving the goalpost so that it ends up wherever the ball goes. Difficult to disconfirm ideas.\np-hacking:\n\nAnalyze data after every subject, and stop collecting data once p&lt;.05\nAnalyze many different variables, but only report those with p&lt;.05\nCollect many different experimental conditions, but only report those with p&lt;.05\nExclude participants to get p&lt;.05\nTransform the data to get p&lt;.05\n\nAdd publication pressure etc. 7 sins?",
    "crumbs": [
      "15 Reproducible Research"
    ]
  },
  {
    "objectID": "W15_RepResearchR.html#questionable-research-practices-2",
    "href": "W15_RepResearchR.html#questionable-research-practices-2",
    "title": "15 Reproducible Research",
    "section": "Questionable Research Practices 2",
    "text": "Questionable Research Practices 2\n\n\n\nThe Research Cycle - and where QRPs play a role",
    "crumbs": [
      "15 Reproducible Research"
    ]
  },
  {
    "objectID": "W15_RepResearchR.html#preregistration",
    "href": "W15_RepResearchR.html#preregistration",
    "title": "15 Reproducible Research",
    "section": "Preregistration",
    "text": "Preregistration\nSubmit a detailed description of a study (incl. all data analyses) to a trusted, time-stamped repository (https://osf.io/ or https://aspredicted.org/).\n-&gt; Provides greater transparency and trust that the analyses are not p-hacked or other questionable research practices were used.\n-&gt; Resulted in an increase in published non-significant findings (good because they are not lost in the “file drawer” and remain available for meta-analyses).",
    "crumbs": [
      "15 Reproducible Research"
    ]
  },
  {
    "objectID": "W15_RepResearchR.html#reproducible-practices",
    "href": "W15_RepResearchR.html#reproducible-practices",
    "title": "15 Reproducible Research",
    "section": "Reproducible Practices",
    "text": "Reproducible Practices\nSimmons, Nelson, and Simonsohn (2011) suggested the following standards for making research more reproducible:\n\nAuthors must decide the rule for terminating data collection before data collection begins and report this rule in the article.\nAuthors must collect at least 20 observations per cell or else provide a compelling cost-of-data-collection justification.\nAuthors must list all variables collected in a study.\nAuthors must report all experimental conditions, including failed manipulations.\nIf observations are eliminated, authors must also report what the statistical results are if those observations are included.\nIf an analysis includes a covariate, authors must report the statistical results of the analysis without the covariate.",
    "crumbs": [
      "15 Reproducible Research"
    ]
  },
  {
    "objectID": "W15_RepResearchR.html#replication",
    "href": "W15_RepResearchR.html#replication",
    "title": "15 Reproducible Research",
    "section": "Replication",
    "text": "Replication\nOther researchers should be able to perform the same study and obtain the same result.\n\nIt would be a good practice to replicate your own finding in a new (sufficiently powered) sample. Not every replication will be successful (80% power = 1/5 chance of getting a non-significant finding although there is a true effect!).\nA small p-value does not necessarily provide stronger evidence for your hypothesis! (Although a p-value close to .05 is never strong evidence…).",
    "crumbs": [
      "15 Reproducible Research"
    ]
  },
  {
    "objectID": "W15_RepResearchR.html#doing-reproducible-data-analysis",
    "href": "W15_RepResearchR.html#doing-reproducible-data-analysis",
    "title": "15 Reproducible Research",
    "section": "Doing Reproducible Data Analysis",
    "text": "Doing Reproducible Data Analysis\nReplicating another lab’s findings is crucial, but another aspect of reproducibility is to be able to reproduce someone’s analysis on their own data: computational reproducibility.\nFor this, it is of course necessary that data and code are openly shared (on e.g. Github, osf.io, Zenodo, OpenNeuro…). Furthermore, scripted analyses, e.g using R, are highly preferred over point-and-click software, because it doesn’t document what was actually clicked (and you can’t comment it - there are some exceptions).",
    "crumbs": [
      "15 Reproducible Research"
    ]
  },
  {
    "objectID": "W15_RepResearchR.html#doing-reproducible-data-analysis-2",
    "href": "W15_RepResearchR.html#doing-reproducible-data-analysis-2",
    "title": "15 Reproducible Research",
    "section": "Doing Reproducible Data Analysis 2",
    "text": "Doing Reproducible Data Analysis 2\nThere are a number of ways to make you code even more reproducible, such as using version control (Git/Github) and containers or virtual environments, which ensure e.g. that the same version of the software (and packages etc.) was used.\n\n\n\nThe Turing Way of Reproducible Research",
    "crumbs": [
      "15 Reproducible Research"
    ]
  },
  {
    "objectID": "W12_LMM.html#setup",
    "href": "W12_LMM.html#setup",
    "title": "12 Linear Mixed Models",
    "section": "Setup",
    "text": "Setup\nWe will use a package called lme4 for the statistical models. The package includes a dataset called sleepstudy, which we will be using. You don’t have to load the data separately, just load the package and you have access to the data:\n\nlibrary(lme4)\n\n# for information about the dataset, check out:\n# ?sleepstudy\n\n\nDescription:\nThe average reaction time per day (in milliseconds) for subjects in a sleep deprivation study.\nDays 0-1 were adaptation and training (T1/T2), day 2 was baseline (B); sleep deprivation started after day 2.\n\n\nFormat:\nA data frame with 180 observations on the following 3 variables.\n‘Reaction’ Average reaction time (ms)\n‘Days’ Number of days of sleep deprivation\n‘Subject’ Subject number on which the observation was made.",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#multilevel-data",
    "href": "W12_LMM.html#multilevel-data",
    "title": "12 Linear Mixed Models",
    "section": "Multilevel Data",
    "text": "Multilevel Data\nMultilevel data are nested data, which means that they are clustered:\n\n\n\n\n\nLevels of a Multilevel Model\n\n\n\n\n\n\n3-level LMM\n\n\n\n\nFor example, repeated measures of the same subjects will result in data that are often more strongly correlated within subjects than between.\nBut LMMs can also account for other kinds of nesting/clustering, such as patients who share therapists or mice from the same cage/experimenter.\n\n\nData is usually multilevel for one of the three reasons below (multiple reasons could simultaneously apply):\n\nyou have a within-subject factor, and/or\nyou have pseudoreplications (several trials/measurements), and/or\nyou have multiple stimulus items (this rarely is accounted for in a statistical model :( ).\n\n\npseudorep: Get RT to same stimulus several times, or give VP beverage repeatedly\nmutliple: different but related stimuli from pool of stimuli",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#multilevel-data-2",
    "href": "W12_LMM.html#multilevel-data-2",
    "title": "12 Linear Mixed Models",
    "section": "Multilevel Data 2",
    "text": "Multilevel Data 2\nMultilevel data are nested data, which means that they are clustered:\n\n\n\n\n\nLevels of a Multilevel Model\n\n\n\n\n\n\n3-level LMM\n\n\n\n\nMultilevel data are extremely common in neuroscientific research!\nUnfortunately, LMMs are hardly every covered in statistics classes. Instead, these data are often analyzed using t-tests or ANOVAs, but sometimes these models are not sufficient.\nMoreover, LMMs have less of a problem with missing data.",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#the-sleepstudy-data",
    "href": "W12_LMM.html#the-sleepstudy-data",
    "title": "12 Linear Mixed Models",
    "section": "The Sleepstudy Data",
    "text": "The Sleepstudy Data\nIn the dataset, we have measurements of 18 participants across 10 days of sleep deprivation. Each day, the participants performed a “psychomotor vigilance test” during which they had to monitor a display and press a button as quickly as possible as soon as a stimulus appeared.\nThe dependent measure (DV) is response times (RT).\nLet’s take a look at the data, with a separate plot per participant:\n\nIt looks like RT is increasing with each additional day of sleep deprivation, starting from day 2 and increasing until day 10.",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#preparing-the-data",
    "href": "W12_LMM.html#preparing-the-data",
    "title": "12 Linear Mixed Models",
    "section": "Preparing the Data",
    "text": "Preparing the Data\nWe have some more information about the model that is helpful:\n\nThe first two days were adaptation and training, the third day was a baseline measurement (8h time in bed)\nOn the 4th day (until the 10th, so for 7 days), the sleep deprivation began:\n\nThere were four groups: 9h, 7h, 5h, 3h time in bed\n\n\n\nWe thus have to remove the first two days, as they might bias our results.\n\nTask:\n\nRemove (filter) observations where Days is 0 or 1.\nMake a new variable, days_deprived, where day 2 is recoded as 0, day 3 as 1 etc.\nStore the data in a dataframe called sleep2.\n\n\n\n\nsleep2 &lt;- sleepstudy %&gt;%\n  filter(Days &gt;= 2) %&gt;%\n  mutate(days_deprived = Days - 2)",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#fitting-the-model",
    "href": "W12_LMM.html#fitting-the-model",
    "title": "12 Linear Mixed Models",
    "section": "Fitting the Model",
    "text": "Fitting the Model\nHow might we model the relationship between days_deprived and Reaction?\n\n\nIt looks like we could fit a different line to each participant’s data.\nRemember the general formula for fitting lines:\n\\(Y = \\beta_0 + \\beta_1 X\\)\nwhere \\(\\beta_0\\) is the y-intercept and \\(\\beta_1\\) is the slope, which we both estimate from the data.\n\n\nIf we fit such a line for every participant, the lines will differ in their intercept (individual mean RT at baseline) and slope (the individual change in RT with each additional day of sleep deprivation).\nShould we fit the same line for every participant? Or individual lines? Or something in between?\nThese three approaches are also called complete pooling, no pooling, and partial pooling.",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#complete-pooling",
    "href": "W12_LMM.html#complete-pooling",
    "title": "12 Linear Mixed Models",
    "section": "Complete Pooling",
    "text": "Complete Pooling\nWith complete pooling, we would estimate the same intercept and slope for every participant (“one size fits all”). This approach ignores diversity among participants (average RT and sensitivity to sleep deprivation):\n\n\n\ncp_model &lt;- lm(Reaction ~ days_deprived, sleep2)\n\nsummary(cp_model)\n\n\nCall:\nlm(formula = Reaction ~ days_deprived, data = sleep2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-112.284  -26.732    2.143   27.734  140.453 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    267.967      7.737  34.633  &lt; 2e-16 ***\ndays_deprived   11.435      1.850   6.183 6.32e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 50.85 on 142 degrees of freedom\nMultiple R-squared:  0.2121,    Adjusted R-squared:  0.2066 \nF-statistic: 38.23 on 1 and 142 DF,  p-value: 6.316e-09\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinds significant effects but fits the data poorly!\nThis is usually never done - even repeated measures ANOVAs at least provide a random intercept (but not slope).\nthe predicted mean response time on Day 0 is about 268 milliseconds, with an increase of about 11 milliseconds per day of deprivation, on average. We can’t trust the standard errors for our regression coefficients, however, because we are assuming that all of the observations are independent (technically, that the residuals are). However, we can be pretty sure this is a bad assumption.",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#no-pooling",
    "href": "W12_LMM.html#no-pooling",
    "title": "12 Linear Mixed Models",
    "section": "No Pooling",
    "text": "No Pooling\nAnother approach would be to fit completely separate lines for each participant. This approach implies that the estimates for one participant are completely uninformed by the estimates for the other participants - we could fit 18 separate models.\nWe could also include Subject as a predictor, or a so-called fixed effect. For this approach, we have to make sure Subject is a factor (and not a continuous predictor).\n\nstr(sleep2)\n\n'data.frame':   144 obs. of  4 variables:\n $ Reaction     : num  251 321 357 415 382 ...\n $ Days         : num  2 3 4 5 6 7 8 9 2 3 ...\n $ Subject      : Factor w/ 18 levels \"308\",\"309\",\"310\",..: 1 1 1 1 1 1 1 1 2 2 ...\n $ days_deprived: num  0 1 2 3 4 5 6 7 0 1 ...\n\n# fit the model\n\nnp_model &lt;- lm(Reaction ~ days_deprived * Subject, data = sleep2)\n\nsummary(np_model)\n\n\nCall:\nlm(formula = Reaction ~ days_deprived * Subject, data = sleep2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-106.521   -8.541    1.143    8.889  128.545 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              288.2175    16.4772  17.492  &lt; 2e-16 ***\ndays_deprived             21.6905     3.9388   5.507 2.49e-07 ***\nSubject309               -87.9262    23.3023  -3.773 0.000264 ***\nSubject310               -62.2856    23.3023  -2.673 0.008685 ** \nSubject330               -14.9533    23.3023  -0.642 0.522422    \nSubject331                 9.9658    23.3023   0.428 0.669740    \nSubject332                27.8157    23.3023   1.194 0.235215    \nSubject333                -2.7581    23.3023  -0.118 0.906000    \nSubject334               -50.2051    23.3023  -2.155 0.033422 *  \nSubject335               -25.3429    23.3023  -1.088 0.279207    \nSubject337                24.6143    23.3023   1.056 0.293187    \nSubject349               -59.2183    23.3023  -2.541 0.012464 *  \nSubject350               -40.2023    23.3023  -1.725 0.087343 .  \nSubject351               -24.2467    23.3023  -1.041 0.300419    \nSubject352                43.0655    23.3023   1.848 0.067321 .  \nSubject369               -21.5040    23.3023  -0.923 0.358154    \nSubject370               -53.3072    23.3023  -2.288 0.024107 *  \nSubject371               -30.4896    23.3023  -1.308 0.193504    \nSubject372                 2.4772    23.3023   0.106 0.915535    \ndays_deprived:Subject309 -17.3334     5.5703  -3.112 0.002380 ** \ndays_deprived:Subject310 -17.7915     5.5703  -3.194 0.001839 ** \ndays_deprived:Subject330 -13.6849     5.5703  -2.457 0.015613 *  \ndays_deprived:Subject331 -16.8231     5.5703  -3.020 0.003154 ** \ndays_deprived:Subject332 -19.2947     5.5703  -3.464 0.000765 ***\ndays_deprived:Subject333 -10.8151     5.5703  -1.942 0.054796 .  \ndays_deprived:Subject334  -3.5745     5.5703  -0.642 0.522423    \ndays_deprived:Subject335 -25.8995     5.5703  -4.650 9.47e-06 ***\ndays_deprived:Subject337   0.7518     5.5703   0.135 0.892895    \ndays_deprived:Subject349  -5.2644     5.5703  -0.945 0.346731    \ndays_deprived:Subject350   1.6007     5.5703   0.287 0.774382    \ndays_deprived:Subject351 -13.1681     5.5703  -2.364 0.019867 *  \ndays_deprived:Subject352 -14.4019     5.5703  -2.585 0.011057 *  \ndays_deprived:Subject369  -7.8948     5.5703  -1.417 0.159273    \ndays_deprived:Subject370  -1.0495     5.5703  -0.188 0.850912    \ndays_deprived:Subject371  -9.3443     5.5703  -1.678 0.096334 .  \ndays_deprived:Subject372 -10.6041     5.5703  -1.904 0.059613 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 25.53 on 108 degrees of freedom\nMultiple R-squared:  0.849, Adjusted R-squared:  0.8001 \nF-statistic: 17.35 on 35 and 108 DF,  p-value: &lt; 2.2e-16\n\n\n\nalso uses lm()\nintercept and slope = 308, other values are deviations from 308\nThis model does not give us an overall intercept and slope! (Can average of course…) -&gt; suboptimal if we want to generalize to new participants!",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#no-pooling-2",
    "href": "W12_LMM.html#no-pooling-2",
    "title": "12 Linear Mixed Models",
    "section": "No Pooling 2",
    "text": "No Pooling 2\n\n\ntibble [18 × 3] (S3: tbl_df/tbl/data.frame)\n $ Subject  : Factor w/ 18 levels \"308\",\"309\",\"310\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ intercept: num [1:18] 288 200 226 273 298 ...\n $ slope    : num [1:18] 21.69 4.36 3.9 8.01 4.87 ...\n\n\n\n\nSubject 335 has a negative slope (faster with more sleep deprivation). While it is not impossible, it seems highly unlikely given what we know about sleep deprivation and/or looking at the rest of the data.",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#partial-pooling",
    "href": "W12_LMM.html#partial-pooling",
    "title": "12 Linear Mixed Models",
    "section": "Partial Pooling",
    "text": "Partial Pooling\nNeither the complete nor no-pooling approach are satisfactory. It would be desirable to improve our estimates for individual participants (\\(1/18\\)th of the total data) by taking advantage of what we know about other participants.\n\nThis is called partial pooling: We treat a factor (e.g., subject) as implementing random deviations from its higher level fixed effect - with larger deviations being less likely (think: normal distribution). Consequently, we bias the random effect estimate (individual level) towards the fixed effect estimate (group level). This procedure is also called shrinkage for we are downsizing the individual’s deviation from the group mean.\n\n\nWe thus estimate a model like this:\n\\(Y_{sd} = \\gamma_{0} + S_{0s} + \\left(\\gamma_{1} + S_{1s}\\right) X_{sd} + e_{sd}\\)\nwhere \\(\\gamma_{0}\\) is the “overall”/population intercept and \\(\\gamma_{1}\\) is the population slope. These are the fixed effects which are usually of interest and they are estimated from the data.\n\\(S_{0s}\\) are the random intercepts per participant and \\(S_{1s}\\) the random slopes for \\(X_{sd}\\) per participant. These values vary over subjects (thus the \\(s\\) in the index) and are the offsets from the fixed effects (i.e., how much do individuals differ from the overall intercept/slope? Some subjects will have slower RTs than average, for some the effect of sleep deprivation will be stronger than average, etc.).\n(See textbook for further mathematical formula descriptions and details!)\n\nWill help us distinguish signal from error for each participant\nimprove generalization to the population\nespecially important if we have missing data\n\nRandom effects: result of sampling, want to generalize beyond those levels\nFixed effects: assume that they reflect true pop para, don’t vary from sample to sample",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#partial-pooling-shrinkage",
    "href": "W12_LMM.html#partial-pooling-shrinkage",
    "title": "12 Linear Mixed Models",
    "section": "Partial Pooling: Shrinkage",
    "text": "Partial Pooling: Shrinkage\n\n\n\nShrinkage\n\n\n\nthe further away from the population estimate, the more biased.\nThe fewer observations in a cluster, the more information borrowed from others, greater pull (373 and 374)\nAvoids overfitting by taming extreme estimates!",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#comparison-of-pooling-methods",
    "href": "W12_LMM.html#comparison-of-pooling-methods",
    "title": "12 Linear Mixed Models",
    "section": "Comparison of Pooling Methods",
    "text": "Comparison of Pooling Methods\n-,p_model_comparison,-If%20we%20stare)\n\nthe further away from the population estimate, the more biased.\nThe fewer observations in a cluster, the more information borrowed from others, greater pull (373 and 374)\nAvoids overfitting by taming extreme estimates!",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#fitting-the-model-1",
    "href": "W12_LMM.html#fitting-the-model-1",
    "title": "12 Linear Mixed Models",
    "section": "Fitting the Model",
    "text": "Fitting the Model\nTo fit an LMM, we can use the function lmer() from the lme4 package (you could also use functions from the afex package, which might be more user friendly).\nThe notation is very similar to that of fitting lm() models, we only need to add the random effects:\n\npp_mod &lt;- lmer(Reaction ~ days_deprived + (days_deprived | Subject), sleep2)\n\n\nHere we can see that we only have one predictor/IV/fixed effect: days_deprived.\nRandom effects are denoted in the parentheses (). On the right side of the |, you write down what uniquely identifies the clustering variable, e.g. Subjects. On the left side of the |, you put the effects that you want to vary over the levels of the clustering variable. The right side thus denotes the random intercept, the left side the random slope.\n\n\nThere are a number of ways to specify random effects. The most common you will see are:\n\n\n\n\n\n\n\nModel\nSyntax\n\n\n\n\nRandom intercepts only\nReaction ~ days_deprived + (1 | Subject)\n\n\nRandom intercepts and slopes\nReaction ~ days_deprived + (days_deprived | Subject)\n\n\n\nRandom-intercepts-only models are appropriate if you have within-subjects factors without pseudo-replications (i.e., one measurement per subject/level). If you have more than one observation per subject and fixed effect conditions, you can estimate random slopes.\n\nrepeated-measures ANOVA is equivalent to a random intercept model!\nalways good to include random slopes, but sometimes the model does not converge –&gt; only random intercepts\nYou can add other random effects, e.g., stimulus\nYou can’t have a random slope without a random intercept (you could but it wouldn’t make sense)",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#interpreting-the-model---fixed-effects",
    "href": "W12_LMM.html#interpreting-the-model---fixed-effects",
    "title": "12 Linear Mixed Models",
    "section": "Interpreting the Model - Fixed Effects",
    "text": "Interpreting the Model - Fixed Effects\nLet’s look at the model output:\n\nsummary(pp_mod)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: Reaction ~ days_deprived + (days_deprived | Subject)\n   Data: sleep2\n\nREML criterion at convergence: 1404.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.0157 -0.3541  0.0069  0.4681  5.0732 \n\nRandom effects:\n Groups   Name          Variance Std.Dev. Corr\n Subject  (Intercept)   958.35   30.957       \n          days_deprived  45.78    6.766   0.18\n Residual               651.60   25.526       \nNumber of obs: 144, groups:  Subject, 18\n\nFixed effects:\n              Estimate Std. Error t value\n(Intercept)    267.967      8.266  32.418\ndays_deprived   11.435      1.845   6.197\n\nCorrelation of Fixed Effects:\n            (Intr)\ndays_deprvd -0.062\n\n\nThe section called Fixed effects is similar to what you have seen so far for lm() models. This is also the section that will likely be of main interest to you.\nYou can see that the estimated mean reaction time for participants at Day 0 was about 268 milliseconds, with each day of sleep deprivation adding an additional 11 milliseconds to the response time, on average.",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#interpreting-the-model---fixed-effects-2",
    "href": "W12_LMM.html#interpreting-the-model---fixed-effects-2",
    "title": "12 Linear Mixed Models",
    "section": "Interpreting the Model - Fixed Effects 2",
    "text": "Interpreting the Model - Fixed Effects 2\nYou might notice that you didn’t see p-values in the output. There is a huge discussion on how to best estimate the degrees of freedom for these models… If you don’t want to go into the details, one option is to use the lmerTest package to obtain p-values:\n\nlibrary(lmerTest)\npp_mod &lt;- lmer(Reaction ~ days_deprived + (days_deprived | Subject), sleep2)\n#you can also call lmerTest::lmer explicitly to highlight the distinction to lme4::lmer\nsummary(pp_mod)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: Reaction ~ days_deprived + (days_deprived | Subject)\n   Data: sleep2\n\nREML criterion at convergence: 1404.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-4.0157 -0.3541  0.0069  0.4681  5.0732 \n\nRandom effects:\n Groups   Name          Variance Std.Dev. Corr\n Subject  (Intercept)   958.35   30.957       \n          days_deprived  45.78    6.766   0.18\n Residual               651.60   25.526       \nNumber of obs: 144, groups:  Subject, 18\n\nFixed effects:\n              Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)    267.967      8.266  17.000  32.418  &lt; 2e-16 ***\ndays_deprived   11.435      1.845  16.999   6.197 9.75e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr)\ndays_deprvd -0.062",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#interpreting-the-model---random-effects",
    "href": "W12_LMM.html#interpreting-the-model---random-effects",
    "title": "12 Linear Mixed Models",
    "section": "Interpreting the Model - Random Effects",
    "text": "Interpreting the Model - Random Effects\nThe random effects part of the output provides you with the variance-covariance matrix of the random effects and the residual variance.\nThe residual variance is the error variance which is not explained by the model.\nThe variance-covariance matrix above gives us the variance of each random effect component as well as the correlation between random intercept and slope. Often, you would not need to interpret these effects in too much detail (unless you’re interested in floor/ceiling effects visible in a big correlation).\nIf the variance of a random effect is close to 0, it means that there is not much diversity of the sample with respect to predictors. In other words: Each random effect is very similar to its fixed effect.",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#lmm-with-crossed-random-factors",
    "href": "W12_LMM.html#lmm-with-crossed-random-factors",
    "title": "12 Linear Mixed Models",
    "section": "LMM with Crossed Random Factors",
    "text": "LMM with Crossed Random Factors\nOften, we have a set of stimuli that we use for all subjects, e.g., pictures. Each specific stimulus might have its own effects, some might be more efficient in eliciting the intended response than others. In such a case, the stimuli would also explain some of the variance and would be a random factor.\n\nData would be clustered not only within subjects but also within stimuli\n\n\nWith lmer(), it is quite easy to add other random effects, such as crossed random effects:\n\ny ~ x + (1 + x | subject_id) + (1 + x | stimulus_id)\n\n\n\nWhy are they “crossed”?\nIf you look at the data of all trials, you can average them for every subject (i.e., across stimuli) or for every stimulus (i.e., across subjects). These provide different perspectives of the data from two different “angles”.",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#convergence-issues-and-singular-fits",
    "href": "W12_LMM.html#convergence-issues-and-singular-fits",
    "title": "12 Linear Mixed Models",
    "section": "Convergence Issues and Singular Fits",
    "text": "Convergence Issues and Singular Fits\nIt often happens that you get an error message: Either your model does not converge (R tries but can’t find stable estimates) or you have a singular fit (the random factors have variances close to 0 or correlate perfectly with each other, i.e. \\(-1\\) or \\(+1\\)).\nIn both cases, it makes sense to simplify your random effect structure to reduce overfitting:\n\nConstrain all covariance parameters to zero. This is accomplished using the double-bar || syntax, e.g., changing (a * b | subject) to (a * b || subject). If you still run into estimation problems, then:\nInspect the parameter estimates from the non-converging or singular model. Are any of the slope variables zero or near to zero? Remove these and re-fit the model, repeating this step until the convergence warnings / singular fit messages go away.\n\nNote: We usually start with simplifying the random effects structure because it is much more complicated (e.g., one slope per subject!) and thus provides way more potential for overfitting.\n\nthis might not make sense right now, but you can look at it once you run into these problems",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#example",
    "href": "W12_LMM.html#example",
    "title": "12 Linear Mixed Models",
    "section": "Example",
    "text": "Example\nLet’s fit a model with simulated data.\n\n\n# A tibble: 6 × 5\n  subj_id item_id  cond gender     Y\n    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;\n1       1       1  -0.5 male   1078.\n2       1       2   0.5 male    957.\n3       1       3  -0.5 male    698.\n4       1       4   0.5 male    464.\n5       1       5  -0.5 male    497.\n6       1       6   0.5 male    787.\n\n\nWe have 100 participants (subj_id) and 50 observations per participant, one for each stimulus (item_id).\nYou can also see two predictors: cond and gender.\nAs you can see, cond is a within-subject, across-item variable (a categorical factor!), which means that some of the stimuli belong to one category, the others to a second category (e.g., positive and negative images).\ngender is a between-subjects variable (also a categorical factor!): Participants either identified as female or male but that didn’t change across the experiment.\nFinally, there is a dependent/outcome variable called Y, representing reaction times.\n\nIf we’re interested in the effects of cond and gender (including their interaction) on Y, how would you specify the model? Which would be the fixed effects, which would be random effects?",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#example-2",
    "href": "W12_LMM.html#example-2",
    "title": "12 Linear Mixed Models",
    "section": "Example 2",
    "text": "Example 2\n\n# make sure gender is a factor!\ndat_sim2$gender &lt;- as.factor(dat_sim2$gender)\nlevels(dat_sim2$gender)\n\n[1] \"female\" \"male\"  \n\nmod_sim &lt;- lmer(Y ~ cond * gender + (1 + cond | subj_id) + (1 | item_id), dat_sim2, REML = FALSE)\n\nsummary(mod_sim)\n\nLinear mixed model fit by maximum likelihood . t-tests use Satterthwaite's\n  method [lmerModLmerTest]\nFormula: Y ~ cond * gender + (1 + cond | subj_id) + (1 | item_id)\n   Data: dat_sim2\n\n     AIC      BIC   logLik deviance df.resid \n 67643.3  67702.0 -33812.7  67625.3     4991 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6374 -0.6612 -0.0244  0.6779  3.7702 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr\n subj_id  (Intercept)  9457.0   97.25       \n          cond          595.3   24.40   0.67\n item_id  (Intercept)  8086.4   89.92       \n Residual             40305.0  200.76       \nNumber of obs: 5000, groups:  subj_id, 100; item_id, 50\n\nFixed effects:\n                Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)      790.541     19.157 134.091  41.267  &lt; 2e-16 ***\ncond              76.085     26.894  56.207   2.829  0.00646 ** \ngendermale         5.503     20.261  99.624   0.272  0.78651    \ncond:gendermale    3.134     12.361  99.160   0.254  0.80035    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) cond   gndrml\ncond         0.062              \ngendermale  -0.529 -0.059       \ncond:gndrml -0.135 -0.230  0.256\n\n# with the anova() function, you will get the typical anova table with main effects and interaction!\nanova(mod_sim)\n\nType III Analysis of Variance Table with Satterthwaite's method\n            Sum Sq Mean Sq NumDF  DenDF F value   Pr(&gt;F)   \ncond        354738  354738     1 50.671  8.8013 0.004584 **\ngender        2973    2973     1 99.624  0.0738 0.786505   \ncond:gender   2592    2592     1 99.160  0.0643 0.800346   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#contrasts",
    "href": "W12_LMM.html#contrasts",
    "title": "12 Linear Mixed Models",
    "section": "Contrasts",
    "text": "Contrasts\nR, by default, uses a coding of the factor levels called dummy coding. This means that one factor level is coded as \\(0\\), another as \\(1\\) (and if there are more than two levels, there will be several dummy coded variables used for the models).\nThe problem with dummy coding is that the output is hard to interpret, especially if interactions are involved. Therefore, it is preferable to use effects or sum coding, which uses \\(-.5\\) and \\(.5\\) as codes for the factor levels.\n(For more details, see the example on Regression/Linear Model from last session)\nYou can change this before running the model using:\n\n## use sum coding instead of default 'dummy' (treatment) coding\n\ncontrasts(dat_sim2$gender) &lt;- contr.sum\n\n\n\nLinear mixed model fit by maximum likelihood . t-tests use Satterthwaite's\n  method [lmerModLmerTest]\nFormula: Y ~ cond * gender + (1 + cond | subj_id) + (1 | item_id)\n   Data: dat_sim2\n\n     AIC      BIC   logLik deviance df.resid \n 67643.3  67702.0 -33812.7  67625.3     4991 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.6374 -0.6612 -0.0244  0.6779  3.7702 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr\n subj_id  (Intercept)  9457.0   97.25       \n          cond          595.3   24.40   0.67\n item_id  (Intercept)  8086.4   89.92       \n Residual             40305.0  200.76       \nNumber of obs: 5000, groups:  subj_id, 100; item_id, 50\n\nFixed effects:\n             Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)   793.293     16.259 101.954  48.791  &lt; 2e-16 ***\ncond           77.652     26.175  50.671   2.967  0.00458 ** \ngender1        -2.751     10.131  99.624  -0.272  0.78651    \ncond:gender1   -1.567      6.180  99.160  -0.254  0.80035    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) cond  gendr1\ncond        0.038              \ngender1     0.000  0.000       \ncond:gendr1 0.000  0.000 0.256 \n\n\nType III Analysis of Variance Table with Satterthwaite's method\n            Sum Sq Mean Sq NumDF  DenDF F value   Pr(&gt;F)   \ncond        354738  354738     1 50.671  8.8013 0.004584 **\ngender        2973    2973     1 99.624  0.0738 0.786505   \ncond:gender   2592    2592     1 99.160  0.0643 0.800346   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#assumption-check",
    "href": "W12_LMM.html#assumption-check",
    "title": "12 Linear Mixed Models",
    "section": "Assumption Check",
    "text": "Assumption Check\nWe can use the check_model() function of the performance package also for LMMs:\n\n# check_model(mod_sim)\n\n\nLooks good!",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#planned-comparisons",
    "href": "W12_LMM.html#planned-comparisons",
    "title": "12 Linear Mixed Models",
    "section": "Planned Comparisons",
    "text": "Planned Comparisons\nYou can also use the emmeans package for comparing different groups/factor levels. For example, you could do pairwise comparisons for the main effect of gender, if that was significant. This is especially relevant if you have more than two factor levels/groups/conditions, because with two you can already read out the effect from the lmer() output (the estimate for gender1 is the difference between the two genders if you use dummy coding, and 2* the estimate if you use sum coding!). We would use the emmeans() function:\n\nemm1 = emmeans(mod_sim, specs = pairwise ~ gender)\n\nYou could also investigate further in which direction an interaction goes. If you have a categorical and a continuous predictor, we would probably use emtrends() to see how the slope of the continuous variable differs between groups of the categorical variable.\nIf we have two categorical variables, like we have in our example, we can use emmeans() similarly to the code above, only that we include the interaction:\n\nemm1 = emmeans(mod_sim, specs = pairwise ~ cond:gender)\ntest(emm1)\n\n$emmeans\n cond gender emmean   SE  df z.ratio p.value\n -0.5 female    752 22.7 Inf  33.134  &lt;.0001\n  0.5 female    829 24.1 Inf  34.410  &lt;.0001\n -0.5 male      756 22.7 Inf  33.307  &lt;.0001\n  0.5 male      836 24.1 Inf  34.703  &lt;.0001\n\nDegrees-of-freedom method: asymptotic \n\n$contrasts\n contrast                            estimate   SE  df z.ratio p.value\n (cond-0.5 female) - cond0.5 female    -76.08 26.9 Inf  -2.829  0.0241\n (cond-0.5 female) - (cond-0.5 male)    -3.94 19.6 Inf  -0.201  0.9971\n (cond-0.5 female) - cond0.5 male      -83.15 33.1 Inf  -2.512  0.0580\n cond0.5 female - (cond-0.5 male)       72.15 33.1 Inf   2.180  0.1289\n cond0.5 female - cond0.5 male          -7.07 22.6 Inf  -0.312  0.9895\n (cond-0.5 male) - cond0.5 male        -79.22 26.9 Inf  -2.946  0.0170\n\nDegrees-of-freedom method: asymptotic \nP value adjustment: tukey method for comparing a family of 4 estimates \n\n\nYou would then select the comparisons in the $contrasts output that are of interest (you can also run only those, but that’s a bit more difficult).\nYou can also use the emmip() function to make interaction plots, e.g.\n\nemmip(mod_sim, cond ~ gender)\n\n\nBut since the interaction is not significant, we don’t need to do any post-hoc comparisons!\n\nThe reason these functions exist is that we cannot simply calculate means to visualize the effects once we include random slopes using shrinkage. We have to predict values using the whole fitted model to make inference about partial effects.",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#effect-sizes",
    "href": "W12_LMM.html#effect-sizes",
    "title": "12 Linear Mixed Models",
    "section": "Effect Sizes",
    "text": "Effect Sizes\nYou can calculate R², the explained variance of the DV Y, as an overall model fit index. For LMMs, you can calculate two R²: One for the fixed effects only (marginal), one when also accounting for the random effect (i.e., the individual differences, conditional).\n\n# use r2() from the performance package:\n\nr2(mod_sim)\n\n# R2 for Mixed Models\n\n  Conditional R2: 0.323\n     Marginal R2: 0.025\n\n\n\nIn addition, you can calculate the effect sizes per effect. This is not as straight-forward for LMMs, but you could use the following function from the effectsize package to obtain the partial eta² (you will have to plug in the F values etc. from the ANOVA table):\n\nlibrary(effectsize)\noptions(es.use_symbols = TRUE) #get nice symbols when printing!\n\nF_to_eta2(\n  f = c(8.8013, 0.0738, 0.0643),\n  df = c(1, 1, 1),\n  df_error = c(50.671, 99.624,99.160)\n)\n\nη² (partial) |       95% CI\n---------------------------\n0.15         | [0.03, 1.00]\n7.40e-04     | [0.00, 1.00]\n6.48e-04     | [0.00, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#reporting-interpretation",
    "href": "W12_LMM.html#reporting-interpretation",
    "title": "12 Linear Mixed Models",
    "section": "Reporting & Interpretation",
    "text": "Reporting & Interpretation\nWe ran a linear mixed model with condition and gender as fixed effect, Y as dependent variable, and random slopes for condition for each subject, as well as random intercepts for subjects and items. All assumptions of linear mixed models were met and the model explains \\(32.3\\%\\) of the variance in Y if accounting for the random effects (marginal R²) and \\(2.5\\%\\) if only accounting for the fixed effects (conditional R²).\nWe found a main effect of condition (F(1, 50.67) = 8.8, p = .005, partial η² = .15), but neither a main effect of gender (F(…, …) = … , p = …, partial η² = …) nor a significant interaction between gender and condition (F(…, …) = .. , p = …, partial η² = …) emerged.\nThe reaction times in the first condition are significantly lower (M = 754 ms, SD = …) than in the other condidtion (M = 832 ms, SD = …). The effects are summarized in Figure 2.\n[Add visualization where you can see the difference between conditions!]\n\nThe ANOVA, as a fixed effects model, would have only accounted for 2.5% of variance instead of almost a third due to its neglect of random effects",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#why-not-model-discrete-data-as-continuous",
    "href": "W12_LMM.html#why-not-model-discrete-data-as-continuous",
    "title": "12 Linear Mixed Models",
    "section": "Why not Model Discrete Data as Continuous?",
    "text": "Why not Model Discrete Data as Continuous?\nThis is actually what happens a lot (you can see it in published papers): Researchers treat percentages, counts, or (sums of) responses on a Likert scale as continuous data and simply run a linear model.\nBut there are a number of reasons why this is a bad idea:\n\nBounded scale: There are usually no negative numbers and often an upper limit as well. A normal linear model would try to assign probability to these impossible values. This can lead to spurious interaction effects (think of improvements from \\(90\\%\\) - there’s a ceiling)!\nVariance depends on mean: In LMs, the variance is independent from the mean (related to the assumption of homogeneity of variance). This is not necessarily the case for discrete data (e.g. binary or count data).\n\nIt thus makes sense to model the data as best as possible.",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#how-to-run-a-generalized-linear-model",
    "href": "W12_LMM.html#how-to-run-a-generalized-linear-model",
    "title": "12 Linear Mixed Models",
    "section": "How to run a Generalized Linear Model",
    "text": "How to run a Generalized Linear Model\nThe basic idea is to use a link function that transforms the response space so that we can perform our usual linear regression. The parameters will be hard to interpret because they are in the model space (~different units), but we can transform them back to our response space (data units) using an inverse link function.\n\nThere are a lot of different kinds of generalized linear models that you would use depending on your data. The most common ones are the logistic regression (for binary data) and the Poisson regression (for count data).\nI will just give you an example with logistic regression.",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#logistic-regression",
    "href": "W12_LMM.html#logistic-regression",
    "title": "12 Linear Mixed Models",
    "section": "Logistic Regression",
    "text": "Logistic Regression\nDefinitions:\n\n\n\n\n\n\n\nTerm\nDefinition\n\n\n\n\nBernoulli trial\nAn event with a binary outcome, one outcome being considered “success”\n\n\nproportion\nThe ratio of successes to the total number of Bernoulli trials\n\n\nodds\nThe ratio of successes to failures\n\n\nlog odds\nThe (natural) logarithm of the odds\n\n\n\nIn logisitc regression, we are modeling the relationship between response (DV) and predictors (IVs) in log odds space (= model space).\n\nLogistic regression is used when the individual outcomes are Bernoulli trials. The outcome of a sequence of trials is communicated as a proportion:\nIf we flip a coin 100 times and get 47 heads, we have a proportion of .47. This is our estimate of the probability of the event.\n\n\nWe can also calculate the (natural) odds of heads: \\(47/53 = .89\\) (heads:not heads).\nThe natural log of the odds or logit is the scale of the logistic regression.\nRecall that the logarithm of some value Y gives the exponent that would yield Y for a given base. For instance, the log2 (log to the base 2) of 16 is 4, because 24 = 16.\nIn logistic regression, the base is usually e (Euler’s number). To get the log odds from the natural odds, we can use log() and to get the inverse, the natural from the log odds, we can use exp().\n\nBernoulli: 0,1 / success, failure… arbitrary what is success!\nodds = p/1-p\n0 to +inf\nnice properties of log odds:\n\nsymmetric around 0\n0 = max. uncertainty, both outcomes equally likely\npos: success more likely than failure",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#link-function",
    "href": "W12_LMM.html#link-function",
    "title": "12 Linear Mixed Models",
    "section": "Link Function",
    "text": "Link Function\nThe link function for logistic regression is:\n\\(\\eta = \\log \\left(\\frac{p}{1-p}\\right)\\)\nThe inverse link function is:\n\\(p = \\frac{1}{1 + e^{-\\eta}}\\)\n\n\n\nModel vs. response space\n\n\n\neta = outcome variable?!",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W12_LMM.html#estimating-logistic-regression-in-r",
    "href": "W12_LMM.html#estimating-logistic-regression-in-r",
    "title": "12 Linear Mixed Models",
    "section": "Estimating Logistic Regression in R",
    "text": "Estimating Logistic Regression in R\nEstimating logistic regressions is not very difficult in R (the interpretation might be, though), because you simply use the function glm() instead of lm() or glmer() instead of lmer().\nIn addition, you’d add an argument to the function, which specifies the link function. For logistic regression, this would be family = binomial(link = \"logit\") or family = binomial would be sufficient if you want to use the default logit link.\nSo the code would look like this:\n\nglm(DV ~ IV1 + IV2 + ..., data, family = binomial)\n\n# for multi-level data:\nglmer(DV ~ IV1 + IV2 + ... (1 | subject), data, family = binomial)",
    "crumbs": [
      "12 Linear Mixed Models"
    ]
  },
  {
    "objectID": "W10_GLM.html#glm",
    "href": "W10_GLM.html#glm",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "GLM",
    "text": "GLM\nOne approach is the GLM. You might be surprised that a lot of the common models can be viewed as linear models:\n\nAll models can be thought of as linear models",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#definitions",
    "href": "W10_GLM.html#definitions",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Definitions",
    "text": "Definitions\nDependent variable (DV): The outcome variable that the model aims to explain (\\(Y\\)).\nIndependent variable (IV): The variable(s) that we use to explain the DV (\\(X\\)).\nLinear model: The model for the DV is composed of a linear combination of IVs (that are multiplied by different weights!)\n\nThe weights are the parameters \\(\\beta\\) and determine the relative contribution of each IV. (This is what the model estimates! The weights thus give us the important information we’re usually interested in: How strong are IV and DV related.)\nThere may also be several DVs (“multivariate statistics”), but usually that’s not the case except for specific biopsychological methods (e.g., fMRI). Thus, we will focus on those cases with one DV!",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#example",
    "href": "W10_GLM.html#example",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Example",
    "text": "Example\n\n\nLet’s use some simulated data:\n\n\n\n\n\n\n\n\n\n\nWe can calculate the correlation between the two variables:\n\n\n\n    Pearson's product-moment correlation\n\ndata:  df$grade and df$studyTime\nt = 2.0134, df = 6, p-value = 0.09073\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.1261283  0.9255245\nsample estimates:\n      cor \n0.6349813 \n\n\nr(6) = .63 [-.13; .93], p = .091\n\n\nThe correlation is quite high (.63), but the CI is also pretty wide.\n\n\nFundamental activities of statistics:\n\nDescribe: How strong is the relationship between grade and study time?\nDecide: Is there a statistically significant relationship between grade and study time?\nPredict: Given a particular amount of study time, what grade do we expect?\n\n\nrelationship study time and grade",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#linear-regression",
    "href": "W10_GLM.html#linear-regression",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Linear Regression",
    "text": "Linear Regression\nUse the GLM to…\n\ndescribe the relation between two variables (similar to correlation)\ndecide whether an IV is a significant predictor of the DV\npredict DV for new values of IV (new observations)\nadd multiple IVs!\n\n\n\n\nSimple GLM (here: equivalent to linear regression):\n\\[\ny = \\beta_0+ x * \\beta_x + \\epsilon\n\\]\n\\(\\beta_0\\) = intercept: the overall offset of the line when \\(x=0\\) (this cannot always be interpreted)\n\\(\\beta_x\\) = slope: how much do we expect \\(y\\) to change with each change in \\(x\\)?\n\\(y\\) = DV\n\\(x\\) = IV or predictor\n\\(\\epsilon\\) = error term* or residuals: whatever variance is left once the model is fit (Think of the model as the blue line and the residuals are the vertical deviations of the data points from the line)\n(If we refer to predicted \\(y\\)-values, after we have estimated the model, we can drop the error term: \\(\\hat{y} = \\hat{\\beta_0} + x * \\hat{\\beta_x}\\).)",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#the-relation-between-correlation-and-regression",
    "href": "W10_GLM.html#the-relation-between-correlation-and-regression",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "The Relation Between Correlation and Regression",
    "text": "The Relation Between Correlation and Regression\nThere is a close relation and we can convert \\(r\\) to \\(\\hat{\\beta_x}\\).\n\\(\\hat{r} = \\frac{covariance_{xy}}{s_x * s_y}\\)\n\\(\\hat{\\beta_x} = \\frac{covariance_{xy}}{s_x*s_x}\\)\n\\(covariance_{xy} = \\hat{r} * s_x * s_y\\)\n\\(\\hat{\\beta_x} = \\frac{\\hat{r} * s_x * s_y}{s_x * s_x} = r * \\frac{s_y}{s_x}\\)\n–&gt; Regression slope = correlation multiplied by ratio of SDs (if SDs are equal, \\(r\\) = \\(\\hat{\\beta}\\) )\n\nEstimation of GLM:\nlinear algebra (R will do that for us!) –&gt; Appendix book",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#standard-errors-for-regression-models",
    "href": "W10_GLM.html#standard-errors-for-regression-models",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Standard Errors for Regression Models",
    "text": "Standard Errors for Regression Models\nWe usually want to make inferences about the regression parameter estimates. For this we need an estimate of their variability.\nWe first need an estimate of how much variability is not explained by the model: the residual variance (or error variance):\nCompute residuals:\n\\[\nresidual = y - \\hat{y} = y - (x*\\hat{\\beta_x} + \\hat{\\beta_0})\n\\]\nCompute Sum of Squared Errors (remember from ANOVA?):\n\\[\nSS_{error} = \\sum_{i=1}^n{(y_i - \\hat{y_i})^2} = \\sum_{i=1}^n{residuals^2}\n\\]\nCompute Mean Squared Error:\n\\[\nMS_{error} = \\frac{SS_{error}}{df} = \\frac{\\sum_{i=1}^n{(y_i - \\hat{y_i})^2} }{N - p}\n\\]\nwhere the \\(df\\) are the number of observations \\(N\\) - the number of estimated parameter \\(p\\) (in this case 2: \\(\\hat{\\beta_0}\\) and \\(\\hat{\\beta_x}\\)).\nFinally, we can calculate the standard error for the full model:\n\\[\nSE_{model} = \\sqrt{MS_{error}}\n\\]\nWe can also calculate the SE for specific regression parameter estimates by rescaling the \\(SE_{model}\\):\n\\[\nSE_{\\hat{\\beta_x}} = \\frac{SE_{model}}{\\sqrt{\\sum{(x_i - \\bar{x})^2}}}\n\\]\n\nrescaling SE: by square root of the SS of the X variable",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#statistical-tests-for-regression-parameters",
    "href": "W10_GLM.html#statistical-tests-for-regression-parameters",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Statistical Tests for Regression Parameters",
    "text": "Statistical Tests for Regression Parameters\nWith the parameter estimates and their standard errors, we can compute \\(t\\)-statistics, which represent the likelihood of the observed estimate vs. the expected value under \\(H_0\\) (usually 0, no effect).\n\\[\n\\begin{array}{c}\nt_{N - p} = \\frac{\\hat{\\beta} - \\beta_{expected}}{SE_{\\hat{\\beta}}}\\\\\nt_{N - p} = \\frac{\\hat{\\beta} - 0}{SE_{\\hat{\\beta}}}\\\\\nt_{N - p} = \\frac{\\hat{\\beta} }{SE_{\\hat{\\beta}}}\n\\end{array}\n\\]",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#glm-results",
    "href": "W10_GLM.html#glm-results",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "GLM results",
    "text": "GLM results\nUsually, we would just let R do the calculations:\n\nsummary(lmResult)\n\n\nCall:\nlm(formula = grade ~ studyTime, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-10.656  -2.719   0.125   4.703   7.469 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   76.156      5.161  14.756 6.09e-06 ***\nstudyTime      4.313      2.142   2.013   0.0907 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.386 on 6 degrees of freedom\nMultiple R-squared:  0.4032,    Adjusted R-squared:  0.3037 \nF-statistic: 4.054 on 1 and 6 DF,  p-value: 0.09073\n\n\nThe intercept is significantly different from zero (which is usually not very relevant: with 0 study time, you don’t get 0%) and the effect of studyTime is not (or only “marginally”) significant. So for every hour that we study more, the effect on the grade is descriptively rather small (~4%) but possibly not present at all (because it is not statistically significant).\n\n\\(t\\) ratio of \\(\\beta\\) to its \\(SE\\)!\nintercept: expected grade without studying at all",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#quantifying-goodness-of-fit-of-the-model",
    "href": "W10_GLM.html#quantifying-goodness-of-fit-of-the-model",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Quantifying Goodness of Fit of the Model",
    "text": "Quantifying Goodness of Fit of the Model\nOften, it is useful to check how good the (total) model we estimated fits the data.\n\nWe can do that easily by asking how much of the variability in the data is accounted for by the model?\n\n\nIf we only have one IV (\\(x\\)), then we can simply square the correlation coefficient:\n\\[\nR^2 = r^2\n\\]\nIn study time example, \\(R^2\\) = 0.63² = 0.4 –&gt; we accounted for 40% of the overall variance in grades!\n\n\nMore generally, we can calculate \\(R^2\\) with the Sum of Squared Variances:\n\\[\nR^2 = \\frac{SS_{model}}{SS_{total}} = 1-\\frac{SS_{error}}{SS_{total}}\n\\]\n\n\nWith a sample of sufficient size, it is possible to get highly significant values that still explain very little of the total variance (i.e., little practical significance despite statistical significance)\n\n\\(R^2\\) is the name of the Goodness of Fit stat!\nA small R² tells us that even though a model might be significant, it may only explain a small amount of information in the DV",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#fitting-more-complex-models",
    "href": "W10_GLM.html#fitting-more-complex-models",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Fitting More Complex Models",
    "text": "Fitting More Complex Models\nOften we want to know the effects of multiple variables (IVs) on some outcome.\nExample:\nSome students have taken a very similar class before, so there might not only be the effect of studyTime on grades, but also of having taken a priorClass.\n\n\n\nWe can built a model that takes both into account by simply adding the “weight” and the IV (priorClass) to the model:\n\\(\\hat{y} = \\hat{\\beta_1}*studyTime + \\hat{\\beta_2}*priorClass + \\hat{\\beta_0}\\)\n\nTo model priorClass, i.e. whether each individual has taken a previous class or not, we use dummy coding (0=no, 1=yes).\nThis means, for those who have not taken a class, the whole part of the equation (\\(\\hat{\\beta_2} * priorClass\\)) will be zero - we will add it for the others.\n\\(\\hat{\\beta_2}\\) is thus the difference in means between the two groups!\n\\(\\hat{\\beta_1}\\) is the regression slope of studyTime across data points/regardless of whether someone has taken a class before.\n\n\nIf we plot the data, we can see that both IVs seem to have an effect on grades:\n\n\n\n\n\n\n\n\n\n\n\nHow can we tell from the plot that both IVs might have an effect?",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#interactions-between-variables",
    "href": "W10_GLM.html#interactions-between-variables",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Interactions Between Variables",
    "text": "Interactions Between Variables\nWe previously assumed that the effect of studyTime on grade was the same for both groups - but sometimes we expect that this regression slope differs per group!\n\nE.g., due to prior knowledge from another class, it may be easier to profit from studying the new materials (i.e., steeper slope). Or it may be harder due to diminishing marginal returns (i.e., flatter slope).\n\n\n\nThis is what we call an interaction: The effect of one variable depends on the value of another variable.\nThus, priorClass can have a main effect on grade (i.e., independent of studyTime): “I already know more, regardless wether I study”.\nBut it can also interact with studyTime: “Due to my prior knowledge, I can study more efficiently.”",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#interaction-example",
    "href": "W10_GLM.html#interaction-example",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Interaction Example",
    "text": "Interaction Example\nExample: What is the effect of caffeine on public speaking?\n\n\n\n\n\n# perform linear regression with caffeine as independent variable\nlmResultCaffeine &lt;- lm(speaking ~ caffeine, data = df)\nsummary(lmResultCaffeine)\n\n\nCall:\nlm(formula = speaking ~ caffeine, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-33.096 -16.024   5.014  16.453  26.979 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  -7.4132     9.1653  -0.809    0.429\ncaffeine      0.1676     0.1508   1.111    0.281\n\nResidual standard error: 19.19 on 18 degrees of freedom\nMultiple R-squared:  0.06419,   Adjusted R-squared:  0.0122 \nF-statistic: 1.235 on 1 and 18 DF,  p-value: 0.2811\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThere doesn’t seem to be a “direct” (bivariate) effect:",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#interaction-example-two-main-effects",
    "href": "W10_GLM.html#interaction-example-two-main-effects",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Interaction Example: Two main effects",
    "text": "Interaction Example: Two main effects\nWhat if we have the hypothesis that anxiety also affects public speaking?\n\n\n\n\n\n\n\nCall:\nlm(formula = speaking ~ caffeine + anxiety, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-32.968  -9.743   1.351  10.530  25.361 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)       -12.5812     9.1967  -1.368    0.189\ncaffeine            0.1313     0.1446   0.908    0.377\nanxietynotAnxious  14.2328     8.2324   1.729    0.102\n\nResidual standard error: 18.21 on 17 degrees of freedom\nMultiple R-squared:  0.2041,    Adjusted R-squared:  0.1105 \nF-statistic:  2.18 on 2 and 17 DF,  p-value: 0.1436\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe new model is still not significant. This is due to the fact that we only look at additive effects (main effects). But neither caffeine nor anxiety alone/independently predict public speaking performance.\n\n\nFrom the plot, however, it looks like the effect of caffeine is indeed different for the two anxiety groups: Increasing for non-anxious people and decreasing for anxious ones.\nIn other words: We need to have a model that allows to fit different regression slopes to both groups.\n\nexplain additive effects: look at average caffeine effect, then add mean for anxiety groups (but: both not significant here!)\nproblem of independent main effects: also if you bring together two findings from two different papers =&gt; no information about interaction of predictors",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#interaction-example-full-model",
    "href": "W10_GLM.html#interaction-example-full-model",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Interaction Example: Full model",
    "text": "Interaction Example: Full model\nTo allow for different slopes for each group (i.e. for the effect of caffeine to vary between the anxiety groups), we have to model the interaction as well.\n\n\n\n\n\nCall:\nlm(formula = speaking ~ caffeine + anxiety + caffeine:anxiety, \n    data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-11.385  -7.103  -0.444   6.171  13.458 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 17.43085    5.43012   3.210 0.005461 ** \ncaffeine                    -0.47416    0.09664  -4.906 0.000158 ***\nanxietynotAnxious          -43.44873    7.79141  -5.576 4.17e-05 ***\ncaffeine:anxietynotAnxious   1.08395    0.12931   8.382 3.01e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.085 on 16 degrees of freedom\nMultiple R-squared:  0.8524,    Adjusted R-squared:  0.8247 \nF-statistic:  30.8 on 3 and 16 DF,  p-value: 7.014e-07\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe model is now significant! There is an interaction between caffeine and anxiety. Interestingly, the main effects are also significant now even though they were not in the previous models (because the residual variance has been reduced drastically from 18 to 8 by the highly significant interaction).\nNote: speaking ~ caffeine * anxiety is shorthand for speaking ~ caffeine + anxiety + caffeine:anxiety\n\ninterpretation coefficients:\nintercept: intercept of anxious group!\nintercept not anxious: difference intercept anxious vs. notanxious\nslope anxious: only for the anxious group!\nslope not anxious: diff in slopes\nno main effects!!!",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#convert-glm-to-anova",
    "href": "W10_GLM.html#convert-glm-to-anova",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Convert GLM to ANOVA",
    "text": "Convert GLM to ANOVA\nThe interpretation of the coefficients of a GLM when interactions are included is not as straight forward compared to an ANOVA!\n\nIf you want to report the “typical” ANOVA table with main effects and the general interaction:\n\nanova(lmResultInteraction)\n\nAnalysis of Variance Table\n\nResponse: speaking\n                 Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ncaffeine          1  454.8   454.8  6.9578 0.017911 *  \nanxiety           1  991.5   991.5 15.1678 0.001288 ** \ncaffeine:anxiety  1 4593.4  4593.4 70.2662 3.01e-07 ***\nResiduals        16 1045.9    65.4                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nNote: The p-values are different between the GLM and the ANOVA outputs because effects including factors are coded slightly differently (dummy vs. effect coding):\nDummy coding uses the first level as a default and compares the remaining levels to it (\\(0\\) vs. \\(1\\)).\nEffect coding takes the overall mean as an abstract comparison (\\(-.5\\) vs. \\(+.5\\)).\nThis difference is resembled in the output tables as anxietynotAnxious (GLM) vs. anxiety (ANOVA).\n\ninterpretation coefficients:\nintercept: intercept of anxious group!\nintercept not anxious: difference intercept anxious vs. notanxious\nslope anxious: only for the anxious group!\nslope not anxious: diff in slopes\nno main effects!!!",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#model-comparison",
    "href": "W10_GLM.html#model-comparison",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Model Comparison",
    "text": "Model Comparison\nSometimes, we want to compare two (nested!) models to see which one fits the data better.\nWe can do so by using the anova()* function in R:\n\nanova(lmResultCafAnx, lmResultInteraction)\n\nAnalysis of Variance Table\n\nModel 1: speaking ~ caffeine + anxiety\nModel 2: speaking ~ caffeine + anxiety + caffeine:anxiety\n  Res.Df    RSS Df Sum of Sq      F   Pr(&gt;F)    \n1     17 5639.3                                 \n2     16 1045.9  1    4593.4 70.266 3.01e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThis shows that Model 2, incl. the interaction, is to be preferred.\n\nNote: We can only meaningfully use this method with so-called nested models, which means that the simpler (reduced) model only contains variables also included in the more complex (full) model.\n\n\nWald compares the ratio of squared errors to an F-distribution (sound familiar from ANOVA?), while likelihood ratio compares the ratio of likelihoods to a χ2 distribution\n\n\n\n*Yes, it is kind of an ANOVA as well, in that (a ratio of) squared errors is compared to an \\(F\\)-distribution…",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#criticizing-our-model-and-checking-assumptions",
    "href": "W10_GLM.html#criticizing-our-model-and-checking-assumptions",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Criticizing Our Model and Checking Assumptions",
    "text": "Criticizing Our Model and Checking Assumptions\n“Garbage in, garbage out” - we have to make sure our model is properly specified!\n\nProperly specified = having included the appropriate IVs.\n\n\nThe model also needs to satisfy the assumptions of the statistical method (= GLM).\nOne important assumption of the GLM is that the residuals are normally distributed.\nThis assumption can be violated by a not properly specified model or because the data are inappropriate for the statistical model.\n\n\nWe can use a Q-Q plot, which represents the quantiles of two distributions/variables (e.g., the data and a normal distribution of the same data) against each other.\nIf the data points diverge substantially from the line (especially in the extremes), we can conclude that the residuals are not normally distributed.",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#model-diagnostics",
    "href": "W10_GLM.html#model-diagnostics",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Model Diagnostics",
    "text": "Model Diagnostics\nTo check the assumptions, we can easily run a function for model diagnostics (incl. Q-Q plots) in R. The function, check_model(), is included in the performance package by the easystats team (who make great packages for everything related to statistical modeling!)\n\n# install.packages(\"easystats\")\nlibrary(performance)\n\n# check this function again - not always working\n# check_model(lmResultInteraction)\n\n\nWe’re not going into detail about all these diagnostics (and hard to see!), but it is always a good idea to run diagnostics/check assumptions for your models!",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#remark-predicting-in-a-statistical-context",
    "href": "W10_GLM.html#remark-predicting-in-a-statistical-context",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Remark: “Predicting” in a Statistical Context",
    "text": "Remark: “Predicting” in a Statistical Context\nWe neither mean “predicting before seeing the data/in the future” nor mean to imply causality!\n\nIt simply refers to fitting a model to the data: We estimate (or predict) values for the DV (\\(\\hat{y}\\)) and the IVs are often referred to as predictors.\n\nRelated to: predicting future values",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#multivariate-statistics-2",
    "href": "W10_GLM.html#multivariate-statistics-2",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Multivariate Statistics 2",
    "text": "Multivariate Statistics 2\nThese two methods belong to the class of unsupervised learning. Before, we have only dealt with supervised learning (e.g., regression, ANOVA). There are also methods for multivariate, supervised learning (e.g., MANOVA).\nNote: Unsupervised learning techniques are very explorative in nature. It is a different approach to learning from data compared to hypothesis testing. Explorative methods are usually used in science to create a first insight into new phenomena that can develop into hypotheses further down the line.\n\nSupervised: we know the value of the DV that we’re trying to predict (try to find best model predictions).\nUnsupervised: we don’t have specific value to predict, we try to discover (patterns that help understand). Requires some assumptions about pattern.\n–&gt; does not necessarily have a “right” answer!",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#multivariate-data-an-example",
    "href": "W10_GLM.html#multivariate-data-an-example",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Multivariate Data: An Example",
    "text": "Multivariate Data: An Example\nHow do different aspects of psychological function (self-control etc.) relate to one another?\n10h battery of cognitive tests and surveys, N = 522, 9 measures of interest!\nMeasures:\n\nResponse inhibition: ability to quickly stop an action (measured with the stop-signal task, measure is called stop-signal reaction time (SSRT) - we have 4 different versions of this measure).\nImpulsivity: tendency to make decisions on impulse, without regard of potential consequences (UPPS-P survey, assesses 5 facets of impulsivity).",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#visualizing-multivariate-data",
    "href": "W10_GLM.html#visualizing-multivariate-data",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Visualizing Multivariate Data",
    "text": "Visualizing Multivariate Data\nHard (impossible?) for us to visualize more than three dimensions/variables.\n\nScatterplot of matrices for the nine variables in the self-control dataset. The diagonal elements in the matrix show the histogram for each of the individual variables. The lower left panels show scatterplots of the relationship between each pair of variables, and the upper right panel shows the correlation coefficient for each pair of variables.\nWhat do you see?\neach row/col –&gt; single variable\ndiagonal: dist each var\nlower triangle: scatterplot each pair, regression line –&gt; relationship\nupper: correlation coefficient",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#heatmap",
    "href": "W10_GLM.html#heatmap",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Heatmap",
    "text": "Heatmap\nVisualize correlations:\n\nHeatmap of the correlation matrix for the nine self-control variables. The brighter yellow areas in the top left and bottom right highlight the higher correlations within the two subsets of variables.We can see clear clusters: SSRT and UPPS have greater intercorrelations than correlations with the other measure.",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#heatmap-2",
    "href": "W10_GLM.html#heatmap-2",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Heatmap 2",
    "text": "Heatmap 2\nHeatmaps are especially helpful if we have a large number of variables, such as in neuroimaging! Below you can see the functional connectivity of &gt;300 brain regions:\n\nHeatmap of correlation coefficients of brain activity between 316 regions of the left hemisphere of a single individual. Yellow: strong positive correlations, blue: strong negative correlations\nlarge blocks of pos corr: major connected networks in the brain",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#clustering",
    "href": "W10_GLM.html#clustering",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Clustering",
    "text": "Clustering\nClustering: Identifying groups of related observations or variables within a dataset, based on the similarity of the values of the observations.\n\nSimilarity: Distance between values.\nEuclidean Distance: Length of the line that connects two data points:\n\n\n\n\n\n\n\n\n\n\\[\nd(x,y) = \\sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}\n\\]\n\n\nEuclidean Distance is sensitive to variability in both variables –&gt; scale data before! (e.g., z-transformation using R’s scale function)\n\nClustering: finding set of groups that have the lowest distance between their members.\nEuclidean Dist: Pythagorean theorem\n–&gt; can be extended to more than two dimensions!\nScale: calculate z-score, standardizing\nExample: Relation between height and weight =&gt; it shouldn’t make a difference if we rescale the data from m to cm or from kg to pounds.",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#k-means-clustering",
    "href": "W10_GLM.html#k-means-clustering",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "K-Means Clustering",
    "text": "K-Means Clustering\nK-means clustering: Identifies a set of cluster centers & then assigns each data point to the cluster whose center is the closest (Euclidean Distance!).\n\nDecide on value for K, the number of clusters to be found (e.g. based on previous knowledge/expectations).\nCome up with k locations for the centers - or centroids - of the clusters (e.g. choose data points at random to start with).\nCompute Euclidean distance of each data point to each centroid.\nAssign each point to a cluster, based on closest distance to centroid.\nRecompute centroid by averaging the location of all points assigned to that cluster.\nRepeat steps 1-5 until a stable solution is found (iterative process).",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#example-latitudelongitude-data",
    "href": "W10_GLM.html#example-latitudelongitude-data",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Example: Latitude/Longitude Data",
    "text": "Example: Latitude/Longitude Data\n\n\nHere we can see the starting points (black squares) and end points (big colored dots) for each cluster, as well as the final cluster assignment of each data point (color):\n\n\n\n\n\n\n\n\n\n\nWe can see that there is a reasonable overlap between clusters and continents.\nWe can further investigate this overlap with the confusion matrix, which compares membership of each cluster with the actual continents for each country:\n\n\n      \nlabels AF AS EU NA OC SA\n     1  5  1 36  0  0  0\n     2  3 24  0  0  0  0\n     3  0  0  0  0  0  7\n     4  0  0  0 15  0  4\n     5  0 10  0  0  6  0\n     6 35  0  0  0  0  0\n\n\nNote: usually we don’t know the ground truth (i.e. which continent) in unsupervised learning!\n=&gt; confusion matrix cannot be estimated\nNote 2: Every time we run the iterative process, we will get a different result if we use random starting points. Make sure the result is robust, e.g. by running the Clustering algorithm several times.)\n\n\n\nCluster 1 contains all European countries, as well as countries from northern Africa and Asia.\n\n\n\nCluster 2 contains contains Asian countries as well as several African countries.\nCluster 3 contains countries from the southern part of South America.\nCluster 4 contains all of the North American countries as well as northern South American countries.\nCluster 5 contains Oceania as well as several Asian countries\nCluster 6 contains all of the remaining African countries.",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#hierarchical-clustering",
    "href": "W10_GLM.html#hierarchical-clustering",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Hierarchical Clustering",
    "text": "Hierarchical Clustering\nHierarchical Clustering: Also uses distances to determine clusters but also visualizes relationships in dendrograms.\n\n\nThe most common procedure is agglomerative clustering:\n\nEvery data point is treated as its own cluster.\nTwo clusters with the least distance (e.g. average linkage) between them are combined.\nRepeat 1 & 2 until only one cluster is left.\nVisualize, decide on a cutoff for the amount of reasonable clusters.\n\n\n\n\n\n\n\n\n\n\n\nColored lines: different cutoffs.\n\n\nThere seems to be a high degree of similarity within each variable set (SSRT and UPPS) compared to between sets.\n=&gt; The first split separates UPPS vs. SSRT perfectly.\nWithin UPPS, sensation seeking stands out as the most different to the rest.\n\naverage linkage: average of all distances between each data point in each of two clusters.\nCan read diagram from left to right: One supercluster that is split up more and more. Or right to left: Individual points that get joint together into bigger and bigger clusters.\ncolored lines: different cutoff values",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#dimensionality-reduction",
    "href": "W10_GLM.html#dimensionality-reduction",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Dimensionality Reduction",
    "text": "Dimensionality Reduction\nWe often measure different variables that are highly similar to each other, e.g. because they are supposed to measure the same construct.\nAlthough we might measure a particular number of variables (= dimensionality of data set), there may be fewer independent sources of underlying information!\nDimensionality reduction: Reduce the number of variables by creating composite variables that reflect the underlying information.",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#principal-component-analysis-pca",
    "href": "W10_GLM.html#principal-component-analysis-pca",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Principal Component Analysis (PCA)",
    "text": "Principal Component Analysis (PCA)\nAim: Find a lower-dimensional (linear) description of a set of variables (that still accounts for the maximum possible information/variance in the dataset).\nVariance: Combination of signal + noise –&gt; find strongest common signal between variables!\n\n1st Component: explains most variance between variables, 2nd component: maximum of remaining variance - but uncorrelated with 1st…\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGreen arrow: 1st component, follows direction of max. variance\nRed arrow: 2nd component, perpendicular to 1st =&gt; uncorrelated!\nWe can run a PCA on more than two variables!\n\n\nobtain as many components as there are variables (assuming that there are more observations than there are variables)\nin practice: find a small number of components that can explain a large portion of the variance.\n1st component: similar to regression line, but minimizes perpendicular distance points to line (not vertical!)",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#pca-2",
    "href": "W10_GLM.html#pca-2",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "PCA 2",
    "text": "PCA 2\nIf we calculate a PCA on the impulsivity data, we see that there are two components (in the scree plot) that account for quite some variance.\nWe can also look at the variable loadings, which show which variable “goes into” which component to better specify what that component represents. Here we can see that one components represents (=captures variance related to) the SSRT variables, the other the UPPS.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScree plot: Sometimes used to make decisions on number of components (eigenvalues plotted)\nloadings: sign is arbitrary",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#factor-analysis-fa",
    "href": "W10_GLM.html#factor-analysis-fa",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "Factor Analysis (FA)",
    "text": "Factor Analysis (FA)\nPCA is useful for reducing the dimensionality of a dataset.\nThe components are per definition uncorrelated –&gt; sometimes this is a limitation.\nPCA also doesn’t account for measurement error –&gt; possibly difficult to interpret loadings.\n\nExploratory Factor Analysis: can also be used for dimensionality reduction.\nIdea: Each observed variable is created through a combination of contributions from a latent variable + measurement error. (latent: can’t be directly observed!)\n\n\nHow do different measures relate to underlying factor (that gives rise to these measures)?",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "W10_GLM.html#fa-2",
    "href": "W10_GLM.html#fa-2",
    "title": "10 The General Linear Model & Multivariate Statistics",
    "section": "FA 2",
    "text": "FA 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFactor analysis with Call: fa(r = observed_df, nfactors = 3)\n\nTest of the hypothesis that 3 factors are sufficient.\nThe degrees of freedom for the model is 7  and the objective function was  0.04 \nThe number of observations was  200  with Chi Square =  7.96  with prob &lt;  0.34 \n\nThe root mean square of the residuals (RMSA) is  0.01 \nThe df corrected root mean square of the residuals is  0.03 \n\nTucker Lewis Index of factoring reliability =  0.993\nRMSEA index =  0.026  and the 10 % confidence intervals are  0 0.094\nBIC =  -29.13\n\n\n\n\n\n\n\n\n\n\nRMSEA (root mean square error of approximation): Measure of model fit, should be &lt; .08.\nUse (lowest) SABIC (sample-size adjusted Bayesian information criterion) to compare models with different number of factors.\n\nWe can “hand over” 3 factors\nRMSEA quantifies how far predicted covariances (between data) are from actual covariances",
    "crumbs": [
      "10 The General Linear Model & Multivariate Statistics"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Biostatistics",
    "section": "",
    "text": "Welcome to the website of the course “Biostatistics” of the master’s programme “Translational Neuroscience” of the Julius-Maximilians-University Würzburg.\nPlease use the navigation on the left to select the slides for each session (recommendation: Open in new tab).\nWe will use the following textbooks:"
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Biostatistics",
    "section": "Schedule",
    "text": "Schedule\n\n\n\n\n\n\n\n\n\n\nSession\nDate\nTopic\nReading\nProject Deadlines\n\n\n\n\n\n14.10.\nNo class\n\nRead chapters and install software\n\n\n01\n21.10.\nGeneral & R Intro\nST21: 1-3, QF: 1-3\nR & RStudio installed\n\n\n02\n28.10.\nModels\nST21: 4, QF: 4-6\n\n\n\n03\n04.11.\nData Wrangling\nST21: 4, QF: 4-6\n\n\n\n04\n11.11.\nData Visualization\nQF: 7\n\n\n\n05\n18.11.\nProbability\nST21: 7-8, QF: 8\nDataset\n\n\n06\n25.11.\nSampling\nST21: 7-8, QF: 8\n\n\n\n07\n02.12.\nHypothesis Testing\nST21: 9-10\n\n\n\n08\n09.12.\nComparing Means & Categories\nST21: 12, 15\nResearch Question & Hypotheses\n\n\n09\n16.12.\nExercises (t-Tests, Chi²)\nST21: 12, 15\n\n\n\n10\n23.12.\n(General) Linear Models\nST21: 12-13\nFirst Analysis Ideas\n\n\n\n30.12. & 06.01.\nHolidays\n\n\n\n\n11\n13.01.\nExercises (GLM)\nST21: 12-13\n\n\n\n12\n20.01.\nLinear Mixed Models\nST21: 14\nAnalysis (with R scripts)\n\n\n13\n27.01.\nR Markdown for Reports\n\n\n\n\n14\n03.02.\nTroubleshooting Your Report\n\nSend Questions via Email\n\n\n\n10.02.\nReproducible Research\nST21: 18\nReport (with R Markdown)"
  },
  {
    "objectID": "W11_GLMinR.html#setup",
    "href": "W11_GLMinR.html#setup",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Setup",
    "text": "Setup\nWe will use the data by Zhang et al. (2014), Study 3 (Click here to download)\nThe study design was a 2x2 design:\n\ntime (time1, time2) - within-subjects IV\nevent (ordinary vs. extraordinary) - between-subjects IV\nDV: interest",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W11_GLMinR.html#data-wrangling",
    "href": "W11_GLMinR.html#data-wrangling",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Data Wrangling",
    "text": "Data Wrangling\nTasks:\n\nRead in the data file\n\nSelect the three columns we need\n\nAdd a column of subject IDs using the row number\n\nTidy the data: bring it into long format\n\nRecode the values of Condition from numeric to text labels\n\nRecode the values of time to be easier to read/write\n\nChange the data type of Condition and time to be factors!\n\nReplace the “NULLs” to achieve all this step by step…\n\nzhang_data2 &lt;- read_csv(\"Zhang et al. 2014 Study 3.csv\") %&gt;% \n  select(NULL, NULL, NULL) %&gt;% \n  mutate(subject = NULL) %&gt;% \n  NULL(names_to = \"time\", values_to = \"interest\", \n       cols = c(T1_Predicted_Interest_Composite, T2_Actual_Interest_Composite)) %&gt;%\n  mutate(Condition = Condition %&gt;% NULL(\"1\" = \"Ordinary\", \"2\" = \"Extraordinary\"),\n         time = time %&gt;% NULL(\"T1_Predicted_Interest_Composite\" = \"Time 1 (Predicted)\", \n                              \"T2_Actual_Interest_Composite\" = \"Time 2 (Actual)\"),\n         NULL = as.factor(NULL))",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W11_GLMinR.html#data-wrangling-solution",
    "href": "W11_GLMinR.html#data-wrangling-solution",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Data Wrangling: Solution",
    "text": "Data Wrangling: Solution\n\nzhang_data2 &lt;- read_csv(\"Data/Zhang et al. 2014 Study 3.csv\") %&gt;%\n  select(Condition, T1_Predicted_Interest_Composite, T2_Actual_Interest_Composite) %&gt;%\n  mutate(subject = row_number()) %&gt;%\n  pivot_longer(names_to = \"time\", values_to = \"interest\", \n               cols = c(T1_Predicted_Interest_Composite, T2_Actual_Interest_Composite)) %&gt;%\n  mutate(Condition = Condition %&gt;% recode(\"1\" = \"Ordinary\", \"2\" = \"Extraordinary\") %&gt;% as.factor(),\n         time = time %&gt;% recode(\"T1_Predicted_Interest_Composite\" = \"Time 1\", \n                                \"T2_Actual_Interest_Composite\" = \"Time 2\") %&gt;% as.factor())\n\n\n\nIf you plan ahead, you can also use rename prior to pivot_longer to substitute the recode of time. This has the advantage that you can use the shorter names already in pivot_longer (but may be harder to read because the recoding of time and Condition now occur in different places):\n\nzhang_data2 &lt;- read_csv(\"Data/Zhang et al. 2014 Study 3.csv\") %&gt;%\n  select(Condition, T1_Predicted_Interest_Composite, T2_Actual_Interest_Composite) %&gt;%\n  mutate(subject = row_number()) %&gt;%\n  rename(`Time 1` = T1_Predicted_Interest_Composite, #use backticks for column names that include spaces\n         `Time 2` = T2_Actual_Interest_Composite) %&gt;% \n  pivot_longer(names_to = \"time\", values_to = \"interest\", \n               cols = c(\"Time 1\", \"Time 2\")) %&gt;%\n  mutate(Condition = Condition %&gt;% recode(\"1\" = \"Ordinary\", \"2\" = \"Extraordinary\") %&gt;% as.factor(),\n         time = time %&gt;%  as.factor())",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W11_GLMinR.html#descriptive-statistics",
    "href": "W11_GLMinR.html#descriptive-statistics",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\nCalculate descriptive statistics (mean, SD, and N) for interest summarized for each Condition and each time. Store the results in a variable called sum_dat_factorial.\n\n\nsum_dat_factorial &lt;- zhang_data2 %&gt;% \n  summarise(mean_interest = mean(interest, na.rm=TRUE),\n            sd_interest = sd(interest, na.rm=TRUE),\n            n = interest %&gt;% na.omit() %&gt;% length(), #can also use n() but works incorrectly if NA values exist\n            .by = c(Condition, time))\nsum_dat_factorial\n\n# A tibble: 4 × 5\n  Condition     time   mean_interest sd_interest     n\n  &lt;fct&gt;         &lt;fct&gt;          &lt;dbl&gt;       &lt;dbl&gt; &lt;int&gt;\n1 Ordinary      Time 1          4.04        1.09    64\n2 Ordinary      Time 2          4.73        1.24    64\n3 Extraordinary Time 1          4.36        1.13    66\n4 Extraordinary Time 2          4.65        1.14    66",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W11_GLMinR.html#visualize-the-data-violin-boxplot",
    "href": "W11_GLMinR.html#visualize-the-data-violin-boxplot",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Visualize the data: Violin-Boxplot",
    "text": "Visualize the data: Violin-Boxplot\nWrite the code that produces violin-boxplots for the scores in each group. time should be on the x-axis and Condition should be in different colors; interest is on the y-axis. Such plots are called “grouped” (e.g., grouped boxplot).\nHint: You want to add position = position_dodge(width = 0.9) to everything except the violin part to achieve alignment of all parts.\n\n\nggplot(zhang_data2, \n       aes(x = time , y = interest, fill = Condition))+\n  geom_violin(trim = FALSE, alpha = .4) +\n  geom_boxplot(position = position_dodge(.9), \n               width = .2, alpha = .6) +\n  #scale_x_discrete(labels = c(\"Time 1 (Predicted)\", \"Time 2 (Actual)\")) + \n  scale_fill_viridis_d(option = \"E\") +\n  stat_summary(fun = \"mean\", geom = \"point\",\n               position = position_dodge(width = 0.9)) +\n  stat_summary(fun.data = \"mean_se\", geom = \"errorbar\", width = .1,\n               position = position_dodge(width = 0.9)) +\n  theme_minimal()",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W11_GLMinR.html#interaction-line-plot",
    "href": "W11_GLMinR.html#interaction-line-plot",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Interaction (line) plot",
    "text": "Interaction (line) plot\nIn this visualization, we want to look at time and Condition to see whether an interaction might be present. It is helpful to make a line plot with time on the x-axis, Condition as separate lines, and (mean) interest on the y-axis.\n\nlineplot &lt;- sum_dat_factorial %&gt;% mutate(se_interest = sd_interest / sqrt(n)) %&gt;% \n  ggplot(aes(x = time, y = mean_interest, group = Condition, shape = Condition)) +\n  geom_errorbar(aes(ymin = mean_interest - se_interest, ymax = mean_interest + se_interest), width=.5) +\n  geom_point(size = 5) +\n  geom_line(aes(linetype = Condition)) +\n  #scale_x_discrete(labels = c(\"Time 1\", \"Time 2\")) + #this is how you could change x-axis labels\n  theme_classic()\nlineplot\n\n\n\nThe increase in interest between time 1 and 2 seems greater in the ordinary condition! But is this interaction effect significant?\nNote: You may want to add position = position_dodge(.5) to all geoms to avoid an overlap of errorbars.\nNote2: The (between-subject) errorbars are only helpful to interpret the significance of the between-subject effect Condition (at each time point). For the within-subject effect of time, we would need the mean and standard error of the paired differences (but this is very hard to visualize).",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W11_GLMinR.html#mixed-anova",
    "href": "W11_GLMinR.html#mixed-anova",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Mixed ANOVA",
    "text": "Mixed ANOVA\nWe now want to run a mixed ANOVA. It is called “mixed” because it includes both between- and within-subjects factors.\n\nComplete the below code to run the factorial ANOVA. Remember that you will need to specify both IVs and that one of them is between-subjects and one of them is within-subjects. Look up the help documentation for aov_ez to find out how to do this.\nSave the ANOVA model to an object called mod_factorial\nRun the code and inspect the result. Now, try to pull out the ANOVA table only. You can either do this with mod_factorial$anova_table or anova(mod_factorial). Hint: You can use tidy() to save the output table as a data frame, which might be useful.\n\n\nmod_factorial &lt;- aov_ez(id = \"NULL\",\n                        data = NULL, \n                        between = \"NULL\", \n                        within = \"NULL\",\n                        dv = \"NULL\", \n                        type = 3,\n                        es = \"NULL\") \nNULL %&gt;% tidy()\n\n\n\nmod_factorial &lt;- aov_ez(id = \"subject\",\n                        data = zhang_data2, \n                        between = \"Condition\", \n                        within = \"time\",\n                        dv = \"interest\", \n                        type = 3,\n                        es = \"pes\") \nanova(mod_factorial) %&gt;% tidy() #or mod_factorial$anova_table %&gt;% tidy()\n\n# A tibble: 3 × 7\n  term           num.Df den.Df   MSE statistic     ges    p.value\n  &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n1 Condition           1    128 2.05      0.463 0.00278 0.498     \n2 time                1    128 0.607    25.9   0.0441  0.00000126\n3 Condition:time      1    128 0.607     4.44  0.00786 0.0370    \n\napa::anova_apa(mod_factorial) #or use this for apa format\n\n          Effect                                                \n1    (Intercept) F(1, 128) = 2505.82, p &lt; .001, petasq = .95 ***\n2      Condition F(1, 128) =    0.46, p = .498, petasq &lt; .01    \n3           time F(1, 128) =   25.88, p &lt; .001, petasq = .17 ***\n4 Condition:time F(1, 128) =    4.44, p = .037, petasq = .03 *",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W11_GLMinR.html#mixed-anova-results",
    "href": "W11_GLMinR.html#mixed-anova-results",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Mixed ANOVA Results",
    "text": "Mixed ANOVA Results\n\n\n\n          Effect                                                \n1    (Intercept) F(1, 128) = 2505.82, p &lt; .001, petasq = .95 ***\n2      Condition F(1, 128) =    0.46, p = .498, petasq &lt; .01    \n3           time F(1, 128) =   25.88, p &lt; .001, petasq = .17 ***\n4 Condition:time F(1, 128) =    4.44, p = .037, petasq = .03 *  \n\n\n\nConclusion: The main effect of time and the interaction between time and Condition are significant. Judged by visual inspection of the plot, interest increases over time, especially for the “ordinary” group.",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W11_GLMinR.html#assumption-checking",
    "href": "W11_GLMinR.html#assumption-checking",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Assumption Checking",
    "text": "Assumption Checking\nThe assumptions for a factorial ANOVA are the same as the one-way ANOVA.\n\nThe DV is continuous (interval or ratio data)\nThe observations should be independent (only true for between-subjects variables!)\nThe residuals should be normally distributed\nThere should be homogeneity of variance between the groups\n\nTo test assumption 3, extract the residuals from the model, create a QQ-Plot and conduct a Shapiro-Wilk test. For assumption 4, we use the Levene test for homogeneity of variance.\n\n\n# normality testing\ncar::qqPlot(mod_factorial$lm$residuals)\n\n\n\n\n\n\n\n\n[1] 203  73\n\nshapiro.test(mod_factorial$lm$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mod_factorial$lm$residuals\nW = 0.98325, p-value = 0.003785\n\n# levene's test\n#afex::test_levene(mod_factorial) #old version\nperformance::check_homogeneity(mod_factorial)\n\nOK: There is not clear evidence for different variances across groups (Levene's Test, p = 0.893).",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W11_GLMinR.html#write-up",
    "href": "W11_GLMinR.html#write-up",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Write Up",
    "text": "Write Up\nWhat do we need to report?\n\n\nSummary statistics (means, SDs, N) per cell\nF(df1, df2) = F-value, p = p-value, effect size per effect (apa package!)\nA visualization of the most important effect(s) in the data\nPossibly pairwise contrasts (or t-tests)\nInterpretation (direction of effect and theoretical meaning)\n\n\n\nExample how to use the apa package for reporting (you want print=F and :\nWe found a main effect of time (`r apa::anova_apa(mod_factorial, print=F, format=\"markdown\") %&gt;% filter(effect==\"time\") %&gt;% pull(text)`) with interest increasing from the first time point (*M* = `r zhang_data2 %&gt;% summarise(m = mean(interest, na.rm=TRUE), .by = c(time)) %&gt;% filter(time %&gt;% grepl(\"1\", ., fixed=T)) %&gt;% pull(m) %&gt;% signif(3)`) to the second (*M* = `r zhang_data2 %&gt;% summarise(m = mean(interest, na.rm=TRUE), .by = c(time)) %&gt;% filter(time %&gt;% grepl(\"1\", ., fixed=T)) %&gt;% pull(m) %&gt;% signif(3)`). This effect was superseded by an interaction of time and condition (`r apa::anova_apa(mod_factorial, print=F, format=\"markdown\") %&gt;% filter(effect==\"Condition:time\") %&gt;% pull(text)`) [...].\nWe found a main effect of time (F(1, 128) = 25.88, p &lt; .001, petasq = .17) with interest increasing from the first time point (M = 4.2) to the second (M = 4.2). This effect was superseded by an interaction of time and condition (F(1, 128) = 4.44, p = .037, petasq = .03) […].\n\n\n\nHint: You can add gsub to insert the greek letter for eta: gsub(\"petasq\", \"$\\\\eta_p^2$\", ., fixed=T)\nWe found a main effect of time (`r apa::anova_apa(mod_factorial, print=F, format=\"markdown\") %&gt;% filter(effect==\"time\") %&gt;% pull(text) %&gt;% gsub(\"petasq\", \"$\\\\eta_p^2$\", ., fixed=T)`) [...]\nWe found a main effect of time (F(1, 128) = 25.88, p &lt; .001, \\(\\eta_p^2\\) = .17) […]",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W11_GLMinR.html#setup-1",
    "href": "W11_GLMinR.html#setup-1",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Setup",
    "text": "Setup\nWe will use the data from this paper: Przybylski, A. & Weinstein, N. (2017). A Large-Scale Test of the Goldilocks Hypothesis.\nIn the paper, the authors investigated whether there is a “just right” amount of screen time that is associated with higher well-being.\nIn this huge dataset (\\(N=120,000\\)), we have the following variables that we will use for analysis:\n\na continuous DV, well-being (Warwick-Edinburgh Mental Well-Being Scale; WEMWBS). This is a 14-item scale with 5 response categories, summed together to form a single score ranging from 14-70 (so it’s not completely continuous…),\na continuous predictor/IV: screen time,\na categorical predictor/IV: gender.",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W11_GLMinR.html#tasks",
    "href": "W11_GLMinR.html#tasks",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Tasks",
    "text": "Tasks\n\nDownload wellbeing.csv, participant_info.csv and screen_time.csv and save them in your project folder. Make sure that you do not change the file names at all.\nLoad the CSV datasets into variables called pinfo, wellbeing, and screen using read_csv().\nTake a look at the data and make sure you understand what you see.\n\n\n \n\nThe wellbeing tibble has information from the WEMWBS questionnaire,\nscreen has information about screen time use on weekends (variables ending with “we”) and weekdays (variables ending with “wk”) for four types of activities:\n\nusing a computer (variables starting with “Comph”; Q10 on the survey)\nplaying video games (variables starting with “Comp”; Q9 on the survey)\nusing a smartphone (variables starting with “Smart”; Q11 on the survey), and\nwatching TV (variables starting with “Watch”; Q8 on the survey).",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W11_GLMinR.html#preprocessing",
    "href": "W11_GLMinR.html#preprocessing",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Preprocessing",
    "text": "Preprocessing\nCalculate the WEMWBS scores by taking the sum of all the items:\n\nWrite the code to create a new table called wemwbs with two variables: Serial (the participant ID), and tot_wellbeing, the total WEMWBS score.\nyou might have to “pivot” the data from wide to long format and use .by to calculate the well-being (WEMWBS) score per person.\nverify for yourself that the scores all fall in the 14-70 range. Przybylski and Weinstein reported a mean of 47.52 with a standard deviation of 9.55. Can you reproduce these values?\n\n\n\nwemwbs = wellbeing %&gt;%\n  pivot_longer(names_to = \"var\", values_to = \"score\", cols = -Serial) %&gt;%\n  summarise(tot_wellbeing = sum(score), .by=Serial)\n\n# you could also mutate(tot_wellbeing = WBOptimf + ...) \n# but it is easier to use \"across\" and \"filter\" the variable names\n\nwemwbs = wellbeing %&gt;% mutate(tot_wellbeing = rowSums(across(starts_with(\"WB\")))) %&gt;% \n  select(Serial, tot_wellbeing)\n\n# sanity check values\n\nwemwbs %&gt;% summarise(mean = mean(tot_wellbeing),\n                     sd = sd(tot_wellbeing),\n                     min = min(tot_wellbeing), \n                     max = max(tot_wellbeing))\n\n      mean       sd min max\n1 47.52189 9.546374  14  70",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W11_GLMinR.html#data-visualization",
    "href": "W11_GLMinR.html#data-visualization",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Data Visualization",
    "text": "Data Visualization\nWe now want to visualize the relationship between screen time (for the four different technologies) and well-being.\nRun the code below and write comments in the code that explain what each line of code is doing:\n\nscreen_long &lt;- screen %&gt;%\n  pivot_longer(names_to = \"var\", values_to = \"hours\", -Serial) %&gt;%\n  separate(var, c(\"variable\", \"day\"), \"_\")\n\nscreen2 &lt;- screen_long %&gt;%\n  mutate(variable = variable %&gt;% recode(\"Watch\" = \"Watching TV\",\n                                        \"Comp\" = \"Playing Video Games\",\n                                        \"Comph\" = \"Using Computers\",\n                                        \"Smart\" = \"Using Smartphone\"),\n         day = day %&gt;% recode(\"wk\" = \"Weekday\", \"we\" = \"Weekend\"))\n\ndat_means &lt;- inner_join(wemwbs, screen2, \"Serial\") %&gt;%\n  summarise(mean_wellbeing = mean(tot_wellbeing), .by=c(variable, day, hours))\n\nmeanplot = dat_means %&gt;% ggplot(aes(hours, mean_wellbeing, linetype = day)) +\n  geom_line() +\n  geom_point() +\n  facet_wrap(vars(variable), nrow = 2)",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W11_GLMinR.html#data-visualization-interpretation",
    "href": "W11_GLMinR.html#data-visualization-interpretation",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Data Visualization: Interpretation",
    "text": "Data Visualization: Interpretation\nDescribe what you see in the figures/plots that you get when running the code.\n\n\nThere seems to be a peak at roughly 1h/day for well-being for all sorts of screen time.",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W11_GLMinR.html#data-wrangling-1",
    "href": "W11_GLMinR.html#data-wrangling-1",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Data Wrangling",
    "text": "Data Wrangling\nWe need to do a few things to get a dataset that we can use for analysis:\n\nCreate a new table, smarttot, that has the mean number of hours per day of smartphone use for each participant, averaged over weekends/weekdays.\n\n\nYou will need to filter the dataset to only include smartphone use and not other technologies.\n\nThe final data set should have two variables: Serial (the participant) and tothours. In this step, you will need to summarise the data.\n\nYou will also need to group the summary by the participant ID (i.e., serial).\n\nYou will need to use the dataset screen2 to do this.\n\n\n\nsmarttot &lt;- screen2 %&gt;%\n  filter(variable == \"Using Smartphone\") %&gt;%\n  summarise(tothours = mean(hours), .by=Serial)\n\n\n\n\nNext, create a new tibble called smart_wb that only includes participants from smarttot who used a smartphone for more than one hour per day each week and then combine (join) this table with the information in wemwbs and pinfo.\n\n\n\n\nsmart_wb &lt;- smarttot %&gt;%\n  filter(tothours &gt; 1) %&gt;%\n  inner_join(wemwbs, \"Serial\") %&gt;%\n  inner_join(pinfo, \"Serial\")",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W11_GLMinR.html#data-wrangling-2",
    "href": "W11_GLMinR.html#data-wrangling-2",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Data Wrangling 2",
    "text": "Data Wrangling 2\nWhen you do regression analysis, it is helpful to mean center your continuous (independent) variables. You mean center a predictor X simply by subtracting the mean (X_centered = X - mean(X)). This has two useful consequences:\n\nthe model intercept reflects the prediction for Y at the mean value of the predictor variable, rather than at the zero value of the original variable;\nif there are interactions in the model, any lower-order effects can be given the same interpretation as they receive in ANOVA (main effects, rather than simple effects). (Don’t worry if you don’t understand what this means yet!)\n\nIf you mean-center categorical predictors with two levels, these become coded as \\(-.5\\) and \\(.5\\) (because the mean of these two values is 0). This is also handy and is called effects coding. (Not exactly true for unequal group sizes! So rather use if_else() function and assign \\(-.5\\) and \\(.5\\))",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W11_GLMinR.html#tasks-1",
    "href": "W11_GLMinR.html#tasks-1",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Tasks",
    "text": "Tasks\n\nUse mutate to add two new variables to smart_wb: tothours_c, calculated as a mean-centered version of the tothours predictor; and male_c, recoded as \\(-.5\\) for female and \\(.5\\) for male.\nTo create male_c you will need to use if_else(male == 1, .5, -.5)\n(Read as: “If the variable male equals 1, switch it to \\(.5\\), if not, switch it to \\(-.5\\)”.)\nFinally, recode male and male_c as factors, so that R knows not to treat them as real numbers.\n\n\n\nsmart_wb &lt;- smarttot %&gt;%\n  filter(tothours &gt; 1) %&gt;%\n  inner_join(wemwbs, \"Serial\") %&gt;%\n  inner_join(pinfo, \"Serial\") %&gt;%\n  mutate(thours_c = tothours - mean(tothours),\n         #thours_c = tothours %&gt;% scale(), #alternative, also scales the variable to SD=1\n         male_c = if_else(male == 1, .5, -.5) %&gt;% as_factor(),\n         male = as_factor(male))",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W11_GLMinR.html#data-visualization-2",
    "href": "W11_GLMinR.html#data-visualization-2",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Data Visualization 2",
    "text": "Data Visualization 2\nTry to recreate the following plot:\n\n\nsmart_wb_gen &lt;- smart_wb %&gt;%\n  summarise(mean_wellbeing = mean(tot_wellbeing), .by= c(tothours, male))\n\nggplot(NULL, aes(NULL, NULL, color = NULL)) +\n  geom_NULL() +  # which geom to use for the points?\n  geom_NULL(method = \"lm\") + # which geom for the lines?\n  scale_color_discrete(name = \"Gender\", labels = c(\"Female\", \"Male\"))+\n  scale_x_continuous(name = \"Total hours smartphone use\") +\n  scale_y_continuous(name = \"Mean well-being score\") + \n  theme_bw()",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W11_GLMinR.html#data-visualization-2-solution",
    "href": "W11_GLMinR.html#data-visualization-2-solution",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Data Visualization 2: Solution",
    "text": "Data Visualization 2: Solution\n\nsmart_wb_gen &lt;- smart_wb %&gt;%\n  summarise(mean_wellbeing = mean(tot_wellbeing), .by = c(tothours, male))\n\nggplot(smart_wb_gen, aes(tothours, mean_wellbeing, color = male)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  scale_color_discrete(name = \"Gender\", labels = c(\"Female\", \"Male\"))+\n  scale_x_continuous(name = \"Total hours smartphone use\") +\n  scale_y_continuous(name = \"Mean well-being score\") + \n  theme_bw()",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W11_GLMinR.html#analysis",
    "href": "W11_GLMinR.html#analysis",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Analysis",
    "text": "Analysis\nTry to specify the following regression model in R:\n\\(Y_i = \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\beta_3 X_{3i} + e_i\\)\nwhere\n\n\\(Yi\\) is the well-being score for participant i;\n\\(X1i\\) is the mean-centered smartphone use variable for participant i;\n\\(X2i\\) is gender (\\(-.5\\) = female, \\(.5\\) = male);\n\\(X3i\\) is the interaction between smartphone use and gender (=\\(X1i×X2i\\))\n\n\nmod &lt;- lm(NULL ~ NULL, data = smart_wb)\n\nmod_summary &lt;- summary(mod)",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W11_GLMinR.html#analysis-result",
    "href": "W11_GLMinR.html#analysis-result",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Analysis: Result",
    "text": "Analysis: Result\n\nmod &lt;- lm(tot_wellbeing ~ thours_c * male_c, data = smart_wb)\n#mod &lt;- lm(tot_wellbeing ~ thours_c + male_c + thours_c:male_c, data = smart_wb)\n\nmod_summary &lt;- summary(mod)\nmod_summary\n\n\nCall:\nlm(formula = tot_wellbeing ~ thours_c * male_c, data = smart_wb)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-36.881  -5.721   0.408   6.237  27.264 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        44.86740    0.04478 1001.87   &lt;2e-16 ***\nthours_c           -0.77121    0.02340  -32.96   &lt;2e-16 ***\nmale_c0.5           5.13968    0.07113   72.25   &lt;2e-16 ***\nthours_c:male_c0.5  0.45205    0.03693   12.24   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.135 on 71029 degrees of freedom\nMultiple R-squared:  0.09381,   Adjusted R-squared:  0.09377 \nF-statistic:  2451 on 3 and 71029 DF,  p-value: &lt; 2.2e-16\n\n\nBy which variable in the output is the interaction between smartphone use and gender shown? Is it significant?\nHow would you interpret the results?",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W11_GLMinR.html#assumption-checking-1",
    "href": "W11_GLMinR.html#assumption-checking-1",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Assumption checking",
    "text": "Assumption checking\nHere are the assumptions for multiple regression:\n\nThe outcome/DV is continuous (interval/ratio level data)\nThe predictor variable is interval/ratio or categorical\nAll values of the outcome variable are independent (i.e., each score should come from a different participant)\nThe predictors have non-zero variance\nThe relationship between outcome and predictor is linear\nThe residuals should be normally distributed\nThere should be homoscedasticity (homogeneity of variance, but for the residuals)\nMulticollinearity: predictor variables should not be too highly correlated\n\nFrom the work we’ve done so far we know that assumptions 1 - 4 are met and we can use the functions from the performance package again to check the rest (this will take a while because the dataset is so huge)",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W11_GLMinR.html#assumption-checking-2",
    "href": "W11_GLMinR.html#assumption-checking-2",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Assumption checking 2",
    "text": "Assumption checking 2\n\n# qqPlot(mod$residuals)\n# check_model(mod, check = c(\"vif\", \"qq\", \"normality\", \"linearity\", \"homogeneity\"))\n\n(Note: the line in the homogeneity plot is missing due to the large amount of data. Check out the textbook for a solution as well as for further information on what these measures mean.)",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W11_GLMinR.html#further-analysis-of-interaction",
    "href": "W11_GLMinR.html#further-analysis-of-interaction",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Further Analysis of Interaction",
    "text": "Further Analysis of Interaction\nWe can use emmeans package to further investigate the direction of the interaction. This is especially handy if we have more than two factor levels and can’t read out the direction of the effect from the model summary.\nSpecifically, we’re using the emtrends() function, because we have a continuous variable and want to know the (simple) slope/trend of this variable within each of the factor levels of the categorical variable:\n\nsimple_slopes_interaction &lt;- emtrends(mod, ~male_c|thours_c, var=\"thours_c\")\nsimple_slopes_interaction\n\nthours_c = -3.41e-16:\n male_c thours_c.trend     SE    df lower.CL upper.CL\n -0.5           -0.771 0.0234 71029   -0.817   -0.725\n 0.5            -0.319 0.0286 71029   -0.375   -0.263\n\nConfidence level used: 0.95 \n\ntest(simple_slopes_interaction)  # with the test() function, you can get the p-value to test whether the slope within each group is sign. different from 0!\n\nthours_c = -3.41e-16:\n male_c thours_c.trend     SE    df t.ratio p.value\n -0.5           -0.771 0.0234 71029 -32.956  &lt;.0001\n 0.5            -0.319 0.0286 71029 -11.170  &lt;.0001",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W11_GLMinR.html#power-effect-size",
    "href": "W11_GLMinR.html#power-effect-size",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Power & Effect Size",
    "text": "Power & Effect Size\nUse this code to calculate the minimum effect size for \\(99\\%\\) power and the empirical effect size:\n\n#minimum effect size needed: set f2 (effect size) to NULL so it will be calculated\npwr.f2.test(u = 3, v = 71029, f2 = NULL, sig.level = .05, power = .99)\n\n\n     Multiple regression power calculation \n\n              u = 3\n              v = 71029\n             f2 = 0.0003673651\n      sig.level = 0.05\n          power = 0.99\n\nf2.empirical &lt;- mod_summary$adj.r.squared/(1 - mod_summary$adj.r.squared)\nf2.empirical #empirical effect size\n\n[1] 0.1034697\n\n\nIs the study adequately powered?",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W11_GLMinR.html#write-up-1",
    "href": "W11_GLMinR.html#write-up-1",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Write Up",
    "text": "Write Up\nFor the write up, you can copy this text block, including inline code (wrapped by R) to directly use the output of R in your text. If you then knit your document, it will insert the values:\nAll continuous predictors were mean-centered and deviation coding was used for categorical predictors. The results of the regression indicated that the model significantly predicted course engagement (*F*(`r mod_summary$fstatistic[2]`, `r mod_summary$fstatistic[3] %&gt;% round(2)`) = `r mod_summary$fstatistic[1] %&gt;% round(2)`, *p* \\&lt; .001, adjusted *R*^2 = `r mod_summary$adj.r.squared %&gt;% round(2)`, f^2^ = .63), accounting for `r (mod_summary$adj.r.squared %&gt;% round(2))*100`% of the variance. Total screen time was a significant negative predictor of wellbeing scores (β = `r mod$coefficients[2] %&gt;% round(2)`, *p* \\&lt; .001), as was gender (β = `r mod$coefficients[3] %&gt;% round(2)`, *p* \\&lt; .001), with girls having lower wellbeing scores than boys. Importantly, there was a significant interaction between screentime and gender (β = `r mod$coefficients[4] %&gt;% round(2)`, *p* \\&lt; .001): Smartphone use was more negatively associated with wellbeing for girls than for boys.\n\nAll continuous predictors were mean-centered and deviation coding was used for categorical predictors. The results of the regression indicated that the model significantly predicted course engagement (F(3, 7.1029^{4}) = 2450.89, p &lt; .001, adjusted R^2 = 0.09, f2 = .63), accounting for 9% of the variance. Total screen time was a significant negative predictor of wellbeing scores (β = -0.77, p &lt; .001), as was gender (β = 5.14, p &lt; .001), with girls having lower wellbeing scores than boys. Importantly, there was a significant interaction between screentime and gender (β = 0.45, p &lt; .001): Smartphone use was more negatively associated with wellbeing for girls than for boys.",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W11_GLMinR.html#write-up-2",
    "href": "W11_GLMinR.html#write-up-2",
    "title": "11 ANOVA & the General Linear Model in R",
    "section": "Write Up 2",
    "text": "Write Up 2\nYou can also use the report() function from the report package to get a suggestion for what to report from your results (it would still need some editing!):\n\n# report(mod)",
    "crumbs": [
      "11 ANOVA & the General Linear Model in R"
    ]
  },
  {
    "objectID": "W13_RMarkdown.html#comparison-r-vs.-r-markdown-1",
    "href": "W13_RMarkdown.html#comparison-r-vs.-r-markdown-1",
    "title": "13 R Markdown",
    "section": "Comparison: R vs. R Markdown 1",
    "text": "Comparison: R vs. R Markdown 1\n\n\n\nR script\n\n\n\n\n\n\nR Markdown",
    "crumbs": [
      "13 R Markdown"
    ]
  },
  {
    "objectID": "W13_RMarkdown.html#comparison-r-vs.-r-markdown-2",
    "href": "W13_RMarkdown.html#comparison-r-vs.-r-markdown-2",
    "title": "13 R Markdown",
    "section": "Comparison: R vs. R Markdown 2",
    "text": "Comparison: R vs. R Markdown 2\n\n\n\nR Markdown\n\n\n\n\n\nR Markdown rendered as html report",
    "crumbs": [
      "13 R Markdown"
    ]
  },
  {
    "objectID": "W13_RMarkdown.html#your-first-r-markdown-script",
    "href": "W13_RMarkdown.html#your-first-r-markdown-script",
    "title": "13 R Markdown",
    "section": "Your First R Markdown Script",
    "text": "Your First R Markdown Script\n\nCreate a new .Rmd file, change/insert the title and author.\nCheck out the content of it. What different parts do you see?\n\n\n\nSwitch between “Source” and “Visual” in the top left. What changes? What is “Visual”?\n\n\n\n\nDelete and add some of the text on the white background. Change the Header (indicated by ##) to “About me” and write something about yourself underneath.\nIn the grey boxes (“code chunks”), add some code. Try to find out how you can add a new code chunk.\n\n\n\n\nSave the file with a sensible name.\nWhat happens when you click on “Knit” (top of Script pane)?\n\n\n\nhint: The green C with the + on the top right will do so (or using “insert” in the visual view)\nClick on the little arrow next to knit and select “Knit to PDF”\ninsert inline code",
    "crumbs": [
      "13 R Markdown"
    ]
  },
  {
    "objectID": "W13_RMarkdown.html#r-markdown-advantages",
    "href": "W13_RMarkdown.html#r-markdown-advantages",
    "title": "13 R Markdown",
    "section": "R Markdown Advantages",
    "text": "R Markdown Advantages\nThere are many useful things you can do with R Markdown (adding different headers, adding inline code, knitting as a PDF, adding pictures or tables…). You can also decide whether each code chunk should be visible in the output, etc.\nExample: \n```{r, echo=TRUE, eval=FALSE}\n#your code here that will only be shown but not be executed\n```\nFor further information, check out the R Markdown cheatsheet: https://rmarkdown.rstudio.com/lesson-15.HTML",
    "crumbs": [
      "13 R Markdown"
    ]
  },
  {
    "objectID": "W13_RMarkdown.html#code-chunk-options",
    "href": "W13_RMarkdown.html#code-chunk-options",
    "title": "13 R Markdown",
    "section": "Code Chunk Options",
    "text": "Code Chunk Options\n\nYou can change these default values for code chunks for the rest of your document:\n```{r, include=FALSE}\nknitr::opts_chunk$set(\n  echo = FALSE, #this is a good default for your report\n  fig.width = 6, fig.height = 6\n)\n```\nFore more information, see https://yihui.org/knitr/options/",
    "crumbs": [
      "13 R Markdown"
    ]
  },
  {
    "objectID": "W13_RMarkdown.html#from-an-r-script-to-r-markdown",
    "href": "W13_RMarkdown.html#from-an-r-script-to-r-markdown",
    "title": "13 R Markdown",
    "section": "From an R script to R Markdown",
    "text": "From an R script to R Markdown\nPreviously, we have just worked with .R scripts. If you have a full R script with your entire analysis (or even several scripts), how do you include them in an R Markdown file?\n\nOption 1: Copy all code into one giant code chunk:\n```{r}\n#copy all code here\n```\nYou can break this code chunk apart into smaller ones by copying this into a new line of the code chunk:\n```\n\n```{r}\n\nseparate code chunks make sense for two reasons:\n\nit helps you structure different steps of your data analysis (e.g., data wrangling, data visualization, and different analyses)\n⇒ naming code chunks can greatly support your structure!\nif you want different chunk options for parts of your code (e.g., echo=TRUE for certain lines of code ⇒ put them into a separate code chunk)",
    "crumbs": [
      "13 R Markdown"
    ]
  },
  {
    "objectID": "W13_RMarkdown.html#from-an-r-script-to-r-markdown-2",
    "href": "W13_RMarkdown.html#from-an-r-script-to-r-markdown-2",
    "title": "13 R Markdown",
    "section": "From an R script to R Markdown 2",
    "text": "From an R script to R Markdown 2\nOption 2: “Import” the R script and run it with the source function:\n```{r message=FALSE, warning=FALSE}\nsource(\"analysis.R\", #your R script here (same folder as your project)\n       local = knitr::knit_global())\n```\nYou can now use all variables that you have created in your R script. But you cannot show individual code chunks (echo = TRUE).",
    "crumbs": [
      "13 R Markdown"
    ]
  },
  {
    "objectID": "W13_RMarkdown.html#your-second-r-markdown-script",
    "href": "W13_RMarkdown.html#your-second-r-markdown-script",
    "title": "13 R Markdown",
    "section": "Your Second R Markdown Script",
    "text": "Your Second R Markdown Script\n\nUse one of the two methods described before to include the R analysis for your report into an R Markdown document.\nOutput the content of any variable of your R script and include it as inline code in some text (Cheat Sheet).\n\n\n```{r}\ndata = tibble(rt = rnorm(n=100, mean=.5, sd=.2))\n```\nWe observed an average reaction time of `r data %&gt;% pull(rt) %&gt;% mean() %&gt;% signif(digits=3)` seconds.\nWe observed an average reaction time of 0.547 seconds.\n\nKnit the document and open the output with a double click.",
    "crumbs": [
      "13 R Markdown"
    ]
  },
  {
    "objectID": "W13_RMarkdown.html#examples-for-your-report-t-test",
    "href": "W13_RMarkdown.html#examples-for-your-report-t-test",
    "title": "13 R Markdown",
    "section": "Examples for your report: t-test",
    "text": "Examples for your report: t-test\n```{r}\ndata = tibble(a = rnorm(n=100, mean=.5, sd=.2)) %&gt;% mutate(b = a - rnorm(n=100, mean=.1, sd=.2))\nmytest = with(data, t.test(a, b, paired=TRUE))\n#mytest %&gt;% apa::t_apa(es_ci=TRUE) #we don't want to print output to the console anymore\n```\nWe performed a paired *t*-test and found a significant difference between both conditions \n(`r mytest %&gt;% apa::t_apa(es_ci=TRUE, print=FALSE, format=\"rmarkdown\")`). In condition A, reaction times were higher \n(*M* = `r data %&gt;% pull(a) %&gt;% mean() %&gt;% signif(3)` s, *SD* = `r data %&gt;% pull(a) %&gt;% sd() %&gt;% signif(3)` s)\ncompared to condition B  (*M* = `r data %&gt;% pull(b) %&gt;% mean() %&gt;% signif(3)` s, *SD* = `r data %&gt;% pull(b) %&gt;% sd() %&gt;% signif(3)` s).\nWe performed a paired t-test and found a significant difference between both conditions (t(99) = 5.38, p &lt; .001, d = 0.54 [0.33; 0.75]). In condition A, reaction times were higher (M = 0.547 s, SD = 0.213 s) compared to condition B (M = 0.439 s, SD = 0.309 s).\n\n\nComment out the code that performes an output to the console. We will replace it with inline code.\nThe apa functions need some tweaking: print=FALSE and format=\"rmarkdown\".\nThe signif() function is your friend! It helps you to show a certain amount of significant digits for output of descriptive data.",
    "crumbs": [
      "13 R Markdown"
    ]
  },
  {
    "objectID": "W13_RMarkdown.html#examples-for-your-report-correlation",
    "href": "W13_RMarkdown.html#examples-for-your-report-correlation",
    "title": "13 R Markdown",
    "section": "Examples for your report: Correlation",
    "text": "Examples for your report: Correlation\n```{r}\nmyCor = with(data, cor.test(a, b))\n#myCor %&gt;% apa::cor_apa(r_ci=TRUE) #we don't want to print output to the console anymore\n```\nWe found a significant Pearson correlation between both conditions\n(`r myCor %&gt;% apa::cor_apa(r_ci=TRUE, print=FALSE, format=\"rmarkdown\")`). \nThose individuals with higher reaction times in condition A \n(*M* = `r data %&gt;% pull(a) %&gt;% mean() %&gt;% signif(3)` s, *SD* = `r data %&gt;% pull(a) %&gt;% sd() %&gt;% signif(3)` s)\nalso performed more slowly in condition B\n(*M* = `r data %&gt;% pull(b) %&gt;% mean() %&gt;% signif(3)` s, *SD* = `r data %&gt;% pull(b) %&gt;% sd() %&gt;% signif(3)` s).\nWe found a significant Pearson correlation between both conditions (r(98) = .76 [.66; .83], p &lt; .001). Those individuals with higher reaction times in condition A (M = 0.547 s, SD = 0.213 s) also performed more slowly in condition B (M = 0.439 s, SD = 0.309 s).",
    "crumbs": [
      "13 R Markdown"
    ]
  },
  {
    "objectID": "W13_RMarkdown.html#examples-for-your-report-anova",
    "href": "W13_RMarkdown.html#examples-for-your-report-anova",
    "title": "13 R Markdown",
    "section": "Examples for your report: ANOVA",
    "text": "Examples for your report: ANOVA\n\nlibrary(afex)\nmodel &lt;- aov_ez(data = data,\n              id = \"subject\", \n              dv = \"performance\", \n              between = \"condition\", \n              within = \"time\",\n              es = \"pes\", type = 3, include_aov = TRUE)\n#apa::anova_apa(model) #we don't want to print output to the console anymore\nanovaTable &lt;- apa::anova_apa(model, print = F, format = \"rmarkdown\") %&gt;% bind_rows()\n\n\n\n# A tibble: 4 × 2\n  effect         text                                                \n  &lt;chr&gt;          &lt;chr&gt;                                               \n1 (Intercept)    \"*F*(1, 98) = 661.36, *p* &lt; .001, $\\\\eta^2_p$ = .87\"\n2 condition      \"*F*(1, 98) = 7.65, *p* = .007, $\\\\eta^2_p$ = .07\"  \n3 time           \"*F*(1, 98) = 6.40, *p* = .013, $\\\\eta^2_p$ = .06\"  \n4 condition:time \"*F*(1, 98) = 0.81, *p* = .370, $\\\\eta^2_p$ &lt; .01\"  \n\n\n\nFor the ANOVA, we also have to call bind_rows() after anova_apa to bind the output into a data frame that we can filter.",
    "crumbs": [
      "13 R Markdown"
    ]
  },
  {
    "objectID": "W13_RMarkdown.html#examples-for-your-report-anova-2",
    "href": "W13_RMarkdown.html#examples-for-your-report-anova-2",
    "title": "13 R Markdown",
    "section": "Examples for your report: ANOVA 2",
    "text": "Examples for your report: ANOVA 2\n```{r}\nanovaTable &lt;- apa::anova_apa(model, print = F, format = \"rmarkdown\") %&gt;% bind_rows()\n```\nWe conducted a $2 \\times 2$ ANOVA with *performance* as dependent variable, the within-subjects factor *time* (Baseline vs. Post), and the between-subjects factor *condition* (Treatment vs. Placebo). \nResults indicated a main effect of *condition* \n`r anovaTable %&gt;% filter(effect==\"condition\") %&gt;% pull(text)` with the treatment group \n(*M* = `r data %&gt;% filter(condition==\"treatment\") %&gt;% summarize(.by = subject, performance = mean(performance)) %&gt;% pull(performance) %&gt;% mean() %&gt;% signif(3)`, *SD* = `r data %&gt;% filter(condition==\"treatment\") %&gt;% summarize(.by = subject, performance = mean(performance)) %&gt;% pull(performance) %&gt;% sd() %&gt;% signif(3)`)\nexhibiting higher performance than the placebo group (*M* = `r data %&gt;% filter(condition==\"placebo\") %&gt;% summarize(.by = subject, performance = mean(performance)) %&gt;% pull(performance) %&gt;% mean() %&gt;% signif(3)`, *SD* = `r data %&gt;% filter(condition==\"placebo\") %&gt;% summarize(.by = subject, performance = mean(performance)) %&gt;% pull(performance) %&gt;% sd() %&gt;% signif(3)`).\nWe also observed a main effect of *time* `r anovaTable %&gt;% filter(effect==\"time\") %&gt;% pull(text)` with performance **decreasing** from baseline (*M* = `r data %&gt;% filter(time==1) %&gt;% pull(performance) %&gt;% mean() %&gt;% signif(3)`, *SD* = `r data %&gt;% filter(time==1) %&gt;% pull(performance) %&gt;% sd() %&gt;% signif(3)`) to post treatment (*M* = `r data %&gt;% filter(time==2) %&gt;% pull(performance) %&gt;% mean() %&gt;% signif(3)`, *SD* = `r data %&gt;% filter(time==2) %&gt;% pull(performance) %&gt;% sd() %&gt;% signif(3)`).\nThe interaction did not reach significance `r anovaTable %&gt;% filter(effect==\"condition:time\") %&gt;% pull(text)`.\nThe effects are depicted in Figure 1.\nWe conducted a \\(2 \\times 2\\) ANOVA with performance as dependent variable, the within-subjects factor time (Baseline vs. Post), and the between-subjects factor condition (Treatment vs. Placebo). Results indicated a main effect of condition F(1, 98) = 7.65, p = .007, \\(\\eta^2_p\\) = .07 with the treatment group (M = 0.433, SD = 0.17) exhibiting higher performance than the placebo group (M = 0.349, SD = 0.131). We also observed a main effect of time F(1, 98) = 6.40, p = .013, \\(\\eta^2_p\\) = .06 with performance decreasing from baseline (M = 0.429, SD = 0.217) to post treatment (M = 0.352, SD = 0.219). The interaction did not reach significance F(1, 98) = 0.81, p = .370, \\(\\eta^2_p\\) &lt; .01. The effects are depicted in Figure 1.\n\n\nanovaTable %&gt;% filter(effect==\"condition\") %&gt;% pull(text) to call the statistical output for an individual effect.\nWhen calculating descriptives (esp. SD) while collapsing across (within-subject) variables, make sure to calculate the mean for each subject first before you summarize across all subjects.",
    "crumbs": [
      "13 R Markdown"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#general-working-with-r-in-this-course",
    "href": "W1b_IntroR.html#general-working-with-r-in-this-course",
    "title": "01b Intro to R",
    "section": "General: Working with R in this course",
    "text": "General: Working with R in this course\nDuring Class\n\nYou should have RStudio open and your Biostats project loaded (we will set up the project today).\nHave the slides open in the background. You will need them to copy R code (top right button on any code chunk) or click on links.\n\n\nprint(\"Hello World\")\n\n[1] \"Hello World\"\n\n\n\nRemember: You can navigate through the slides quickly by clicking on the three dashes in the bottom left.",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#why-write-code",
    "href": "W1b_IntroR.html#why-write-code",
    "title": "01b Intro to R",
    "section": "Why write code?",
    "text": "Why write code?\n\n\nDoing statistical calculation by hand? Tedious & error prone! Computer is faster…\nUsing spreadsheets? Limited options, change data accidentally…\nUsing point-and-click software (e.g., SPSS)?\n\nproprietary software = expensive\nR = open, extensible (community)\nreproducible!\n\nScience/Academia is a marathon and not a sprint\n⇒ it is worthwhile investing in skills with a slow learning curve that will pay off in the long run\n\n\n\nChat: What are advantages (or disadvantages!) of coding?",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#why-write-code-1",
    "href": "W1b_IntroR.html#why-write-code-1",
    "title": "01b Intro to R",
    "section": "Why write code?",
    "text": "Why write code?",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#managing-expectations",
    "href": "W1b_IntroR.html#managing-expectations",
    "title": "01b Intro to R",
    "section": "Managing Expectations",
    "text": "Managing Expectations\n\nYou will learn a new (programming) language. Don’t expect to “speak” it fluently right away.\nDuring class, it is more important that you can roughly comprehend written code and “translate” it into natural language.\nThe second step is to be able to make small adjustments to code that is given to you.\nOnly then, the last step is to be able to produce code yourself (with the help of Google, Stackoverflow, chatgpt, templates of this course, etc. :) ).\nBut: Use it or loose it! Don’t wait to use R in your research projects until you’re “good enough”. It’s more fun to use it on “actual” problems, and makes it much easier to learn.",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#install-r-rstudio",
    "href": "W1b_IntroR.html#install-r-rstudio",
    "title": "01b Intro to R",
    "section": "Install R & RStudio",
    "text": "Install R & RStudio\nYou should all have installed R & RStudio by now! Who had problems doing so?",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#overview-rstudio",
    "href": "W1b_IntroR.html#overview-rstudio",
    "title": "01b Intro to R",
    "section": "Overview RStudio",
    "text": "Overview RStudio\n\nRStudio Interface\nopen R!",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#rstudio-panes",
    "href": "W1b_IntroR.html#rstudio-panes",
    "title": "01b Intro to R",
    "section": "RStudio Panes",
    "text": "RStudio Panes\n\n\n\nScript pane: view, edit, & save your code\nConsole: here the commands are run and rudimentary output may be provided\nEnvironment: which variables/data are available\nFiles, plots, help etc.\n\n\n\n\n\n\n\nRStudio Interface\n\n\n\n\nConsole vs. Script (Rmarkdown later)",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#using-the-console-as-a-calculator",
    "href": "W1b_IntroR.html#using-the-console-as-a-calculator",
    "title": "01b Intro to R",
    "section": "Using the Console as a Calculator",
    "text": "Using the Console as a Calculator\n\n100 + 1\n\n[1] 101\n\n2*3\n\n[1] 6\n\nsqrt(9)\n\n[1] 3\n\n\n\nConsole used as calculator\ntry it out!\nWe can’t really do much with these values, they will just be written in the console.\nAlso: Notice that you have the option to include spaces between commands, i.e., 100 + 1 vs. 100+1.",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#saving-the-results-as-a-variableobject",
    "href": "W1b_IntroR.html#saving-the-results-as-a-variableobject",
    "title": "01b Intro to R",
    "section": "Saving the Results as a Variable/Object",
    "text": "Saving the Results as a Variable/Object\n\na &lt;- 100 + 1\n\nmulti &lt;- 2*3\n\nSqrtOfNine &lt;- sqrt(9)\n\nword &lt;- \"Hello\"\n\n\n\n&lt;- is used to assign values to variables (= is also possible, but discouraged in R)\na, multi etc. are the variable names (some naming rules, e.g., no whitespace, must not start with a number, many special characters not allowed)\n\nYou can find those now in your Environment! (top right panel)\nNo feedback in the console for saving variables (2*3 outputs 6, but multi &lt;- 2*3 doesn’t)\n\nvariables can contain basically anything (words, numbers, entire tables of data …)\nthe variables contain the calculated value (i.e. 101) and not the calculation/formula (100+1)\n\n\nType first command in console, what happens?\nWhy don’t we see anything in the console?\nWhat happens if we type in a in the console?\nIs there anything else that you find interesting?\nWhat is sqrt()?",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#working-with-variables",
    "href": "W1b_IntroR.html#working-with-variables",
    "title": "01b Intro to R",
    "section": "Working with variables",
    "text": "Working with variables\n\na + multi\n\n[1] 107\n\na\n\n[1] 101\n\nmulti\n\n[1] 6\n\n\n\n\nYou can use those variables for further calculations, e.g., a + multi\nNote that neither a nor multi change their value.",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#working-with-variables-1",
    "href": "W1b_IntroR.html#working-with-variables-1",
    "title": "01b Intro to R",
    "section": "Working with variables",
    "text": "Working with variables\n\na\n\n[1] 101\n\na &lt;- 42\n\na\n\n[1] 42\n\n\n\n\nVariables can be overwritten (R won’t warn you about this!)",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#functions",
    "href": "W1b_IntroR.html#functions",
    "title": "01b Intro to R",
    "section": "Functions",
    "text": "Functions\nThis code with sqrt(9) looked unfamiliar. sqrt() is an R function that calculates the square root of a number. 9 is the argument that we hand over to the function.\nIf you want to know what a function does, which arguments it takes, or which output it generates, you can type into the console: ?functionname\n\n\n?sqrt\n\nThis will open the help file in the Help Pane on the lower right of RStudio.\nYou can also click on a function in the script or console pane and press the F1 key.\n\nSometimes, the help page can be a bit overwhelming (lots of technical details etc.). It might help you to scroll down to the examples at the bottom to see the function in action!\n\nDo this now! Anything unclear?",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#functions-1",
    "href": "W1b_IntroR.html#functions-1",
    "title": "01b Intro to R",
    "section": "Functions",
    "text": "Functions\nFunctions often take more than one argument (which have names):\n\n\nrnorm(n = 6, mean = 3, sd = 1)\nrnorm(6, 3, 1) # this outputs the same as above\n\n\nYou can explicitly name your arguments (check the help file for the argument names!) or just state the values (but these have to be in the correct order then! See help file).\n\n\n\n\n\nrnorm(n = 6, mean = 3, sd = 1)\n\nrnorm(6, 3, 1) # this outputs the same as above\nrnorm(sd = 1, n = 6, mean = 3) # still the same result\nrnorm(1, 6, 3) # different result - R thinks n = 1 and mean = 6!",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#comments",
    "href": "W1b_IntroR.html#comments",
    "title": "01b Intro to R",
    "section": "Comments",
    "text": "Comments\n\nrnorm(n = 6, mean = 3, sd = 1)\nrnorm(6, 3, 1) # this outputs the same as above\n\n# By the way, # denotes a comment - very important for documentation!\n# Anything after # will be ignored by R\n# To (un)comment the line you are in/multiple lines you selected: ctrl + shift + C",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#packages",
    "href": "W1b_IntroR.html#packages",
    "title": "01b Intro to R",
    "section": "Packages",
    "text": "Packages\nThere are a number of functions already included with Base R (i.e., R after a new installation), but you can greatly extend the power of R by loading packages (and we will!). Packages can e.g. contain collections of functions someone else wrote, or even data.\nYou should already have the tidyverse installed (if not, quickly run install.packages(\"tidyverse\") :-) )\n\n\n\nBut installing is not enough to be able to actually use the functions from that package directly. Usually, you also want to load the package with the library() function. This is the first thing you do at the top of an R script:\n\nlibrary(\"tidyverse\") # or library(tidyverse)\n\n\n\n\n\n(If you don’t load a package, you have to call functions explicitly by packagename::function)\n\nOpen Source! Anyone can write a package!\nBase R = mobile phone, comes with some functions, packages = apps\npossibly necessary to install Rtools!",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#new-project",
    "href": "W1b_IntroR.html#new-project",
    "title": "01b Intro to R",
    "section": "New Project",
    "text": "New Project\n\n\nCreate a new project by clicking on “File” on the top left and then “New Project…”\nSelect “New Directory” (if you already have a folder for this course, you can choose “Existing directory” and select that folder) and then choose “New Project” at the top of the list.\nChoose a project name, e.g., as “Biostats” (this will create a folder in which the project lives)\nBrowse where you want to put your project folder (e.g., “D:/Documents/Studies/Translational Neuroscience/”)\n\n\nPS: R can deal with folder and file names that contain spaces, but since some programms can’t, it’s best practice not to use whitespaces for file/folder naming.",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#existing-projects",
    "href": "W1b_IntroR.html#existing-projects",
    "title": "01b Intro to R",
    "section": "Existing Projects",
    "text": "Existing Projects\nYou will find the current project on the top right corner of RStudio\nIf you click on the current project, you can open new projects by choosing “Open Project” and select the .Rproj file of the project.\nYou can also just double click on .Rproj files and RStudio will open with the project loaded.\n\nExisting projects",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#why-projects",
    "href": "W1b_IntroR.html#why-projects",
    "title": "01b Intro to R",
    "section": "Why Projects",
    "text": "Why Projects\n\nProjects are not only convenient for us (e.g., scripts that we had opened before are re-opened when we open the project), they are also great for reproducibility.\nWe won’t cover the details here - see the “Further Reading” section of the course page!",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#using-scripts",
    "href": "W1b_IntroR.html#using-scripts",
    "title": "01b Intro to R",
    "section": "Using Scripts",
    "text": "Using Scripts\nTo open a new script, click File \\(\\to\\) New File \\(\\to\\) R Script. (Ctrl + Shift + N)\nTo run a line of the script, you can either click Run at the top right of the pane or Ctrl + Enter. It will run the code that is highlighted/selected or automatically select the current line (or the complete multi-line command).\nTo run the whole script/chunk, press Ctrl + Shift + Enter (with full console output) or Ctrl + Shift + S (limited output).\n\n\nUsing scripts",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#working-with-vectors",
    "href": "W1b_IntroR.html#working-with-vectors",
    "title": "01b Intro to R",
    "section": "Working with vectors",
    "text": "Working with vectors\n\nOf course, vectors can be stored in variables.\n\n\n\nmy_vector &lt;- c(1, 2, 10)\n\nshopping_list &lt;- c(\"flour\", \"eggs\", \"apples\")",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#vector-operations",
    "href": "W1b_IntroR.html#vector-operations",
    "title": "01b Intro to R",
    "section": "Vector operations",
    "text": "Vector operations\n\nBut the real fun is that R is “vectorized”, which allows us to do some funny tricks.\nNote that this is different from usual “vector math”.\n\n\n\nc(1, 2, 5) + 1\n\n[1] 2 3 6\n\nc(2, 4, 6) + c(1, 0, 2)\n\n[1] 3 4 8\n\n# Can you spot what happens HERE?!\nc(2, 4, 6, 5, 0, 0) + c(1, 10)\n\n[1]  3 14  7 15  1 10",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#get-the-data",
    "href": "W1b_IntroR.html#get-the-data",
    "title": "01b Intro to R",
    "section": "Get the data",
    "text": "Get the data\nTo read in data files, you need to know which format these files have, e.g. .txt. or .csv files or some other (proprietary) format. There are packages that enable you to read in data of different formats like Excel (.xlsx).\nWe will use the files from Fundamentals of Quantitative Analysis: ahi-cesd.csv and participant-info.csv. Save these directly in your project folder on your computer (do not open them!).\n\n\n\nDid you find the files? Here are the direct links:\n\nhttps://psyteachr.github.io/quant-fun-v2/ahi-cesd.csv\nhttps://psyteachr.github.io/quant-fun-v2/participant-info.csv",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#read-in-the-data",
    "href": "W1b_IntroR.html#read-in-the-data",
    "title": "01b Intro to R",
    "section": "Read in the data",
    "text": "Read in the data\nCreate a new script with the following content:\n\nlibrary(tidyverse) # we will use a function from the tidyverse to read in the data\n\ndat &lt;- read_csv(\"ahi-cesd.csv\")\npinfo &lt;- read_csv(\"participant-info.csv\")\n\nRun the code!",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#looking-at-the-data",
    "href": "W1b_IntroR.html#looking-at-the-data",
    "title": "01b Intro to R",
    "section": "Looking at the Data",
    "text": "Looking at the Data\nThere are several options to get a glimpse at the data:\n\nClick on dat and pinfo in your Environment.\nType View(dat) into the console or into the script pane and run it.\nRun str(dat) or str(pinfo) to get an overview of the data.\nRun summary(dat).\nRun head(dat), print(dat), or even just dat.\nWhat is the difference between these commands?",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#looking-at-the-data-2",
    "href": "W1b_IntroR.html#looking-at-the-data-2",
    "title": "01b Intro to R",
    "section": "Looking at the Data 2",
    "text": "Looking at the Data 2\nWhat is the difference to the objects/variables, that you assigned/saved in your Environment earlier and these objects?\n\nRStudio’s Environment panel\nThe two objects we just read in are data frames, which are “tables” of data (they can contain entire data sets). The objects we assigned earlier were simpler (single values, or “one-dimensional” vectors).\nData frames usually have several rows and columns. The columns are the variables and the rows are the observations (more about that later).",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W2_Models.html#why-do-we-need-models",
    "href": "W2_Models.html#why-do-we-need-models",
    "title": "02 Models",
    "section": "Why do we need Models?",
    "text": "Why do we need Models?\nWhat can we do with data only? Where can a model be helpful?\n\nsummarize/simplify, generalize, explain",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#what-is-a-model",
    "href": "W2_Models.html#what-is-a-model",
    "title": "02 Models",
    "section": "What is a Model?",
    "text": "What is a Model?\n\n“models” are generally simplifications of things in the real world that nonetheless convey the essence of the thing being modeled\nAll models are wrong but some are useful (George Box)\n\n(ST21, Ch 5)\nAim: Find the model that efficiently and accurately summarizes the data.",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#a-simple-model",
    "href": "W2_Models.html#a-simple-model",
    "title": "02 Models",
    "section": "A Simple Model",
    "text": "A Simple Model\nLet’s say we want to have a model of height of students in this Biostatistics class (or height of children based on the NHANES dataset, as used in ST21, see below).\nWhat do you think would be a good model for the height of a student/child?\n(Or: Which value should we guess for a particular or new student/child?)\n\n\n\n\n\n\n\n\n\n\n\nHave them guess the height of an anonymous new student, discuss what could be relevant information. Gender = not known (prior knowledge!).\nMean = model?",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#basic-structure-of-statistical-models",
    "href": "W2_Models.html#basic-structure-of-statistical-models",
    "title": "02 Models",
    "section": "Basic structure of statistical models",
    "text": "Basic structure of statistical models\n\\[\ndata=model+error\n\\]\n\na statistical model is generally much simpler than the data being described; it is meant to capture the structure of the data as simply as possible.\nTwo parts:\n\none portion that is described by a statistical model, which expresses the values that we expect the data to take given our knowledge,\nerror that reflects the difference between the model’s predictions and the observed data.\n\nExample? (Average) age in classroom? All prior knowledge goes into model\n\n\nIn general, we want to predict single observations (denoted by i) from the model. The fact that we are looking at predictions and not at actual values of the data/observations is denoted by the “hat”:\n\\[ \\widehat{data_i} = model_i \\] The error is then simply the deviation of the actual data from the predicted values:\n\\[  error_i = data_i - \\widehat{data_i} \\]\nThis means that the predicted value of the data for observation i is equal to the value of the model for that observation.",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#a-simple-model-2",
    "href": "W2_Models.html#a-simple-model-2",
    "title": "02 Models",
    "section": "A Simple Model 2",
    "text": "A Simple Model 2\nThe simplest model would be to predict the mean of the height values for every student/child! This would imply that individual deviations of the mean would be interpreted to be (prediction) errors in such a model.\nWe can write such a simple model as a formula:\n\\[\ny_i = \\beta + \\epsilon\n\\]\n\\(y_i\\) denotes the individual observations (hence the \\(i\\)) of heights, \\(\\beta\\) is a so-called parameter, and \\(\\epsilon\\) is the error term. In this example, the parameter \\(\\beta\\) would be the same value (= the mean height) for everyone (hence it doesn’t need an \\(i\\) subscript). Parameters are values that we optimize to find the best model.\n\nWhat would be Yi, beta and error for the height example?",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#a-simple-model-3",
    "href": "W2_Models.html#a-simple-model-3",
    "title": "02 Models",
    "section": "A Simple Model 3",
    "text": "A Simple Model 3\nHow do we find parameters that belong to the best fitting model?\nHow did you come up with model for heights, e.g. the mean?\n\nWe try to minimize the error!\nRemember, the error is the difference between the actual and predicted values of \\(y\\) (height):\n\\[\nerror_i = y_i - \\hat{y_i}\n\\]\nIf we select a predicted value (or mean) of 400cm, all individuals’ errors would hugely deviate (because no one is 4m tall). If we average these errors, it would still be a big value.\nA better candidate for such a simple model is thus the arithmetic mean or average:\n\\[\n\\bar{X} = \\frac{\\sum_{i=1}^{n}x_i}{n}\n\\]\nSumming up all individual’s heights and dividing that number by the number of individuals gives us the mean. By definition, the average (directed) error is now 0 (see book for proof, the individual errors cancel out)! This means that the average has no bias to over- or underestimate observations (while 4m would have been a clear overestimation).",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#a-note-on-errors",
    "href": "W2_Models.html#a-note-on-errors",
    "title": "02 Models",
    "section": "A Note on Errors",
    "text": "A Note on Errors\nWe usually don’t simply average across the individual (signed) errors, but across the squared errors.\nThe reason is that we do not want positive and negative errors to cancel each other out.\nThe mean squared error would be in a different unit than the data (e.g., cm2), which is why we usually take the square root of that value to bring it back to the original unit: This leaves us with the root mean squared error (RMSE)!\nNote: We could also use the absolute values of errors, sum those up, and avoid any of these problems. For historical reasons, we do not.",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#a-slightly-more-complex-model",
    "href": "W2_Models.html#a-slightly-more-complex-model",
    "title": "02 Models",
    "section": "A Slightly More Complex Model",
    "text": "A Slightly More Complex Model\nObviously, the model for predicting height from the average is not very good (RMSE = 27 cm). How can we improve this model?\n\nWe can account for other information that we might have!\nFor example, to account for age might be a good idea: Older children are likely taller than younger ones. We plot height against age to visually inspect the relationship:\n\n\n\n\n\n\n\n\n\n\n\n\nRMSE: On average, 27 cm “wrong” per individual!\nA: raw data, visible strong relationship\nB: only age (linear relationship)\nC: intercept/constant\nD: also account for gender\n–&gt; line fits data increasingly better!",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#a-slightly-more-complex-model-2",
    "href": "W2_Models.html#a-slightly-more-complex-model-2",
    "title": "02 Models",
    "section": "A Slightly More Complex Model 2",
    "text": "A Slightly More Complex Model 2\nAs we can see, the line (~ model) fits the data points increasingly well, e.g. if we include a constant (also called “intercept”) and age. We would write this as this formula:\n\\[\n\\hat{y_i} = \\hat{\\beta_0} + \\hat{\\beta_1} * age_i\n\\]\nRemember from linear algebra that this defines a line:\n\\[\ny = intercept + slope * x\n\\]\nThus \\(\\beta_0\\) is the parameter for the intercept and \\(\\beta_1\\) for the slope of age!\nThe model fit is now much better: RMSE = 8.36 cm.\n\nAdding gender? Does not improve model too much! (compared to age)\n\nw/o intercept: A, no \\(\\beta_0\\)\nStats Software will estimate best values for \\(\\beta\\)’s",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#what-is-a-good-model",
    "href": "W2_Models.html#what-is-a-good-model",
    "title": "02 Models",
    "section": "What is a “Good” Model?",
    "text": "What is a “Good” Model?\nTwo aims:\n\nDescribe data well (= low error/RMSE)\nGeneralize to new data (low error when applied to new data)\n\nCan be conflicting!\n\nWhere does error come from?\nAny ideas? Where could the error come from in your height model?\n\n\n\nmeasurement error (noise): random variation in data\n\ndependent variable is hard to measure precisely (difficult/noisy conditions)\ncheap/inadequate equipment for measuring\n\nwrong model specification\n\nimportant variable is missing from model (age!)\ne.g., height has a quadratic relationship with age (old people shrink again)",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#examples-measurement-error",
    "href": "W2_Models.html#examples-measurement-error",
    "title": "02 Models",
    "section": "Examples Measurement Error",
    "text": "Examples Measurement Error\n\nSimulated relationship between blood alcohol content and reaction time on a driving test, with best-fitting linear model represented by the line. A: linear relationship with low measurement error. B: linear relationship with higher measurement error. C: Nonlinear relationship with low measurement error and (incorrect) linear model\nA: very little error, all points close to fitted line\nB: same relationship much more variability across individuals\nC. wrongly specified model (caffeine!), not a linear relationship. Error high (deviations points - line)",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#can-a-model-be-too-good",
    "href": "W2_Models.html#can-a-model-be-too-good",
    "title": "02 Models",
    "section": "Can a Model be “too Good”?",
    "text": "Can a Model be “too Good”?\nYes! This is called overfitting.\n\nIf we fit a line too closely to the data (e.g., with an 8th degree polynomial), the model might not be able to generalize to other data well.\n\n\n\n\n\nAn example of overfitting. Both datasets were generated using the same model, with different random noise added to generate each set. The left panel shows the data used to fit the model, with a simple linear fit in blue and a complex (8th order polynomial) fit in red. The root mean square error (RMSE) values for each model are shown in the figure; in this case, the complex model has a lower RMSE than the simple model. The right panel shows the second dataset, with the same model overlaid on it and the RMSE values computed using the model obtained from the first dataset. Here we see that the simpler model actually fits the new dataset better than the more complex model, which was overfitted to the first dataset.\n\n\n\n\n\n\nHow would overfitting look like in your height examples?\n\nsame formula, different noise (simulation) ~ different individuals\nsimpler model fits new data better!\noverfitting in height examples?",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#central-tendency",
    "href": "W2_Models.html#central-tendency",
    "title": "02 Models",
    "section": "Central Tendency",
    "text": "Central Tendency\nWhy summarize data?\n\nA summary is a model & describes the data! E.g., mean = central tendency of the data\n\n\nMean, Median, Mode?\n\n\nMean = “Balance point” of data; minimizes sum of squared error, but highly influenced by outliers!\nMedian = “middle” of ranked data; minimizes sum of absolute error, less influenced by extreme values\nMode = most often occurring value (i.e., absolute peak)\n\n\nExample:\nIf 4 people earn 50,000 Euros per year and 1 person earns 1,000,000:\nMean: 240,000 Euros\nMedian: (Rank order: 10,000; 10,000; 10,000; 10,000; 1,000,000) -&gt; middle value = 10,000 Euros\nMode: 10,000 Euros\n\nexamples\nmean: income –&gt; if one person earns a million and 3 only 10.000 –&gt; mean = 257.500",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#variability",
    "href": "W2_Models.html#variability",
    "title": "02 Models",
    "section": "Variability",
    "text": "Variability\nHow widespread are the data?\n\nVariance and Standard Deviation\nVariance = Mean Squared Error\n\\[\n\\sigma^2 = \\frac{SSE}{N} = \\frac{\\sum_{i=1}^n (x_i - \\mu)^2}{N}\n\\]\n(Note: \\(x_i\\) = value of ind. observation, \\(\\mu\\) = population mean instead of \\(\\hat{X}\\) = sample mean)\n\n\nStandard Deviation ≈ Root Mean Squared Error\n\\[\nSD = \\sigma = \\sqrt{\\sigma^2}\n\\]\n\n\nWe usually don’t know the population mean \\(\\mu\\), that’s why we estimate the sample variance using the sample mean \\(\\hat{X}\\) (both with the “hat”) and the sample size \\(n\\) instead of the population size \\(N\\):\n\\[\n\\hat\\sigma^2 = \\frac{\\sum_{i=1}^n (x_i - \\hat{X})^2}{n-1}\n\\]\nNote: \\(n-1\\) is used to make the estimate more robust/less biased (I cannot give you an intuition why this is better… please trust me!).\n\nRemember plot above: Points either close to line or wide spread\nVariance = sigma^2, deviations of data points from mean (\\(\\mu\\)) squared and summed, divided by number of oberservations\n\\(n-1\\) = Degrees of Freedom, one value is fixed if we know the mean.",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#comparing-apples-and-oranges-z-scores",
    "href": "W2_Models.html#comparing-apples-and-oranges-z-scores",
    "title": "02 Models",
    "section": "Comparing apples and oranges: Z-Scores",
    "text": "Comparing apples and oranges: Z-Scores\n\\[\nZ_i(x) = \\frac{x_i - \\mu}{\\sigma}\n\\]\n\nstandardizes the distribution: How far is any data point from the mean in units of SD?\ndoesn’t change original relationship of data points!\n\nshifts distribution to have a mean = 0 and scales it to have SD = 1.\n\nuseful if we compare (or use in a model) variables on different scales/units!\n\n\n\n\n\n\n\nDensity (top) and cumulative distribution (bottom) of a standard normal distribution, with cutoffs at one standard deviation above/below the mean.\n\n\n\n\n\nZ of x\nx_i is single value/data point\nmu, sigma\nz-scores: Now you can compare apples to oranges! Imagine two siblings from different classes battling it out on test results:\n- I got 70 points, you got only 60!\n- My test only had 70 points in total, yours had 85. I got 86% correct, you only 82%!\n- My test was harder! The average result was 60 with a standard deviation of 10, so I am 1 SD above the class average!\n- On my test, an average of 52 was achieved with an SD of 8, so I am also 1 SD above the class average. But people in your class are really stupid so that’s a very low standard to compare yourself.\nNarrator: And this was the end of comparability between apples and oranges :)",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#ggplot",
    "href": "W4_DataVizR.html#ggplot",
    "title": "04 Data Visualization",
    "section": "ggplot",
    "text": "ggplot\nWe will use a package called ggplot2 (part of the tidyverse). ggplot2 is a very versatile package that allows us to make beautiful, publication-ready(-ish) figures.\nggplot2 follows the “grammar of graphics” by Leland Wilkinson, a formal guide to visualization principles. A core feature are the layers each plot consists of. The main function to “start” plotting is ggplot() - we will then add layers of data and layers to tweak the appearance.\n\nLayers of a ggplot",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#activity-1-set-up",
    "href": "W4_DataVizR.html#activity-1-set-up",
    "title": "04 Data Visualization",
    "section": "Activity 1: Set Up",
    "text": "Activity 1: Set Up\n\nWithin your biostats project in RStudio, create a new script called DataVisualisation1.R.\nMake sure you have the following two files downloaded into your project folder (we already used them in Intro to R presentation): ahi-cesd.csv and participant-info.csv.\nCopy and run the code below to load the tidyverse package and the data files:\n\n\nlibrary(tidyverse) \n\ndat &lt;- read_csv(\"ahi-cesd.csv\")\npinfo &lt;- read_csv(\"participant-info.csv\")",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#activity-1-set-up-1",
    "href": "W4_DataVizR.html#activity-1-set-up-1",
    "title": "04 Data Visualization",
    "section": "Activity 1: Set Up",
    "text": "Activity 1: Set Up\n\nRun the following code to combine both files and select our variables of interest:\n\n\nall_dat &lt;- \n  dat %&gt;% \n  inner_join(\n    pinfo, # combine dat with pinfo\n    by = c(\"id\", \"intervention\") # common variables that tell R which data belongs together\n  ) %&gt;% \n  arrange(id, occasion) #joining messes up the order of the data frame =&gt; arrange again\n\n# we throw out several variables even though they would be important for a comprehensive data analysis\nsummarydata &lt;- \n  all_dat %&gt;% \n  select(\n    id, ahiTotal, cesdTotal, # ID & questionnaire scores\n    sex, age, educ, income # demographic variables\n  ) \n\n\nwhat happens in the code chunk?",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#look-at-the-data",
    "href": "W4_DataVizR.html#look-at-the-data",
    "title": "04 Data Visualization",
    "section": "Look at the Data",
    "text": "Look at the Data\nHave a look at the types of data:\n\nglimpse(summarydata)\n\nRows: 992\nColumns: 7\n$ id        &lt;dbl&gt; 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, …\n$ ahiTotal  &lt;dbl&gt; 63, 73, 73, 89, 89, 93, 80, 77, 77, 85, 60, 67, 56, 61, 41, …\n$ cesdTotal &lt;dbl&gt; 14, 6, 7, 10, 13, 8, 15, 12, 3, 5, 31, 31, 41, 35, 27, 32, 2…\n$ sex       &lt;dbl&gt; 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, …\n$ age       &lt;dbl&gt; 35, 35, 59, 59, 59, 59, 59, 59, 51, 51, 50, 50, 50, 50, 58, …\n$ educ      &lt;dbl&gt; 5, 5, 1, 1, 1, 1, 1, 1, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, …\n$ income    &lt;dbl&gt; 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, …\n\n\nWhat do you see?\n\nAll variables are loaded as numeric. However, are all of those numeric?\n\n\nsex, educ and income don’t seem to really be numbers but factors with individual categories (factor levels)!\nWe should convert these data to factor. Checking and adjusting data types (as part of data wrangling) will be important for plotting and analyzing the data, you might otherwise get strange/wrong results!",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#activity-2-transform-to-factor",
    "href": "W4_DataVizR.html#activity-2-transform-to-factor",
    "title": "04 Data Visualization",
    "section": "Activity 2: Transform to factor",
    "text": "Activity 2: Transform to factor\nCopy and run the below code to change the categories to factors.\n\nsummarydata1 &lt;- \n  summarydata %&gt;%\n  mutate(\n    sex = as_factor(sex),\n    educ = as_factor(educ),\n    income = as_factor(income)\n  )\n\n\n\nIf you mutate a new column with the same name as the old one, it will overwrite the column.\n\n\n\n\nglimpse(summarydata1)\n\nRows: 992\nColumns: 7\n$ id        &lt;dbl&gt; 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, …\n$ ahiTotal  &lt;dbl&gt; 63, 73, 73, 89, 89, 93, 80, 77, 77, 85, 60, 67, 56, 61, 41, …\n$ cesdTotal &lt;dbl&gt; 14, 6, 7, 10, 13, 8, 15, 12, 3, 5, 31, 31, 41, 35, 27, 32, 2…\n$ sex       &lt;fct&gt; 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, …\n$ age       &lt;dbl&gt; 35, 35, 59, 59, 59, 59, 59, 59, 51, 51, 50, 50, 50, 50, 58, …\n$ educ      &lt;fct&gt; 5, 5, 1, 1, 1, 1, 1, 1, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, …\n$ income    &lt;fct&gt; 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, …",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#activity-2-transform-to-factor-1",
    "href": "W4_DataVizR.html#activity-2-transform-to-factor-1",
    "title": "04 Data Visualization",
    "section": "Activity 2: Transform to factor",
    "text": "Activity 2: Transform to factor\n\nglimpse(summarydata1)\n\nRows: 992\nColumns: 7\n$ id        &lt;dbl&gt; 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, …\n$ ahiTotal  &lt;dbl&gt; 63, 73, 73, 89, 89, 93, 80, 77, 77, 85, 60, 67, 56, 61, 41, …\n$ cesdTotal &lt;dbl&gt; 14, 6, 7, 10, 13, 8, 15, 12, 3, 5, 31, 31, 41, 35, 27, 32, 2…\n$ sex       &lt;fct&gt; 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, …\n$ age       &lt;dbl&gt; 35, 35, 59, 59, 59, 59, 59, 59, 51, 51, 50, 50, 50, 50, 58, …\n$ educ      &lt;fct&gt; 5, 5, 1, 1, 1, 1, 1, 1, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, …\n$ income    &lt;fct&gt; 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, …\n\n\n\n\nsummarydata1 %&gt;% pull(educ) %&gt;% unique()\n\n[1] 5 1 4 2 3\nLevels: 1 2 3 4 5\n\n\n\n\n\nAt first glance, the data look the same. But the 1s and 2s in sex are now e.g. not treated as numbers anymore, but as factor levels (categories). This e.g. changes how the data behave in different analyses, or plotting (continuous vs. categorical data).",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#set-labels",
    "href": "W4_DataVizR.html#set-labels",
    "title": "04 Data Visualization",
    "section": "Set labels",
    "text": "Set labels\nA simple change to a factor is not always helpful. We still don’t know what a 1 in sex or a 5 in educ stands for:\n\nsex: 1 = female, 2 = male\neduc: 1 = no graduation, 2 = school graduation, 3 = vocational training, 4 = bachelor’s degree, 5 = post graduate\nincome: 1 = low, 2 = middle, 3 = high\n\n\n\nThere is very sparse information on the variables at https://doi.org/10.5334/jopd.35, so I guesstimated some of the factor levels.",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#set-labels-1",
    "href": "W4_DataVizR.html#set-labels-1",
    "title": "04 Data Visualization",
    "section": "Set labels",
    "text": "Set labels\nmatch_case() allows us to label our numeric data with more human-readable descriptions. if_else() is a useful shorthand for cases where we only have two categories.\n\nsummarydata2 &lt;- \n  summarydata %&gt;% \n  mutate(\n    sex = if_else(sex == 1, \"female\", \"male\") %&gt;% as_factor(), #wrong if non-binary entries exist\n    educ = educ %&gt;% \n      case_match(\n        1 ~ \"no graduation\",\n        2 ~ \"school graduation\",\n        3 ~ \"vocational training\",\n        4 ~ \"bachelor's degree\",\n        5 ~ \"post grad\"\n      ) %&gt;%\n      as_factor(), # need to transform to factor in the end\n    income = income %&gt;% \n      case_match(1 ~ \"low\", 2 ~ \"middle\", 3 ~ \"high\") %&gt;% \n      as_factor()\n  )",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#set-labels-2",
    "href": "W4_DataVizR.html#set-labels-2",
    "title": "04 Data Visualization",
    "section": "Set labels",
    "text": "Set labels\n\nsummarydata2 %&gt;% pull(educ) %&gt;% unique()\n\n[1] post grad           no graduation       bachelor's degree  \n[4] school graduation   vocational training\n5 Levels: post grad no graduation bachelor's degree ... vocational training\n\n\nFactor is now ordered by occurrence in data! :( (E.g., the order on the axis of a plot would be wrong.)",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#set-factor-order-levels",
    "href": "W4_DataVizR.html#set-factor-order-levels",
    "title": "04 Data Visualization",
    "section": "Set factor order (levels)",
    "text": "Set factor order (levels)\nUsing factor(), we can explicitly order the categories using the argument levels.\n\nsummarydata %&gt;% \n  mutate(\n    income = income %&gt;%\n      case_match(1 ~ \"low\", 2 ~ \"middle\", 3 ~ \"high\") %&gt;% \n      as_factor()\n  ) %&gt;% \n  pull(income) %&gt;% unique()\n\n[1] high   low    middle\nLevels: high low middle\n\n\n\nsummarydata %&gt;% \n  mutate(\n    income = income %&gt;% \n      case_match(1 ~ \"low\", 2 ~ \"middle\", 3 ~ \"high\") %&gt;% \n      factor(levels = c(\"low\", \"middle\", \"high\")) # factor(), not as_factor()!\n  ) %&gt;% \n  pull(income) %&gt;% unique()\n\n[1] high   low    middle\nLevels: low middle high",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#put-it-all-together",
    "href": "W4_DataVizR.html#put-it-all-together",
    "title": "04 Data Visualization",
    "section": "Put it all together",
    "text": "Put it all together\nIn this case, we can arrange the data by the numerical values before switching them to text labels.\n\nsummarydata3 &lt;- \n  summarydata %&gt;% \n  arrange(sex, educ, income) %&gt;% # can be a problem if some condition combinations don't exist\n  mutate(\n    sex = if_else(sex == 1, \"female\", \"male\") %&gt;% as_factor(), # wrong if non-binary entries exist\n    educ = educ %&gt;% \n      case_match(\n        1 ~ \"no graduation\",\n        2 ~ \"school graduation\",\n        3 ~ \"vocational training\",\n        4 ~ \"bachelor's degree\",\n        5 ~ \"post grad\"\n      ) %&gt;%\n      as_factor(),\n    income = income %&gt;% \n      case_match(1 ~ \"low\", 2 ~ \"middle\", 3 ~ \"high\") %&gt;% \n      as_factor()\n  )\n\n# summarydata3 %&gt;% select(sex, educ, income) %&gt;% summary()",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#the-first-layer",
    "href": "W4_DataVizR.html#the-first-layer",
    "title": "04 Data Visualization",
    "section": "The First Layer",
    "text": "The First Layer\n\nThe first line (or layer) sets up the base of the graph: the data to use and the aesthetics (aes()) (what will go on the x and y axis, how the plot will be grouped).\naes() includes anything that is directly related to your data: e.g., what goes on the x and y axis, or whether the plot should be grouped by a variable in your data.\nWe can provide x and y as arguments, however, in a bar plot, the count per category is calculated automatically, so we don’t need to put anything on the y-axis ourselves.\n\n\n\nggplot(summarydata3, aes(x = sex))",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#the-second-layer",
    "href": "W4_DataVizR.html#the-second-layer",
    "title": "04 Data Visualization",
    "section": "The Second Layer",
    "text": "The Second Layer\nThe next layer adds a geom or a shape. In this case we use geom_bar() as we want to draw a bar plot.\n\nNote that we are adding layers, using a + between layers. This is a very important difference between pipes and visualization.\n\n\n\nggplot(summarydata3, aes(x = sex)) +\n  geom_bar()",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#the-second-layer-with-color",
    "href": "W4_DataVizR.html#the-second-layer-with-color",
    "title": "04 Data Visualization",
    "section": "The Second Layer with color",
    "text": "The Second Layer with color\n\nAdding fill to the first layer will separate the data into each level of the grouping variable and fill it with a different color. Note that fill colors the inside of the bar, while color colors the bar’s outlines.\nWe can get rid of the (in this case redundant legend) with show.legend = FALSE.\n\n\n\nggplot(summarydata3, aes(x = sex, fill = sex)) +\n  geom_bar() #geom_bar(show.legend = FALSE)",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#the-next-layers---improving-the-plot",
    "href": "W4_DataVizR.html#the-next-layers---improving-the-plot",
    "title": "04 Data Visualization",
    "section": "The Next Layers - Improving the Plot",
    "text": "The Next Layers - Improving the Plot\nWe might want to make the plot a bit prettier and easier to read. What would you improve?\n\nWe could add better axis labels, and custom colors. We can do so with the functions scale_x_discrete() and scale_y_continuous(), which adjust the x and y axes.\nBoth functions can change several aspects of our axes; here, we use the argument name to set a new axis name.\n\n\nggplot(summarydata3, aes(x = sex, fill = sex)) +\n  geom_bar(show.legend = FALSE) +\n  scale_x_discrete(name = \"Participant Sex\") + \n  scale_y_continuous(name = \"Number of participants\")\n\n\n\n\n\n\n\n\n\n\nThere’s also the counterparts scale_x_continuous() and scale_y_discrete(). What do you think, why do we use the ones mentioned above and when would we use the other ones?",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#themes-changing-the-appearance",
    "href": "W4_DataVizR.html#themes-changing-the-appearance",
    "title": "04 Data Visualization",
    "section": "Themes: Changing the Appearance",
    "text": "Themes: Changing the Appearance\nThere are a number of built-in themes that you can use to change the appearance (background, whether axes are shown etc.), but you can also tweak the themes further manually.\nWe will now change the default theme to theme_minimal(), but you can also try other themes (just type “theme_” and see what the autocomplete brings up).\n\n\nggplot(summarydata3, aes(x = sex, fill = sex)) +\n  geom_bar(show.legend = FALSE) +\n  scale_x_discrete(name = \"Participant Sex\") + \n  scale_y_continuous(name = \"Number of participants\") +\n  theme_minimal()",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#colors",
    "href": "W4_DataVizR.html#colors",
    "title": "04 Data Visualization",
    "section": "Colors",
    "text": "Colors\nThere are various ways to change the colors of the bars. You can manually indicate the colors you want to use but you can also easily use pre-determined color palettes that are already checked for color-blind friendliness.\nA popular palette is viridis. We can simply add a function/layer to your ggplot named scale_fill_viridis_d() (d for discrete). The function has an option parameter that takes 5 different values (A - E).\n\nRun the code below. Try changing the option to either A, B, C or D and see which one you like!\n\n\n\nggplot(summarydata3, aes(x = sex, fill = sex)) +\n  geom_bar(show.legend = FALSE) +\n  scale_x_discrete(name = \"Participant Sex\") +\n  scale_y_continuous(name = \"Number of participants\") +\n  theme_minimal() +\n  scale_fill_viridis_d(option = \"E\")",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#transparency",
    "href": "W4_DataVizR.html#transparency",
    "title": "04 Data Visualization",
    "section": "Transparency",
    "text": "Transparency\nYou can also add transparency to your plot, which can be helpful if you plot several layers of data that overlap.\nTo do so, you can simply add alpha to the geom_bar() - try changing the value of alpha (between 0 and 1):\n\n\nggplot(summarydata3, aes(x = sex, fill = sex)) +\n  geom_bar(show.legend = FALSE, \n           alpha = .8) +\n  scale_x_discrete(name = \"Participant Sex\") +\n  scale_y_continuous(name = \"Number of participants\") +\n  theme_minimal() +\n  scale_fill_viridis_d(option = \"E\")",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#grouped-plots",
    "href": "W4_DataVizR.html#grouped-plots",
    "title": "04 Data Visualization",
    "section": "Grouped Plots",
    "text": "Grouped Plots\nImagine that you have several factors that you want to use to group your data, such as gender and income. In this case, you could use a grouped bar plot:\n\n\nggplot(summarydata3, aes(x = sex, fill = income)) +\n  geom_bar(\n    # the default are stacked bars; we use \"dodge\" to put them side by side\n    position = \"dodge\",\n    alpha = .8\n  ) +\n  scale_x_discrete(name = \"Participant Sex\") +\n  scale_y_continuous(name = \"Number of participants\") +\n  theme_minimal() +\n  scale_fill_viridis_d(option = \"E\")\n\n\n\n\n\n\n\n\n\n\nWithout position = dodge, you would get a stacked barplot",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#facetting",
    "href": "W4_DataVizR.html#facetting",
    "title": "04 Data Visualization",
    "section": "Facetting",
    "text": "Facetting\nYou could also use facets to divide your data visualizations into several subplots: facet_wrap for one variable.\n\nggplot(summarydata3, aes(x = sex, fill = sex)) +\n  geom_bar(show.legend = FALSE, alpha = .8) +\n  scale_x_discrete(name = \"Participant Sex\") +\n  scale_y_continuous(name = \"Number of participants\") +\n  theme_minimal() +\n  scale_fill_viridis_d(option = \"E\")  +\n  facet_wrap(vars(income)) # here, you need to use vars() around variable names\n\n\n\nWhat is problematic here? We needed percentages for females and males for a better comparison",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#facetting-2",
    "href": "W4_DataVizR.html#facetting-2",
    "title": "04 Data Visualization",
    "section": "Facetting 2",
    "text": "Facetting 2\nYou could also use facets to divide your data visualizations into several subplots: facet_grid for a matrix of (combinations of) two variables.\n\nggplot(summarydata3, aes(x = sex, fill = sex)) +\n  geom_bar(show.legend = FALSE, alpha = .8) +\n  scale_x_discrete(name = \"Participant Sex\") +\n  scale_y_continuous(name = \"Number of participants\") +\n  theme_minimal() +\n  scale_fill_viridis_d(option = \"E\")  +\n  facet_grid(\n    rows = vars(income),\n    cols = vars(educ),\n    labeller = \"label_both\" # this adds the variable name into the facet legends\n  )",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#a-closer-look",
    "href": "W4_DataVizR.html#a-closer-look",
    "title": "04 Data Visualization",
    "section": "A closer look",
    "text": "A closer look",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#violin-boxplot",
    "href": "W4_DataVizR.html#violin-boxplot",
    "title": "04 Data Visualization",
    "section": "Violin-Boxplot",
    "text": "Violin-Boxplot\nLet’s look at the code. How does the code differ from the one for the barplot above?\n\n\nggplot(summarydata3, aes(x = income, \n                         y = ahiTotal, # new variable!\n                         fill = income)) +\n  geom_violin(trim = FALSE, # smooth on edges\n              alpha = .4) +\n  geom_boxplot(width = .2, # small boxplot contained in violin\n               alpha = .7) +\n  scale_x_discrete(\n    name = \"Income\",\n    # set new labels\n    labels = c(\"Below Average\", \"Average\", \"Above Average\")) +\n  scale_y_continuous(name = \"Authentic Happiness Inventory Score\")+\n  theme_minimal() +\n  # no need to switch of axis for every geom individually\n  theme(legend.position = \"none\") + \n  scale_fill_viridis_d()\n\n\n\n\n\n\n\n\n\n\nIn this case, not the count on the y-axis, but another cont. variable!",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#layer-order",
    "href": "W4_DataVizR.html#layer-order",
    "title": "04 Data Visualization",
    "section": "Layer Order",
    "text": "Layer Order\nThe order of layers is crucial, as the plot will be built up in that order (later layers on top):\n\n\n\nggplot(summarydata3, aes(x = income, y = ahiTotal)) +\n  geom_violin() +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\nggplot(summarydata3, aes(x = income, y = ahiTotal)) +\n  geom_boxplot() +\n  geom_violin()",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#scatterplot",
    "href": "W4_DataVizR.html#scatterplot",
    "title": "04 Data Visualization",
    "section": "Scatterplot",
    "text": "Scatterplot\nIf we have continuous data of two variables, we often want to make a scatter plot:\n\n\nggplot(summarydata3, aes(x = age, y = cesdTotal)) +\n  geom_point() +\n  # if you don't want the shaded CI, add se = FALSE to this\n  geom_smooth(method = lm)",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#saving-your-figures",
    "href": "W4_DataVizR.html#saving-your-figures",
    "title": "04 Data Visualization",
    "section": "Saving your Figures",
    "text": "Saving your Figures\nYou can use ggsave() to save your plots. If you don’t tell ggsave() which plot you want to save, by default it will save the last plot you created.\nYou just have to enter the name of the file to be saved (in your working directory) like this:\n\nggsave(\"violin-boxplot.png\")\n\nCheck whether indeed the last plot was saved!\n\nYou can also specify the dimensions of your plot to be saved:\n\nggsave(\"violin-boxplot.png\",\n       width = 6.5, #width of a typical page in inches minus border (according to APA format)\n       height = 6.5 / sqrt(2), #golden ratio :)\n       units = \"in\")\n\nor\n\nggsave(\"violin-boxplot.png\",\n       width = 1920,\n       height = 1080,\n       units = \"px\") #full HD picture in pixels: 1920 x 1080",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#saving-your-figures-2",
    "href": "W4_DataVizR.html#saving-your-figures-2",
    "title": "04 Data Visualization",
    "section": "Saving your Figures 2",
    "text": "Saving your Figures 2\nYou can also assign the plot to a variable in your environment and then tell ggsave() which object to save. This is a bit safer.\nRun the code for the violin-boxplot again and save the plot in an object called viobox. You’d then have to explicitly tell ggsave() to save the object viobox:\n\nviobox &lt;- \n  ggplot(summarydata3, aes(x = income, y = ahiTotal, fill = income)) +\n  geom_violin(trim = FALSE, alpha = .4) +\n  geom_boxplot(width = .2, alpha = .7) +\n  scale_x_discrete(\n    name = \"Income\",\n    labels = c(\"Below Average\", \"Average\", \"Above Average\")) +\n  scale_y_continuous(name = \"Authentic Happiness Inventory Score\")+\n  theme_minimal() +\n  theme(legend.position = \"none\") + \n  scale_fill_viridis_d()\n\nggsave(\"violin-boxplot-stored.png\", plot = viobox)\n\n\nDo not add ggsave() to the plot with a +. Instead run it on a separate line!\nIf plot is assigned to object, it won’t be displayed unless you type viobox in the console!",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W6_Sampling.html#how-do-we-sample",
    "href": "W6_Sampling.html#how-do-we-sample",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "How Do We Sample?",
    "text": "How Do We Sample?\nThe sample needs to be representative of the entire population, that’s why it’s critical how we select the individuals.\nThink about examples of non-representative samples!\n\nRepresentative: Every member of the population has an equal chance of being selected.\nIf non-representative: sample statistic is biased, its value is (systematically) different from the true population value (parameter).\n(But talking about bias is mostly a theoretical discussion: Usually we of course don’t know the population parameter and thus cannot compare our estimate with it! Otherwise we wouldn’t need to sample.)\n\nNon-representative: pollster calls people from list of Democratic party, or from rich neighborhood, or only uses psychology students :D\nThink about “your” sample, how could this be non-representative?",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#different-ways-of-sampling",
    "href": "W6_Sampling.html#different-ways-of-sampling",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Different Ways of Sampling",
    "text": "Different Ways of Sampling\n\nwithout replacement: Once a member of the population is sampled, they are not eligible to be sampled again. This is the most common variant of sampling.\nwith replacement: After a member of the population has been sampled, they are put back into the pool and could potentially be sampled again. This usually happens out of accident or by necessity (cf. Bootstrapping)",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#sampling-error",
    "href": "W6_Sampling.html#sampling-error",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Sampling Error",
    "text": "Sampling Error\nIt is likely that our sample statistic differs slightly from the population parameter. This is called the sampling error.\nIf we collect multiple samples, the sample statistic will always differ slightly. If we combine all those sample statistics, we can approximate the sampling distribution.\nOf course, we want to minimize the sampling error and get a good estimate of the population parameter!",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#example-sampling-distribution",
    "href": "W6_Sampling.html#example-sampling-distribution",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Example Sampling Distribution",
    "text": "Example Sampling Distribution\nLet’s use the NHANES dataset again and let’s assume it is the entire population. We can calculate the mean (\\(\\mu = 168.35\\)) and standard deviation (\\(\\sigma = 10.16\\)) as the population parameters. If we repeatedly sample 50 individuals, we get this:\n\n\n\n\n\n\n\nsampleMean\nsampleSD\n\n\n\n\n168.278\n8.709209\n\n\n167.846\n10.895744\n\n\n168.564\n10.803755\n\n\n169.278\n9.233464\n\n\n167.760\n10.387866\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe sample means and SDs are similar, but not exactly equal to the population parameters.\nIf we sample 5000 times (50 individuals each), we can see that the average of these 5000 sample means (depicted in blue) is similar to the population mean!\nAverage sample mean across 5000 sample: \\(\\hat{X} = 168.3463\\).\n\ngrey = population histogram (raw data) blue = sample means of samples with N=50\nWhat is similar between these distributions? What is different?",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#standard-error-of-the-mean",
    "href": "W6_Sampling.html#standard-error-of-the-mean",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Standard Error of the Mean",
    "text": "Standard Error of the Mean\nIn the example on the last slide, the means were all pretty close to each other, i.e. the blue distribution was very narrow and the variance small (compared to the grey distribution). This is an inherent statistical property of sample means: By averaging several individual values, thus aggregating them into a sample (here with \\(n = 50\\)), we reduce the variability of the sampling distribution.\n\nWe can quantify this variability of the sample mean with the standard error of the mean (SEM).\n\\[SEM = \\frac{\\hat{\\sigma}}{\\sqrt{n}}\\]\nThis formula needs two values: the population variability \\(\\sigma\\) (or sample SD \\(\\hat{\\sigma}\\) as approximation) and the size of our sample \\(n\\).\n\n\nWe can only control our sample size, thus if we want a better estimate, we can increase sample size!\nA sample of \\(n = 50\\) already decreases the population variability by a factor of \\(\\sqrt{50} = 7.1\\) !\n\nSEM ~ SD of sampling distribution of the mean\nTakes the SD of the data and divides it by sample size (so always smaller than SD!)\nWe use the sample SD as an approximation for the population SD\nUse the sigma of the data? same as sd(sample_means)\n“the utility of larger samples diminishes with the square root of the sample size”: Doubling the sample size will not double the quality of the statistic.",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#the-central-limit-theorem",
    "href": "W6_Sampling.html#the-central-limit-theorem",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "The Central Limit Theorem",
    "text": "The Central Limit Theorem\nThe Central Limit Theorem (CLT) is a fundamental (and often misunderstood) concept of statistics.\nCLT: With larger sample sizes, the sampling distribution of sample means (i.e., the blue distribution from before) will become more and more normally distributed*, even if the population distribution is not (i.e., the grey distribution from before)!\n\nNormal Distribution of Height\nNote: Means approximate a normal distribution, irrespective of the distribution from which the data stem. This is because the sampling error between the sampling mean \\(\\hat{\\mu}\\) and the population mean \\(\\mu\\) follows a normal distribution.\n\nDescribed by mean and sd: Shape never changes, only location and width!",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#clt-in-action",
    "href": "W6_Sampling.html#clt-in-action",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "CLT in Action",
    "text": "CLT in Action\nOn the left you can see a highly skewed distribution of alcohol consumption per year (from the NHANES dataset). If we repeatedly draw samples of size 50 from the datset and take the mean, we get the right distribution of sample means - which looks a lot more “normal” (normal distribution is added in red)!\n\n\nThe CLT is important because it allows us to safely assume that the sampling distribution of the mean will be normal in most cases, which is a necessary prerequisite for many statistical techniques.\n\nRed peak: True population mean Blue values left of peak: Sampling error with underestimation of the true population mean Blue values right of peak: Sampling error with overestimation of the true population mean",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#simulations",
    "href": "W6_Sampling.html#simulations",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Simulations",
    "text": "Simulations\nAs you saw in last lecture, we can also use similar functions (usually starting with r) to simulate data (i.e., to draw samples from probability distributions).\nThis can be helpful if we don’t know the “ground truth” or want to quantify uncertainty. We can also use simulations to calculate the power of a study.\nWith simulations, we define the expected “ground truth” (distribution of the population) and generate data from it.\n\nExample: We can use rnorm() to simulate data from a normal distribution with given parameters. Here, we will use means and SDs from the Scottish Health Survey (2008) to visualize two normal distributions:\n\n\nmen &lt;- rnorm(n = 100000, mean = 176.2, sd = 6.748) \nwomen &lt;- rnorm(n = 100000, mean = 163.8, sd = 6.931)  \nheights &lt;- tibble(men, women) %&gt;%   \n  pivot_longer(names_to = \"sex\", values_to = \"height\", men:women)  \nheights %&gt;% \n  ggplot(aes(x = height, fill = sex)) +   \n  geom_density(alpha = .6) +   \n  scale_fill_viridis_d(option = \"E\") +   \n  theme_minimal()\n\n\n\n\n\n\n\n\n\nWe could use these data to visualize how much overlap there is between the two distributions of men and women, or to test how big the difference in height needs to be to become significant etc.\nWe use “real data” as input for the simulations! So the simulations are based on empirical values (means, sd), but we actually draw more observations, 100.000!",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#simulate-different-distributions",
    "href": "W6_Sampling.html#simulate-different-distributions",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Simulate Different Distributions",
    "text": "Simulate Different Distributions\nIt is possible to draw data from different distributions:\n\n\nnsamples &lt;- 10000 \nnhistbins &lt;- 100  \n\n# uniform distribution \np1 &lt;- tibble(x = runif(nsamples)) %&gt;%    \n  ggplot((aes(x))) + \n  geom_histogram(bins = nhistbins) +    \n  labs(title = \"Uniform\")  \n\n# binomial distribution \np2 &lt;- tibble(x = rbinom(nsamples, 20, 0.25)) %&gt;%    \n  ggplot(aes(x)) + \n  geom_histogram(bins = nhistbins) +   \n  labs(title = \"Binomial (p=0.25, 20 trials)\")  \n\n# normal distribution \np3 &lt;- tibble(x = rnorm(nsamples)) %&gt;%    \n  ggplot(aes(x)) + \n  geom_histogram(bins = nhistbins) +   \n  labs(title = \"Normal\")  \n\n# Chi-squared distribution \np4 &lt;- tibble(x = rchisq(nsamples, df=1)) %&gt;%    \n  ggplot(aes(x)) + \n  geom_histogram(bins = nhistbins) +   \n  labs(title = \"Chi-squared\")  \n\ncowplot::plot_grid(p1, p2, p3, p4, ncol = 1)",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#simulate-a-fake-dataset",
    "href": "W6_Sampling.html#simulate-a-fake-dataset",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Simulate a Fake Dataset",
    "text": "Simulate a Fake Dataset\nLet’s simulate data of 120 participants of different heights and genders flipping a coin. To do so, we need to know how to simulate a) heights, b) flip a coin, and c) assign genders.\n\nSimulate heights:\n\nheights &lt;- rnorm(120, mean = 170, sd = 10)\n\n\n\nSimulate coin flips:\n(Instead of drawing from a probability distribution function that starts with an r, e.g. rnorm(), we use sample(), which randomly (uniformly) draws from values you determine. We need to set replace=TRUE)\n\ncoin_flips &lt;- sample(c(\"Head\", \"Tail\"), 120, replace=TRUE) \n\n\n\nWe could of course use similar code to simulate gender or the like.\nBut if we want to predetermine which genders we want to collect data from (i.e. same number in each gender group), we can also use the function rep(). This function will simply repeat an observation for a number of rows:\n\ngenders &lt;- rep(x = c(\"man\", \"woman\", \"nonbinary\"), each = 40) #%&gt;% sample() \n#you can run just \"sample\" on a vector to randomize its order \n\n\n\nDetermine participant numbers and combining everything into one dataframe:\n\nsim_data &lt;- tibble(   \n  participant_number = 1:120,   \n  gender = rep(x = c(\"man\", \"woman\", \"nonbinary\"), each = 40),   \n  height = rnorm(120, mean = 170, sd = 10),   \n  coin_flip = sample(c(\"Head\", \"Tail\"), 120, replace=TRUE) )  \n\n# or if you have run all the code before, you could also use the objects you have already in your Environment: \n# sim_data &lt;- tibble(participant_number = 1:120, genders, heights, coin_flips)\n\nIf we wanted to do a Monte Carlo Simulation, we could use the code from the last slide and put the simulation into a for loop. Inside the for loop, we would also calculate some value of interest (one estimate per subsample, such as the mean).",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#monte-carlo-simulation",
    "href": "W6_Sampling.html#monte-carlo-simulation",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Monte Carlo Simulation",
    "text": "Monte Carlo Simulation\nWith the increasing use of computers, simulations have become an essential part of modern statistics. Monte Carlo simulations are the most common ones in statistics.\nThere are four steps to performing a Monte Carlo simulation:\n\nDefine a domain of possible values.\nGenerate random numbers within that domain from a probability distribution.\nPerform a computation using the random numbers.\nCombine the results across many repetitions.",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#randomness-in-statistics",
    "href": "W6_Sampling.html#randomness-in-statistics",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Randomness in Statistics",
    "text": "Randomness in Statistics\nRandom = unpredictable.\nFor a Monte Carlo simulation, we need pseudo-random* numbers, which are generated by a computer algorithm.\n\nWe can simply generate (pseudo-)random numbers from different distributions with R, e.g. with rnorm() to draw (pseudo-)random numbers from a normal distribution:\n\n\n# Draw 10000 random numbers of a normal distribution with mean=0, sd=1\nrand_num &lt;- rnorm(n=10000, mean=0, sd=1)\n\n# Plot the random numbers and verify that they make up a normal distribution\ntibble(x = rand_num) %&gt;% \n  ggplot(aes(x)) +\n  geom_histogram(bins = 100) +\n  labs(title = \"Normal\")\n\n\n\n\n\n\n\n\n\n\n\nEach time, we generate random numbers, these will differ slightly.\nBut we can also generate the exact same set of random numbers (which will be helpful to reproduce results!) by setting the random seed to a specific value such as 123: set.seed(123).\n\n\nrnorm(): Here, r stands for random normal distribution\nFlip a coin, we don’t know the outcome! (Only if we knew a lot of physics and the conditions…)\nHumans have a bad sense of randomness, we think we see patterns everywhere (gambler’s fallacy: being due for a win).\n\n\n\n* Truly random numbers, that are completely unpredictable, are only possible through physical processes that are difficult to obtain.\nPseudo-random numbers will only seem random (they are difficult to predict) but will repeat at some point.",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#using-monte-carlo-simulations",
    "href": "W6_Sampling.html#using-monte-carlo-simulations",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Using Monte Carlo Simulations",
    "text": "Using Monte Carlo Simulations\nExample: Let’s try to find out how much time we should allow for a short in-class quiz.\nWe pretend to know the distribution of completion times is normal, with mean = 5 min and SD = 1 min.\nHow long does the test period need to be so that we can expect ALL students (n = 150) to finish in 99% of the quizzes?\n\nTo answer this question, we need the distribution of the longest finishing time.\nWhat we will do is to simulate finishing times for a great number of quizzes and take the maximum of each (the longest finishing time). We can then look at the distribution of maximum finishing times and see where the 99% quantile is.\nThis value is the amount of time that we should allow - given our assumptions!!",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#using-monte-carlo-simulations-2",
    "href": "W6_Sampling.html#using-monte-carlo-simulations-2",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Using Monte Carlo Simulations 2",
    "text": "Using Monte Carlo Simulations 2\nLet’s repeat the steps of the simulation by going through the four steps mentioned before:\n\nDefine a domain of possible values.\n\n–&gt; Our assumptions: The values would come from a normal distribution with \\(n = 150\\), \\(mean = 5\\), and \\(SD = 1\\).\n\n\nGenerate random numbers within that domain from a probability distribution.\n\n\nrand_num &lt;- rnorm(n = 150, mean = 5, sd = 1)\n\n\n\n\nPerform a computation using the random numbers.\n\n\nmax_rand_num &lt;- max(rand_num) #time of slowest student",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#using-monte-carlo-simulations-3",
    "href": "W6_Sampling.html#using-monte-carlo-simulations-3",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Using Monte Carlo Simulations 3",
    "text": "Using Monte Carlo Simulations 3\n\nCombine the results across many repetitions.\n\n\nnrep &lt;- 5000 #number of repetitions\n\n# initialize an empty matrix to fill in the max values later\nmax_rand_num &lt;- matrix(data = NA, nrow = nrep, ncol=1)\n\n# use a for-loop to repeat resampling nrep times!\nfor (i in 1:nrep) {\n  rand_num &lt;- rnorm(n = 150, mean = 5, sd = 1)\n  max_rand_num[i, 1] &lt;- max(rand_num)\n}\n\n# get the cutoff (99%) of the distribution of max values\ncutoff &lt;- quantile(max_rand_num, 0.99)\nprint(cutoff)\n\n     99% \n8.791655",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#using-monte-carlo-simulations-4",
    "href": "W6_Sampling.html#using-monte-carlo-simulations-4",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Using Monte Carlo Simulations 4",
    "text": "Using Monte Carlo Simulations 4\n\nThis shows that the 99th percentile of the finishing time distribution falls at 8.8083895 minutes, meaning that if we were to give that much time for the quiz, then we expect that in 99% of quizzes, every student would finish.\n\nAssumptions matter, otherwise results wrong! (We assumed: normal dist w/ particular mean and SD). Here assumptions certainly wrong –&gt; elapsed time not normal",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#resampling-the-bootstrap",
    "href": "W6_Sampling.html#resampling-the-bootstrap",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Resampling: The Bootstrap",
    "text": "Resampling: The Bootstrap\nWe can use simulations to demonstrate statistical principles (like we just did) but also to answer statistical questions.\nThe bootstrap is a simulation technique that allows us to quantify our uncertainty of estimates!\n\n\nWe repeatedly sample with replacement from an actual dataset.\nWe compute a statistic of interest for each sample.\nWe get the distribution of those statistics and use it as our sampling distribution.",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#bootstrap-example",
    "href": "W6_Sampling.html#bootstrap-example",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Bootstrap Example",
    "text": "Bootstrap Example\nLet’s use the bootstrap to estimate the sampling distribution of the mean heights of the NHANES dataset. We can then compare the result to the SEM (=uncertainty of the mean) that we discussed earlier.\n\n\n\n# perform the bootstrap to compute SEM and compare to parametric method\nnRuns &lt;- 2500\nsampleSize &lt;- 32\n\nheightSample &lt;- \n  NHANES_adult %&gt;%\n  sample_n(sampleSize) # draw 32 observations\n\n# function to bootstrap (sample w/ replacement) & get mean\nbootMeanHeight &lt;- function(df) {\n  bootSample &lt;- sample_n(df, dim(df)[1], replace = TRUE)\n  return(mean(bootSample$Height))\n}\n\n# run function 2500x\nbootMeans &lt;- replicate(nRuns, bootMeanHeight(heightSample))\n\n# calculate \"normal\" SEM and bootstrap SEM\nSEM_standard &lt;- sd(heightSample$Height) / sqrt(sampleSize)\nSEM_bootstrap &lt;- sd(bootMeans)\n\nSEM_standard\n\n[1] 1.921616\n\nSEM_bootstrap\n\n[1] 1.884266\n\n\n\n\n\n\n\n\nAn example of bootstrapping to compute the standard error of the mean adult height in the NHANES dataset. The histogram shows the distribution of means across bootstrap samples, while the red line shows the normal distribution based on the sample mean and standard deviation.",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#evaluation-bootstrapping",
    "href": "W6_Sampling.html#evaluation-bootstrapping",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Evaluation: Bootstrapping",
    "text": "Evaluation: Bootstrapping\n\n\nCon\nTakes very long to compute (compared to the SEM)\nPrecision depends on computing time\n\nPro\nNo assumption about sampling distribution necessary\nIs a good solution if you do not want to rely on certain assumptions\n\n\nBootstrapping is a so-called model-free procedure: You put in just the data and get a result that does not depend on any further assumptions.\nModel-based procedures (like most statistical tests we will cover in this class) are usually more precise if their assumptions are met. Unfortunately, assumptions are not always straightforward to check.",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#resampling",
    "href": "W6_Sampling.html#resampling",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Resampling",
    "text": "Resampling\nLet’s look at the Bootstrap. Remember that we usually use real data for bootstrapping and draw samples with replacement of the same size as the original dataset. We can use this to quantify uncertainty, such as with the Standard Error of the Mean (SEM) or Confidence Intervals.\nLet’s say we have a very small sample of “sweets consumed”. We don’t know the underlying distribution. We make up a dataset, but let’s pretend it is our real data:\n\ndata_10 &lt;- tibble(\n  participant = 1:10,\n  sweets = c(5, 5, 5, 7, 3, 3, 4, 6, 8, 4)\n)\n\n\nWe want to know how sample size influences the SEM, so we also have a sample with twice 10x as many observations:\n\ndata_20 &lt;- tibble(\n  participant = 1:100,\n  sweets = rpois(100,4) #random Poisson distribution\n)",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#resampling-3",
    "href": "W6_Sampling.html#resampling-3",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Resampling 3",
    "text": "Resampling 3\nLet’s resample 1000 times. To get the sampling distributions of the means, we have to save each mean of each iteration:\n\nset.seed(8465123)\niterations &lt;- 1000 \n\n# initialize empty matrices\nmean_bootstrap_10 &lt;- matrix(NA, nrow = iterations, ncol = 1)\nmean_bootstrap_20 &lt;- matrix(NA, nrow = iterations, ncol = 1)\n\nfor (i in 1:iterations) {\n  # draw exactly the same amount of datapoints as in the original dataset, but with replacement\n  bootstrap_data_10 &lt;- sample_n(data_10, 10, replace=TRUE)\n  bootstrap_data_20 &lt;- sample_n(data_20, 20, replace=TRUE)\n  \n  # calculate the mean for each of the subsamples, put it into matrix in subsequent rows\n  mean_bootstrap_10[i,1] &lt;- mean(bootstrap_data_10$sweets)\n  mean_bootstrap_20[i,1] &lt;- mean(bootstrap_data_20$sweets)\n}\n\n# calculate the SEMs\nsd(mean_bootstrap_10)\n\n[1] 0.4948013\n\nsd(mean_bootstrap_20)\n\n[1] 0.4900853\n\n\nWe can conclude that the SEM is smaller with a larger sample size, which means we can be more certain about our estimate! (We already knew this from the \\(\\sqrt{n}\\) in the denominator of the SE formular but it’s nice to see it confirmed.)",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#chi²-test-general",
    "href": "W8_ModelingRelationships.html#chi²-test-general",
    "title": "08 Modeling Relationships",
    "section": "Chi² Test: General",
    "text": "Chi² Test: General\nWe will first focus on modeling categorical relationships (i.e., of variables that are qualitative!).\n\nThese data are usually expressed in terms of counts.\n\n\nExample: Candy colors\nBag of candy: 30 chocolates, 33 licorices, and 37 gumballs.\n\n\nIs the distribution fair (i.e., 1/3rd of the bag for each candy) and the fact that there are only 30 chocolates within expectations?\n\n\nWhat is the likelihood that the count would come out this way (or even more extreme) if the true probability of each candy type is the same?\n\nCounts: For each combination of variables, how many observations do we have?\nIf the machine really sorts on average 1/3 of each in each bag? How much is due to chance?",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#chi²-test-one-variable",
    "href": "W8_ModelingRelationships.html#chi²-test-one-variable",
    "title": "08 Modeling Relationships",
    "section": "Chi² Test: One Variable",
    "text": "Chi² Test: One Variable\nThe Chi² test checks whether observed counts differ from expected values (\\(H_0\\)).\n\\[\n\\chi^2 = \\sum_i\\frac{(observed_i - expected_i)^2}{expected_i}\n\\]\n\nThe null hypothesis in our example is that the proportion of each type of candy is equal (1/3 or ~33.33).\nIf we plug in our values from above, we would calculate \\(\\chi^2\\) like this:\n\\[ \\chi^2 = \\frac{(30 - 33.33)^2}{33.33} + \\frac{(33 - 33.33)^2}{33.33} + \\frac{(37 - 33.33)^2}{33.33} = 0.74 \\]\n\ntake the difference between observed and expected (33.33), square it, divide it by expected 33.33 and add everything up",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#chi²-test-general-1",
    "href": "W8_ModelingRelationships.html#chi²-test-general-1",
    "title": "08 Modeling Relationships",
    "section": "Chi² Test: General",
    "text": "Chi² Test: General\nOn its own, the \\(\\chi^2\\) statistic is not interpretable - it depends on its distribution.\nThe shape of the \\(\\chi^2\\) distribution depends on the degrees of freedom (much like the t distribution), which is the number of category levels \\(k-1\\).",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#chi2-test-candies",
    "href": "W8_ModelingRelationships.html#chi2-test-candies",
    "title": "08 Modeling Relationships",
    "section": "Chi2 Test: Candies",
    "text": "Chi2 Test: Candies\nFor the candy example, we use a chi-squared distribution with \\(DFs = 2\\) (3 candy categories minus one → green line). If we’d look at the distribution and found \\(\\chi^2 = .74\\) on the x-axis (dashed red line), we would see that it does not fall far into the tail of the distribution but is rather in the middle. If we calculate the p-value, we’d get \\(P(\\chi^2 &gt; .74) = 0.691\\).\n\nIt is thus not particularly surprising to find this distribution of candies and we would not reject \\(H_0\\) (equal proportions).",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#contingency-tables-and-the-two-way-test",
    "href": "W8_ModelingRelationships.html#contingency-tables-and-the-two-way-test",
    "title": "08 Modeling Relationships",
    "section": "Contingency Tables and the Two-Way Test",
    "text": "Contingency Tables and the Two-Way Test\nThe \\(\\chi^2\\) test is also used to test whether two categorical variables are related to each other.\n\nExample: Are Black drivers more likely to be pulled over by police than white drivers?\nWe have two variables: Skin color (black vs white) and being pulled over (true vs. false). We can represent the data in a contingency table (remember: the count() function was helpful to do this in R):\n\n\n\nContingency table for police search data\n\n\nsearched\nBlack\nWhite\nBlack (relative)\nWhite (relative)\n\n\n\n\nFALSE\n36244\n239241\n0.1295298\n0.8550062\n\n\nTRUE\n1219\n3108\n0.0043565\n0.0111075",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#contingency-tables-and-the-two-way-test-1",
    "href": "W8_ModelingRelationships.html#contingency-tables-and-the-two-way-test-1",
    "title": "08 Modeling Relationships",
    "section": "Contingency Tables and the Two-Way Test",
    "text": "Contingency Tables and the Two-Way Test\nIf there is no relationship between skin color and being searched, the frequencies of searches would be proportional to the frequencies of skin color. This would be our expected values. We can determine them using probabilities:\n\n\n\n\nBlack\nWhite\n\n\n\n\n\nNot searched\n\\(P(\\neg S)*P(B)\\)\n\\(P(\\neg S)*P(W)\\)\n\\(P(\\neg S)\\)\n\n\nSearched\n\\(P(S)*P(B)\\)\n\\(P(S)*P(W)\\)\n\\(P(S)\\)\n\n\n\n\\(P(B)\\)\n\\(P(W)\\)\n\\(100\\%\\)\n\n\n\nRemember: You can only multiply two probabilities to get their conjoint probability if they are independent. Here, we assume independence to calculate expected values and then check how much our observed values deviate from independence.\n\nProbabilities: Because we expect the variables to be unrelated, we can calculate the joint probability as the product of the marginal probabilities:\n\\(P(X \\cap Y) = P(X) * P(Y)\\)\nMarginal probabilities are the prob of each event occuring regardless of other events (in the margins of the table!)",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#chi²-test-with-two-variables",
    "href": "W8_ModelingRelationships.html#chi²-test-with-two-variables",
    "title": "08 Modeling Relationships",
    "section": "Chi² Test with Two Variables",
    "text": "Chi² Test with Two Variables\nIf we compute the standardized squared difference between observed and expected values, we can sum them up to get \\(\\chi^2 = 828.3\\)\n\n\n\nContingency table for police search data\n\n\nsearched\ndriver_race\nn\nexpected\nstdSqDiff\n\n\n\n\nFALSE\nBlack\n36244\n36883.67\n11.09\n\n\nTRUE\nBlack\n1219\n579.33\n706.31\n\n\nFALSE\nWhite\n239241\n238601.33\n1.71\n\n\nTRUE\nWhite\n3108\n3747.67\n109.18\n\n\n\n\n\nWe can then compute the p-value using a chi-squared distribution with \\(DF = (levels_{var1} - 1) * (levels_{var2} - 1) = (2-1) * (2-1) = 1\\)",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#chi²-test-with-two-variables-in-r",
    "href": "W8_ModelingRelationships.html#chi²-test-with-two-variables-in-r",
    "title": "08 Modeling Relationships",
    "section": "Chi² Test with Two Variables in R",
    "text": "Chi² Test with Two Variables in R\nWe can calculate a \\(\\chi^2\\) test easily in R:\n\nchisq.test(summaryDf2wayTable, correct = FALSE)\n\n\n    Pearson's Chi-squared test\n\ndata:  summaryDf2wayTable\nX-squared = 828.3, df = 1, p-value &lt; 2.2e-16\n\n\nThe results indicate that the data are highly unlikely if there was no true relationship between skin color and police searches! We would thus reject \\(H_0\\).\n\nDF: computing the expected frequencies requires three values: total number of observations and marg probs each variable. thus only one of the four values can vary freely.",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#chi²-test-with-two-variables-interpretation",
    "href": "W8_ModelingRelationships.html#chi²-test-with-two-variables-interpretation",
    "title": "08 Modeling Relationships",
    "section": "Chi² Test with Two Variables: Interpretation",
    "text": "Chi² Test with Two Variables: Interpretation\nQuestion: What is the direction of the observed relationship?\n\n\n\nContingency table for police search data\n\n\nsearched\ndriver_race\nn\nexpected\nstdSqDiff\n\n\n\n\nFALSE\nBlack\n36244\n36883.67\n11.09\n\n\nTRUE\nBlack\n1219\n579.33\n706.31\n\n\nFALSE\nWhite\n239241\n238601.33\n1.71\n\n\nTRUE\nWhite\n3108\n3747.67\n109.18",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#standardized-residuals",
    "href": "W8_ModelingRelationships.html#standardized-residuals",
    "title": "08 Modeling Relationships",
    "section": "Standardized Residuals",
    "text": "Standardized Residuals\nIf we want to know not only whether but also how the data differ from what we would expect under \\(H_0\\), we can examine the residuals of the model.\nThe residuals tell us for each cell how much the observed data deviates from the expected data.\nTo make the residuals better comparable, we will look at the standardized residuals:\n\\[\n\\text{standardized residual}_{ij} = \\frac{observed_{ij} - expected_{ij}}{\\sqrt{expected_{ij}}}\n\\]\nwhere \\(i\\) and \\(j\\) are the rows and columns respectively.",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#standardized-residuals-1",
    "href": "W8_ModelingRelationships.html#standardized-residuals-1",
    "title": "08 Modeling Relationships",
    "section": "Standardized Residuals",
    "text": "Standardized Residuals\nNegative residuals indicate an observed value smaller than expected.\n\n\n\nSummary of standardized residuals for police stop data\n\n\nsearched\ndriver_race\nStandardized residuals\n\n\n\n\nFALSE\nBlack\n-3.330746\n\n\nTRUE\nBlack\n26.576456\n\n\nFALSE\nWhite\n1.309550\n\n\nTRUE\nWhite\n-10.449072\n\n\n\n\n\n\nraw residuals depend on number of observations!\nBlack individuals are searched way more often than expected –&gt; helps us intepret significant results.",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#odds-ratios",
    "href": "W8_ModelingRelationships.html#odds-ratios",
    "title": "08 Modeling Relationships",
    "section": "Odds Ratios",
    "text": "Odds Ratios\nAlternatively, we can represent the relative likelihood of different outcomes as odds ratios:\n\\[\nodds_{searched|black} = \\frac{N(searched\\cap black)}{N(\\neg searched \\cap black)} = \\frac{1219}{36244} = 0.034\n\\]\n\\[\nodds_{searched|white} = \\frac{N(searched \\cap white)}{N(\\neg searched \\cap white)} = \\frac{3108}{239241} = 0.013\n\\]\n\\[\nodds\\ ratio = \\frac{odds(searched|black)}{odds(searched|white)} = 2.59\n\\]\nThe odds of being searched are 2.59x higher for Black vs. white drivers!",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#simpsons-paradox",
    "href": "W8_ModelingRelationships.html#simpsons-paradox",
    "title": "08 Modeling Relationships",
    "section": "Simpson’s Paradox",
    "text": "Simpson’s Paradox\nThe Simpson’s Paradox is a great example of misleading summaries.\n\nIf we look at the baseball data below, we see that David Justice has a better batting average in every single year, but Derek Jeter has a better overall batting average:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlayer\n1995\n\n1996\n\n1997\n\nCombined\n\n\n\n\n\nJeter\n12/48\n.250\n183/582\n.314\n190/654\n.291\n385/1284\n.300\n\n\nJustice\n104/411\n.253\n45/140\n.321\n163/495\n.329\n312/1046\n.298\n\n\n\nHow can this be?\n\n\nSimpson’s Paradox: A pattern is present in the combined dataset but may be different in subsets of the data.\n\n\nHappens if another (lurking) variable changes across subsets (e.g., the number of at-bats, i.e., the denominator).\n\nbatting average: hits/at bats\n1995: in general low batting averages, Justice had a lot of at-bats =&gt; diminishes total combined value more strongly than for Jeter.\n1996: both players were above their average but Jeter had way more at-bats =&gt; more important for the overall average.",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#simpsons-paradox-more-intuitive",
    "href": "W8_ModelingRelationships.html#simpsons-paradox-more-intuitive",
    "title": "08 Modeling Relationships",
    "section": "Simpson’s Paradox: More intuitive",
    "text": "Simpson’s Paradox: More intuitive\nWhile typing on a keyboard, what is the relationship between speed (words per minute) and accuracy (% correct words)? (positive, negative, or none)\n\n\n\nIf I try to type faster, I will make more errors ⇒ speed-accuracy trade-off (negative association)\nPeople who are better at typing usually are both faster and make fewer mistakes (positive association)\n\n\n\n\nAnswer: It depends\n\nWithin a person, the relationship between speed and accuracy is negative. My own skill is limited, I can either use it for speed or accuracy.\nBetween persons, the relationship is positive due to inter-individual differences in overall typing skill.\n\n\nUsually, when leveling up, people don’t put all their skill points in only speed or accuracy.",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#example-income-inequality-and-hate-crimes",
    "href": "W8_ModelingRelationships.html#example-income-inequality-and-hate-crimes",
    "title": "08 Modeling Relationships",
    "section": "Example: Income Inequality and Hate Crimes",
    "text": "Example: Income Inequality and Hate Crimes\nWe want to look at a dataset that was used for an analysis of the relationship between income inequality (Gini index) and the prevalence of hate crimes in the USA.\n\nIt looks like there is a positive relationship between the variables. How can we quantify this relationship?",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#covariance-and-correlation",
    "href": "W8_ModelingRelationships.html#covariance-and-correlation",
    "title": "08 Modeling Relationships",
    "section": "Covariance and Correlation",
    "text": "Covariance and Correlation\nVariance (single variable): \\(s^2 = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{N - 1}\\)\nCovariance (two variables): \\(covariance = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{N - 1}\\)\n\n“Is there a relation between the deviations of two different variables (from their means) across observations?”\n\n\nCovariance will be far from 0 if data points share a relationship. Positive values for same direction, negative values for opposite directions.\n\n\nCovariance varies with overall level of variance in the data ⇒ hard to compare different relationships\n\n\n\n\nCorrelation coefficient (Pearson correlation): Scales the covariance by the standard deviations of the two variables and thus standardizes it (→ \\(r\\) varies between \\(-1\\) and \\(1\\) ⇒ comparability!)\n\\[\nr = \\frac{covariance}{s_xs_y} = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{(N - 1)s_x s_y}\n\\]\n\nInsight: Variance is the covariance of a variable with itself.\nCovariance depends on dataset and even on scaling of variables!\ne.g. relationship between body height and weight ⇒ Using m vs. cm for height will change variance and thus covariance even though the relationship should be identical (same data)",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#hypothesis-testing-for-correlations",
    "href": "W8_ModelingRelationships.html#hypothesis-testing-for-correlations",
    "title": "08 Modeling Relationships",
    "section": "Hypothesis Testing for Correlations",
    "text": "Hypothesis Testing for Correlations\nThe correlation between income inequality and hate crimes is \\(r = .42\\), which seems to be a reasonably strong (positive) relationship.\n\nWe can test whether such a relationship could occur by chance, even if there is actually no relationship. In this case, our null hypothesis is \\(H_0: r = 0\\).\n\n\nTo test whether there is a significant relationship, we can transform the \\(r\\) statistic into a \\(t\\) statistic:\n\\[\nt_r = \\frac{r\\sqrt{N-2}}{\\sqrt{1-r^2}}\n\\]",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#correlation-in-r",
    "href": "W8_ModelingRelationships.html#correlation-in-r",
    "title": "08 Modeling Relationships",
    "section": "Correlation in R",
    "text": "Correlation in R\n\n# perform correlation test on hate crime data\ncor.test(\n  hateCrimes$avg_hatecrimes_per_100k_fbi,\n  hateCrimes$gini_index\n)\n\n\n    Pearson's product-moment correlation\n\ndata:  hateCrimes$avg_hatecrimes_per_100k_fbi and hateCrimes$gini_index\nt = 3.2182, df = 48, p-value = 0.002314\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.1619097 0.6261922\nsample estimates:\n      cor \n0.4212719 \n\n\nThe p-value is quite small, which indicates that it is quite unlikely to find an \\(r\\) value this high or more extreme with 48 degress of freedom. We would thus reject \\(H_0: r = 0\\).\n\n\nsubsetting with $!\n\n\nSide note: There are more beautiful & convenient ways to do this in R. We will cover this in the next session.",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#robust-correlations",
    "href": "W8_ModelingRelationships.html#robust-correlations",
    "title": "08 Modeling Relationships",
    "section": "Robust Correlations",
    "text": "Robust Correlations\nIn the plot, we have seen an outlier: The District of Columbia was quite different from the other data points.\n\nThe Pearson’s correlation coefficient \\(r\\) is highly sensitive to outliers, see this hypothetical example:",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#robust-correlation-2",
    "href": "W8_ModelingRelationships.html#robust-correlation-2",
    "title": "08 Modeling Relationships",
    "section": "Robust Correlation 2",
    "text": "Robust Correlation 2\nWe can use a different correlation coefficient, which is less sensitive to outliers: Spearman correlation.\nIt is based on ranking (i.e., ordering) the data and using the ranks (instead of the original data) for the correlation.\n\ncor.test(hateCrimes$avg_hatecrimes_per_100k_fbi,\n  hateCrimes$gini_index,\n  method = \"spearman\")\n\n\n    Spearman's rank correlation rho\n\ndata:  hateCrimes$avg_hatecrimes_per_100k_fbi and hateCrimes$gini_index\nS = 20146, p-value = 0.8221\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n       rho \n0.03261836 \n\n\nThe correlation has now dropped from \\(.42\\) to \\(.03\\) and is no longer significant.\nOf course, a ranked correlation can also obscure true effects that critically depend on the scale of the data. When in doubt, try both and discuss reasons for differences.\n\nWithout outlier: perfectly negative correlation, with outlier: highly positive!",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#correlation-and-causation",
    "href": "W8_ModelingRelationships.html#correlation-and-causation",
    "title": "08 Modeling Relationships",
    "section": "Correlation and Causation",
    "text": "Correlation and Causation\nDoing a well controlled, randomized experiment (RCT) is extremely helpful to gather causal evidence. However, it is not always possible or ethical to do an experiment!\nWithout an experiment, we can still collect observational data. However, if we correlate two observed variables, we can’t conclude that one causes the other: They (likely) share a relationship but there could also be a third variable that causes both (or even more complex causal structures).",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#causal-graphs",
    "href": "W8_ModelingRelationships.html#causal-graphs",
    "title": "08 Modeling Relationships",
    "section": "Causal Graphs",
    "text": "Causal Graphs\nIf we have observational data, causal graphs can be helpful for interpreting causality:\n\n\n\n\n\n\n\n\n\n\n\n\nCircle: observed variables\nrectangle: latent (unobservable) variable\n\nGreen arrow: positive relationship,\nred: negative\nExamGrade and FinishTime seem negatively related if we ignore other variables!\n(“Hand in your exam early to improve your grade!”)\nKnowledge = theoretical mediator\nStudyTime = proxy for knowledge\nIf we control for StudyTime (which approximates individual knowledge), we find out that ExamGrade and FinishTime are (causally) unrelated!\n\n\nWe have briefly talked about causation in week 1\nThink of data/questions where it is impossible/unethical!\nabused children and brain development!\n(3rd var: family stress -&gt; less intellectual engagement –&gt; poorer brain dev)\nCorrelation: s.th. is probably causing s.th. else but not clear what causes what!\nDAG:\ngreen: pos, red: net\ncircle: observed, rect: latent (unobservable)\nExamGrade and FinishTime seem neg related if we ignore others\nknowledge = mediates\nStudyTime = proxy for knowledge, if we “control” it/hold it constant/only use people with same amount, we would see that EG and FT are unrelated!",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#testing-a-single-mean-one-sample-t-test",
    "href": "W8_ModelingRelationships.html#testing-a-single-mean-one-sample-t-test",
    "title": "08 Modeling Relationships",
    "section": "Testing a Single Mean (One sample t-Test)",
    "text": "Testing a Single Mean (One sample t-Test)\nWe sometimes might want to know whether a single value, the mean of a group, differs from a specific value, e.g. whether the blood pressure in the sample differs from or is bigger than 80.\n\nWe can test this using the \\(t\\)-test, which we have already encountered in the “Hypothesis Testing” session!\n\\[\nt = \\frac{\\hat{X} - \\mu}{SEM}\n\\]\n\\[\nSEM = \\frac{\\hat{\\sigma}}{\\sqrt{n}}\n\\]\n\\(\\hat{X}\\) is the mean of our sample, \\(\\mu\\) the hypothesized population mean (e.g. the value we want to test against, such as 80 for the blood pressure example).",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#one-sample-t-test-in-r",
    "href": "W8_ModelingRelationships.html#one-sample-t-test-in-r",
    "title": "08 Modeling Relationships",
    "section": "One sample t-Test in R",
    "text": "One sample t-Test in R\n\nt.test(x=NHANES_adult$BPDiaAve, mu=80, alternative='greater')\n\n\n    One Sample t-test\n\ndata:  NHANES_adult$BPDiaAve\nt = -55.23, df = 4599, p-value = 1\nalternative hypothesis: true mean is greater than 80\n95 percent confidence interval:\n 69.1588     Inf\nsample estimates:\nmean of x \n 69.47239 \n\n\n\nThe observed mean is actually much below 80, providing no evidence for our directional alternative hypothesis that it would be greater than 80 ⇒ the p values is (rounded to) 1.\n\n\nIf we had tested two-sidedly, we would have found a significant result. It may seem tempting now to create a story around an altered, non-directional alternative hypothesis, which is why it is important to preregister your hypotheses and analyses.\n\n(The \\(t\\) statistic thus asks how large the deviation of sample mean from the expected value with respect to the sampling variability of the mean!)\nWe tested the one-sided alternative (&gt;) and the blood pressure in the sample is much lower than 80, so it is far from significance\nWe can’t interpret the \\(p\\)-value as evidence in favor of \\(H_0\\) (i.e. larger \\(p\\)-value! vs non.sign) –&gt; Bayes!",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#comparing-two-means-independent-samples-t-test",
    "href": "W8_ModelingRelationships.html#comparing-two-means-independent-samples-t-test",
    "title": "08 Modeling Relationships",
    "section": "Comparing Two Means (Independent samples t-Test)",
    "text": "Comparing Two Means (Independent samples t-Test)\nMore often, we want to know whether there is a difference between the means of two groups.\nExample: Do regular marijuana smokers watch more television?\n\n\\(H_0\\) = marijuana smokers watch less or equally often TV,\n\\(H_A\\) = marijuana smokers watch more TV.\nIf the observations are independent (i.e. you really have two unrelated groups), you can use a very similar formula to calculate the \\(t\\) statistic:\n\\[\nt = \\frac{\\bar{X_1} - \\bar{X_2}}{\\sqrt{\\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}}}\n\\]\nwhereby \\(\\hat{X_1}\\) and \\(\\hat{X_2}\\) are the group means, \\(S_1^2\\) and \\(S_2^2\\) the group variances, and \\(n_1\\) and \\(n_2\\) the group sizes.",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#independent-samples-t-test-in-r",
    "href": "W8_ModelingRelationships.html#independent-samples-t-test-in-r",
    "title": "08 Modeling Relationships",
    "section": "Independent samples t-Test in R",
    "text": "Independent samples t-Test in R\n\n# t.test(NHANES_sample$TVHrsNum[NHANES_sample$RegularMarij==\"Yes\"],\n#        NHANES_sample$TVHrsNum[NHANES_sample$RegularMarij==\"No\"],\n#        alternative = \"greater\")\n\nwith(NHANES_sample, #only refer to data once using \"with\" function\n     t.test(TVHrsNum[RegularMarij==\"Yes\"],\n            TVHrsNum[RegularMarij==\"No\"],\n            alternative = \"greater\"))\n\n\n    Welch Two Sample t-test\n\ndata:  TVHrsNum[RegularMarij == \"Yes\"] and TVHrsNum[RegularMarij == \"No\"]\nt = 1.2147, df = 116.9, p-value = 0.1135\nalternative hypothesis: true difference in means is greater than 0\n95 percent confidence interval:\n -0.09866006         Inf\nsample estimates:\nmean of x mean of y \n  2.30000   2.02963 \n\n\n\n\nDV: continuous, IV: categories\nn.s. (differs from book), although mean is higher in Yes, not significantly different!",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#comparing-dependent-observations-paired-samples-t-test",
    "href": "W8_ModelingRelationships.html#comparing-dependent-observations-paired-samples-t-test",
    "title": "08 Modeling Relationships",
    "section": "Comparing Dependent Observations (Paired samples t-test)",
    "text": "Comparing Dependent Observations (Paired samples t-test)\nIf we have repeated observations of the same subject (i.e., a within-subject design), we might want to compare the same subject thus on multiple, repeated measurements.\n\nIf we want to test whether blood pressure differs between the first and second measurement session across individuals, we can use a paired \\(t\\)-test.\nSide note: A paired \\(t\\)-test is equivalent to a one-sample \\(t\\)-test, when using the paired differences (\\(X_2 - X_1\\)) as \\(\\hat{X}\\) and testing them against a value of 0 (if we expect no difference for \\(H_0\\)) for \\(\\mu\\).\n\nimportant: If we run an independent sample t-test, it would probably be n.s.! (check out book)",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#paired-samples-t-test-in-r",
    "href": "W8_ModelingRelationships.html#paired-samples-t-test-in-r",
    "title": "08 Modeling Relationships",
    "section": "Paired samples t-test in R",
    "text": "Paired samples t-test in R\n\nt.test(NHANES_sample$BPSys1, NHANES_sample$BPSys2, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  NHANES_sample$BPSys1 and NHANES_sample$BPSys2\nt = 2.7369, df = 199, p-value = 0.006763\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.2850857 1.7549143\nsample estimates:\nmean difference \n           1.02",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#comparing-more-than-two-means",
    "href": "W8_ModelingRelationships.html#comparing-more-than-two-means",
    "title": "08 Modeling Relationships",
    "section": "Comparing More Than Two Means",
    "text": "Comparing More Than Two Means\nOften, we want to compare more than two means, e.g. different treatment groups or time points.\nExample: Different treatments for blood pressure",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#analysis-of-variance-anova",
    "href": "W8_ModelingRelationships.html#analysis-of-variance-anova",
    "title": "08 Modeling Relationships",
    "section": "Analysis of Variance (ANOVA)",
    "text": "Analysis of Variance (ANOVA)\n\\(H_0\\): all means are equal\n\\(H_A\\): not all means are equal (e.g. at least one differs)\n\nWe can partition the variance of the data into different parts:\n\\(SS_{total}\\) = total variance in the data\n\\(SS_{model}\\) = Variance explained by the model\n\\(SS_{error}\\) = Variance not explained by the model\n\n\nWe can use those to calculate the mean squares for the model and the error:\n\\(MS_{model} =\\frac{SS_{model}}{df_{model}}= \\frac{SS_{model}}{p-1}\\) (\\(p\\) is the number of factor levels or groups)\n\\(MS_{error} = \\frac{SS_{error}}{df_{error}} = \\frac{SS_{error}}{N - p}\\) (\\(N\\) is the total sample size across groups)\n\n\nquite common analysis! We will just scratch the surface\n\n\n\n\\(SS\\) = Sum of Squares, remember that the variance is the sum of the squared deviation of an observation to the mean\n\\(MS\\) = Mean (Sum of) Squares: How much variance per degree of freedom?",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#anova-in-r",
    "href": "W8_ModelingRelationships.html#anova-in-r",
    "title": "08 Modeling Relationships",
    "section": "ANOVA in R",
    "text": "ANOVA in R\nIn R, we would run an ANOVA like this:\n\ndf &lt;-\n  df %&gt;% \n  mutate(group2=fct_relevel(group,c(\"placebo\",\"drug1\",\"drug2\")))\n# reorder the factor levels so that \"placebo\" is the control condition/intercept!\n  \n \n# test model without separate duymmies\nlmResultAnovaBasic &lt;- lm(sysBP ~ group2, data=df)\nanova(lmResultAnovaBasic)\n\nAnalysis of Variance Table\n\nResponse: sysBP\n           Df  Sum Sq Mean Sq F value   Pr(&gt;F)    \ngroup2      2  2115.6 1057.81  10.714 5.83e-05 ***\nResiduals 105 10366.7   98.73                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe \\(F\\)-statistic (also called omnibus test) actually tests our overall hypothesis of no difference between conditions.",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#anova-in-r-1",
    "href": "W8_ModelingRelationships.html#anova-in-r-1",
    "title": "08 Modeling Relationships",
    "section": "ANOVA in R",
    "text": "ANOVA in R\nWe now know that not all groups should be considered equal. But where is the difference?\n\nsummary(lmResultAnovaBasic)\n\n\nCall:\nlm(formula = sysBP ~ group2, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-29.0838  -7.7452  -0.0978   7.6872  23.4313 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  141.595      1.656  85.502  &lt; 2e-16 ***\ngroup2drug1  -10.237      2.342  -4.371 2.92e-05 ***\ngroup2drug2   -2.027      2.342  -0.865    0.389    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.936 on 105 degrees of freedom\nMultiple R-squared:  0.1695,    Adjusted R-squared:  0.1537 \nF-statistic: 10.71 on 2 and 105 DF,  p-value: 5.83e-05\n\n# emmeans(lmResultAnovaBasic, \"group2\" ) #run this to get means and CIs for each group\n\nWe can see a \\(t\\)-test for every drug against the placebo (remember we used fct_relevel for this). The \\(t\\)-tests show that drug1 (but not drug2) differs significantly from placebo.",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#anova-in-r-comments",
    "href": "W8_ModelingRelationships.html#anova-in-r-comments",
    "title": "08 Modeling Relationships",
    "section": "ANOVA in R: Comments",
    "text": "ANOVA in R: Comments\nIn this simple example, we could have skipped the omnibus test (anova()) and just looked at the summary().\nIn practise, you will often run ANOVAs with several factors (grouping variables) that all have a multitude of factor levels (subgroups).\nThink: Two groups of drugs and one placebo across four time points (before, during, after, & follow-up). This quickly creates too many possible comparisons to keep track of.\nThis complicates things furhter because then you can also have interactions between variables (e.g., drug1 does not work better but faster than drug2).\nFor these examples, it is helpful to first get an overall statement if a factor (or an interaction of factors) has an influence on the results. If this is the case, you can run the individual t-tests for this factor to get a more detailed look.",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  }
]