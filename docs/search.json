[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Biostatistics",
    "section": "",
    "text": "Welcome to the website of the course “Biostatistics” of the master’s programme “Translational Neuroscience” of the Julius-Maximilians-University Würzburg.\nPlease use the navigation on the left to select the slides for each session (recommendation: Open in new tab).\n\n\n\n\n\n\n\n\n\n\nDate\nTopic\nReading\nLecturer\nProject Deadlines\n\n\n\n\n16.10.\nGeneral & R Intro\nST21: 1-3, QF: 1-3\nReutter\nR & RStudio installed\n\n\n23.10.\nModels\nST21: 4, QF: 4-6\nHildebrandt\n\n\n\n30.10.\nData Wrangling\nST21: 4, QF: 4-6\nReutter\n\n\n\n06.11.\nData Visualization\nQF: 7\nReutter\n\n\n\n13.11.\nProbability\nST21: 7-8, QF: 8\nHildebrandt\nDataset\n\n\n20.11.\nPenance Day\n\n\n\n\n\n27.11.\nSampling\nST21: 7-8, QF: 8\nHildebrandt\n\n\n\n04.12.\nHypothesis Testing\nST21: 9-10\nReutter\n\n\n\n11.12.\nComparing Means & Categories\nST21: 12, 15\nReutter\nResearch Question & Hypotheses\n\n\n18.12.\nExercises (t-Tests, Chi²)\nST21: 12, 15\nReutter\n\n\n\n25.12. & 01.01.\nChristmas & New Year’s\n\n\n\n\n\n08.01.\n(General) Linear Models\nST21: 12-13\nHildebrandt\nFirst Analysis Ideas\n\n\n15.01.\nExercises (GLM)\nST21: 12-13\nHildebrandt\n\n\n\n22.01.\nLinear Mixed Models\nST21: 14\nHildebrandt\nAnalysis (with R scripts)\n\n\n29.01.\nR Markdown for Reports\n\nReutter\n\n\n\n05.02.\nTroubleshooting Your Report\n\nboth\nSend Questions via Email\n\n\n12.02.\nReproducible Research\nST21: 18\nHildebrandt\nReport (with R Markdown)"
  },
  {
    "objectID": "W1_Intro.html#hello",
    "href": "W1_Intro.html#hello",
    "title": "01a Introduction to Biostatistics",
    "section": "Hello!",
    "text": "Hello!\nWho am I?\n\nWho are you?\n\nWhat is your background?\nDo you have experience with data analysis?\nWhat’s your attitude towards statistics?",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#using-the-slides",
    "href": "W1_Intro.html#using-the-slides",
    "title": "01a Introduction to Biostatistics",
    "section": "Using the Slides",
    "text": "Using the Slides\n\nThese slides are created directly in R with the quarto extension.\nYou can jump to a slide by clicking the three dashes in the bottom left.\nYou can conveniently copy R code from the slides with one click and paste it into your RStudio.\n\n\nprint(\"Hello World\")\n\n[1] \"Hello World\"",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#organizational-issues",
    "href": "W1_Intro.html#organizational-issues",
    "title": "01a Introduction to Biostatistics",
    "section": "Organizational Issues",
    "text": "Organizational Issues\n\n\n\nAttendance is mandatory! (I don’t make the rules :) )\n\nYou may miss one session without giving reasons (recommendation: don’t waste it early!)\nIf you miss additional sessions, please write an email with an explanation (further proof may be required, e.g. doctor’s certificate)\n\n\n\n\n\nThe course will take place in person\n\nOnly for students who are not in Würzburg yet, there is an option via Zoom\n\n\n\n\n\nWe will use these textbooks (Open Educational Resources - freely available online, also linked in WueCampus):\n\nStatistical Thinking for the 21st Century\nFor the R part: Fundamentals of Quantitative Analysis\n(Additional Resource: R for Data Science)",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#contents",
    "href": "W1_Intro.html#contents",
    "title": "01a Introduction to Biostatistics",
    "section": "Contents",
    "text": "Contents\n\n\nFrom basic probability to (Generalized) Linear Mixed Models\n\nSome things may be repetitive for you but this course aims to provide a common starting position for your next semesters\n\nInput (lecture style) with hands-on R sessions \nIn addition, you should read a few pages in the text books\n(Statistical Thinking for the 21st Century, and possibly Fundamentals of Quantitative Analysis)\nProject: Independently analyze a dataset (exam with pass or fail grading)\n\n\n\nFor some, e.g. the psychologists, it will be more of a repetition - but you will also learn R.\nSlides might be text heavy → so that you can go through the slides afterwards again (but textbook might also be helpful)",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#project",
    "href": "W1_Intro.html#project",
    "title": "01a Introduction to Biostatistics",
    "section": "Project",
    "text": "Project\n\n\nFind a dataset that can answer a question you are interested in\n\nhttps://ourworldindata.org/\nStatistisches Bundesamt\nYour own, e.g., from an internship\n\n\n\n\n\npreprocess/wrangle it,\nanalyze the data,\nand write a short (min. 2-page) report!\n\nshort intro incl. research question and hypothesis\nmethods (both how the data were acquired and how they are analyzed)\nresults (incl. at least one plot)\nand a short discussion.\n\nAll these parts should be at least half a page long.",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#schedule",
    "href": "W1_Intro.html#schedule",
    "title": "01a Introduction to Biostatistics",
    "section": "Schedule",
    "text": "Schedule\nThe up-to-date version can be found at https://spressi.github.io/biostats/\n\n\n\n\n\n\n\n\n\n\nDate\nTopic\nReading\nLecturer\nProject Deadlines\n\n\n\n\n16.10.\nGeneral & R Intro\nST21: 1-3, QF: 1-3\nReutter\nR & RStudio installed\n\n\n23.10.\nProbability\nST21: 4, QF: 4-6\nHildebrandt\n\n\n\n30.10.\nData Wrangling\nST21: 4, QF: 4-6\nReutter\n\n\n\n06.11.\nData Visualization\nQF: 7\nReutter\n\n\n\n13.11.\nSampling\nST21: 7-8, QF: 8\nHildebrandt\nDataset\n\n\n20.11.\nPenance Day\n\n\n\n\n\n27.11.\nProbability & Sampling in R\nST21: 7-8, QF: 8\nHildebrandt\n\n\n\n04.12.\nHypothesis Testing\nST21: 9-10\nReutter\n\n\n\n11.12.\nComparing Means & Categories\nST21: 12, 15\nReutter\nResearch Question & Hypotheses\n\n\n18.12.\nExercises (t-Tests, Chi²)\nST21: 12, 15\nReutter\n\n\n\n25.12. & 01.01.\nChristmas & New Year’s\n\n\n\n\n\n08.01.\n(General) Linear Models\nST21: 12-13\nHildebrandt\nFirst Analysis Ideas\n\n\n15.01.\nExercises (GLM)\nST21: 12-13\nHildebrandt\n\n\n\n22.01.\nLinear Mixed Models\nST21: 14\nHildebrandt\nAnalysis (with R scripts)\n\n\n29.01.\nR Markdown for Reports\n\nReutter\n\n\n\n05.02.\nTroubleshooting Your Report\n\nboth\nSend Questions via Email\n\n\n12.02.\nReproducible Research\nST21: 18\nHildebrandt\nReport (with R Markdown)\n\n\n\n\n\nST21: Statistical Thinking for the 21st Century\nQF: Fundamentals of Quantitative Analysis (QuantFun)",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#why-is-it-important-that-you-know-statistics",
    "href": "W1_Intro.html#why-is-it-important-that-you-know-statistics",
    "title": "01a Introduction to Biostatistics",
    "section": "Why is it important that YOU know statistics?",
    "text": "Why is it important that YOU know statistics?\n\n\nYou’re doing a research master!\n\nResearch = Reading & understanding papers (esp. the analyses)\nDesigning your own experiments, analyze data, interpret results\n\nWe live in an increasingly data-centric world\n\nKnowing how to wrangle and analyze data is a valuable skill\n\nFacts & data literacy matter more than ever!\n\nFake News, “Lying with stats”, Reproducibility Crisis\nBeing able to call bullshit (https://www.callingbullshit.org/)\n\n“I only believe in statistics that I doctored myself” ― Winston S. Churchill\n\nHowever: “It is easy to lie with statistics, but easier to lie without them” ― Frederick Mosteller",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#what-is-statistical-thinking",
    "href": "W1_Intro.html#what-is-statistical-thinking",
    "title": "01a Introduction to Biostatistics",
    "section": "What is Statistical Thinking?",
    "text": "What is Statistical Thinking?\n\n\n“a systematic way of thinking about how we describe the world and use data [to] make decisions and predictions, all in the context of the inherent uncertainty that exists in the real world.” (Poldrack, Preface of ST21)\n“Statistical thinking is a way of understanding a complex world by describing it in relatively simple terms that nonetheless capture essential aspects of its structure or function, and that also provide us some idea of how uncertain we are about that knowledge.” (Poldrack, Chapter 1)\n\n\n\nbreak down complexity, include uncertainty",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#why-is-statistical-thinking-important",
    "href": "W1_Intro.html#why-is-statistical-thinking-important",
    "title": "01a Introduction to Biostatistics",
    "section": "Why is Statistical Thinking Important?",
    "text": "Why is Statistical Thinking Important?\n\n\ndata literacy vs. intuition/heuristics/anecdotal evidence\n\nPublic discourse about Covid-19, migration, etc. (e.g., “50% of people in intensive care are vaccinated”)\n\n\n\n\n\n\n\n\n\n\n\nBase Rate Fallacy\n\n\n\nexample availability heuristic from book (or any other example where intuition is wrong, i.e. vaccinations/covid…)",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#what-can-statistics-do-for-us",
    "href": "W1_Intro.html#what-can-statistics-do-for-us",
    "title": "01a Introduction to Biostatistics",
    "section": "What can Statistics Do For Us?",
    "text": "What can Statistics Do For Us?\n\nDescribe patterns by summarizing/breaking down data (“descriptive statistics”)\nDecide whether one thing is better than another, given the uncertainty (“inferential statistics”)\nPredict how other people would “behave” (generalize to new observations)\n\n\ndescribe: not useful to look at every single data point/person, but we need s.th. like tendencies/trends…",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#the-big-ideas",
    "href": "W1_Intro.html#the-big-ideas",
    "title": "01a Introduction to Biostatistics",
    "section": "The Big Ideas",
    "text": "The Big Ideas\n\n\nLearning from data: Update our beliefs\nAggregation: How to summarize the data to draw meaningful conclusions?\nUncertainty: Probabilistic evidence\nSampling from the population: Which people etc. do we select?\n\n\n\nask for every point what I could mean w/ it?\nLearning from data: gather new knowledge or even just hypotheses\nAggregation: Can’t look at all ind data points, need to find trends etc. (should not go too far! throwing out data)\nUncertainty: stats = tools for making decisions under uncertainty, we can never prove anything but provide evidence, there is no 100% certainty for an outcome\nsampling: how do we represent the population? What is the population? how much data do we need? More is better, but payoff decreases…",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#causality",
    "href": "W1_Intro.html#causality",
    "title": "01a Introduction to Biostatistics",
    "section": "Causality",
    "text": "Causality\nCorrelation does not imply causation… but is a hint!\n\nExample: Smoking = less risk for Parkinson’s disease? (Godwin-Austen et al., 1982; Chen et al., 2010)\n\n\n→ confounding factors?\n\n\ne.g., individual dopaminergic activity ⇒ addiction & motor function\n\n\nRandomized Controlled Trials (RCT) as the solution?\n\nRCT: exp control and manipulation, removes confounds if done well\nAt least some more causal evidence!\nQUESTIONS so far?",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#what-are-data",
    "href": "W1_Intro.html#what-are-data",
    "title": "01a Introduction to Biostatistics",
    "section": "What are Data?",
    "text": "What are Data?\n\nWhat do you think are data?\n\n\n\nqualitative vs. quantitative\n\nqualitative?\n\nopen questions, descriptions… can potentially be coded into categories\n\nquantitative?\n\nnumeric, can be averaged etc.\n\n\n\n\n\nChat → after showing slide! Come up with examples for “Data”\nCollect: Do you have ideas? What are data you encounter in your lives/work etc? What are differences between these data?",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#what-are-data-2",
    "href": "W1_Intro.html#what-are-data-2",
    "title": "01a Introduction to Biostatistics",
    "section": "What are Data? (2)",
    "text": "What are Data? (2)\n\n\nData types\n\ncharacter/string: text (qualitative)\nfactors/categories\ntypes of numbers (quantitative)\n\nbinary: 0 or 1, TRUE or FALSE (logical)\nintegers: whole numbers\nreal numbers: decimals/fractions\n\n\ndiscrete vs. continuous\n\ndiscrete: finite set of particular values (0 or 1, scale from 1 to 10)\ncontinuous: real numbers that fall into particular range (e.g., brain activity, visual analoge scale)\n\nWhat data type is eye color?\n\n\n\neye color can be categorical (e.g., “brown”, “blue”, “green”) or numerical (wave length in nm)",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#what-is-a-data-set",
    "href": "W1_Intro.html#what-is-a-data-set",
    "title": "01a Introduction to Biostatistics",
    "section": "What is a Data Set?",
    "text": "What is a Data Set?\n\na collection of data\nusually organized into rows and columns (like an excel spreadsheet)\n\nrows: participants/animals/cells…\ncolumns: variables!\n\neach variable contains one type of measurement\n\ntable cells = unique observations of variables per participant etc.\n\n\n\nNHANES dataset\npossibly go through columns and ask for data types?",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#what-makes-a-good-measurement",
    "href": "W1_Intro.html#what-makes-a-good-measurement",
    "title": "01a Introduction to Biostatistics",
    "section": "What Makes a Good Measurement?",
    "text": "What Makes a Good Measurement?\n\n\n\nWhat is being measured?\n\nconstructs vs. proxies: need to be well-defined! (Difficult)\nmeasurement error\n\nrandom: e.g., variation in reaction times of same participant across trials\nsystematic: e.g., miscalibrated eye-tracking device\n\n\nDo we have a “gold standard” to compare the measurement to?\n\n\n\nBreak-Out session: Brainstorm what makes a good vs. bad measurement!\nGroup work/brainstorm:\n\nWhat are problems?\nWhich kind of errors/when is data NOT good\nhow can we minimize error?",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#reliability",
    "href": "W1_Intro.html#reliability",
    "title": "01a Introduction to Biostatistics",
    "section": "Reliability",
    "text": "Reliability\nCorrelation of a measurement with “itself”\n\n\nInternal reliability (consistency)\nTest-retest reliability (stability)\nInter-rater reliability (agreement)\n\n\n\nCorrelation with other variables can’t be higher than reliability (cf., Wilmer et al., 2012, Table 1)!",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#validity",
    "href": "W1_Intro.html#validity",
    "title": "01a Introduction to Biostatistics",
    "section": "Validity",
    "text": "Validity\nAre we measuring the construct we’re interested in?\n\n\nFace validity: Does it intuitively make sense? First reality check!\nConstruct validity\n\nconvergent validity: Related to similar measures that should measure the same construct\ndivergent validity: Is it unrelated to other measures?\n\nPredictive validity: Is it predictive of other outcomes? (e.g., intelligence & job success)",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#validity-reliability",
    "href": "W1_Intro.html#validity-reliability",
    "title": "01a Introduction to Biostatistics",
    "section": "Validity & Reliability",
    "text": "Validity & Reliability\n\nReliability & Validity",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1_Intro.html#summarizing-data",
    "href": "W1_Intro.html#summarizing-data",
    "title": "01a Introduction to Biostatistics",
    "section": "Summarizing Data",
    "text": "Summarizing Data\n\n\nThrowing away (some of the) information!\n\nextract the quintessence of the data (important for forming models)\nmake predictions\n\nCounts, frequencies, percentages, averages",
    "crumbs": [
      "01a Introduction to Biostatistics"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#general-working-with-r-in-this-course",
    "href": "W1b_IntroR.html#general-working-with-r-in-this-course",
    "title": "01b Intro to R",
    "section": "General: Working with R in this course",
    "text": "General: Working with R in this course\nDuring Class\n\nYou should have RStudio open and your Biostats project loaded (we will set up the project today).\nHave the slides open in the background. You will need them to copy R code (top right button on any code chunk) or click on links.\n\n\nprint(\"Hello World\")\n\n[1] \"Hello World\"\n\n\n\nRemember: You can navigate through the slides quickly by clicking on the three dashes in the bottom left.\n\n\n\nAt Home\nIf possible, use two screens with the slides (Zoom) opened on one and RStudio on the other",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#why-write-code",
    "href": "W1b_IntroR.html#why-write-code",
    "title": "01b Intro to R",
    "section": "Why write code?",
    "text": "Why write code?\n\n\nDoing statistical calculation by hand? Tedious & error prone! Computer is faster…\nUsing spreadsheets? Limited options, change data accidentally…\nUsing point-and-click software (e.g., SPSS)?\n\nproprietary software = expensive\nR = open, extensible (community)\nreproducible!\n\nScience/Academia is a marathon and not a sprint\n⇒ it is worthwhile investing in skills with a slow learning curve that will pay off in the long run\n\n\n\nChat: What are advantages (or disadvantages!) of coding?",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#why-write-code-1",
    "href": "W1b_IntroR.html#why-write-code-1",
    "title": "01b Intro to R",
    "section": "Why write code?",
    "text": "Why write code?",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#managing-expectations",
    "href": "W1b_IntroR.html#managing-expectations",
    "title": "01b Intro to R",
    "section": "Managing Expectations",
    "text": "Managing Expectations\n\nYou will learn a new (programming) language. Don’t expect to “speak” it fluently right away.\nDuring class, it is more important that you can roughly comprehend written code and “translate” it into natural language.\nThe second step is to be able to make small adjustments to code that is given to you.\nOnly then, the last step is to be able to produce code yourself (with the help of Google, Stackoverflow, templates of this course, etc. :) ).\nBut: Use it or loose it! Don’t wait to use R in your research projects until you’re “good enough”. It’s more fun to use it on “actual” problems, and makes it much easier to learn.",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#install-r-rstudio",
    "href": "W1b_IntroR.html#install-r-rstudio",
    "title": "01b Intro to R",
    "section": "Install R & RStudio",
    "text": "Install R & RStudio\nYou should all have installed R & RStudio by now! Who had problems doing so?",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#overview-rstudio",
    "href": "W1b_IntroR.html#overview-rstudio",
    "title": "01b Intro to R",
    "section": "Overview RStudio",
    "text": "Overview RStudio\n\nRStudio Interface\nopen R!",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#rstudio-panes",
    "href": "W1b_IntroR.html#rstudio-panes",
    "title": "01b Intro to R",
    "section": "RStudio Panes",
    "text": "RStudio Panes\n\n\n\nScript pane: view, edit, & save your code\nConsole: here the commands are run and rudimentary output may be provided\nEnvironment: which variables/data are available\nFiles, plots, help etc.\n\n\n\n\n\n\n\nRStudio Interface\n\n\n\n\n\nConsole vs. Script (Rmarkdown later)",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#using-the-console-as-a-calculator",
    "href": "W1b_IntroR.html#using-the-console-as-a-calculator",
    "title": "01b Intro to R",
    "section": "Using the Console as a Calculator",
    "text": "Using the Console as a Calculator\n\n100 + 1\n\n[1] 101\n\n2*3\n\n[1] 6\n\nsqrt(9)\n\n[1] 3\n\n\n\nConsole used as calculator\ntry it out!\nWe can’t really do much with these values, they will just be written in the console.\nAlso: Notice that you have the option to include spaces are not between commands, i.e., 100 + 1 vs. 100+1.",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#saving-the-results-as-a-variableobject",
    "href": "W1b_IntroR.html#saving-the-results-as-a-variableobject",
    "title": "01b Intro to R",
    "section": "Saving the Results as a Variable/Object",
    "text": "Saving the Results as a Variable/Object\n\na &lt;- 100 + 1\n\nmulti &lt;- 2*3\n\nSqrtOfNine &lt;- sqrt(9)\n\nword &lt;- \"Hello\"\n\n\n\n\n&lt;- is used to assign values to variables (= is also possible, but discouraged in R)\na, multi etc. are the variable names (some naming rules, e.g., no whitespace, must not start with a number, many special characters not allowed)\n\nYou can find those now in your Environment! (top right panel)\nNo feedback in the console for saving variables (2*3 outputs 6, but multi &lt;- 2*3 doesn’t)\n\nvariables can contain basically anything (words, numbers, entire tables of data …)\nthe variables contain the calculated value (i.e. 101) and not the calculation/formula (100+1)\n\n\n\nType first command in console, what happens?\nWhy don’t we see anything in the console?\nWhat happens if we type in a in the console?\nIs there anything else that you find interesting?\nWhat is sqrt()?",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#working-with-variables",
    "href": "W1b_IntroR.html#working-with-variables",
    "title": "01b Intro to R",
    "section": "Working with variables",
    "text": "Working with variables\n\na + multi\n\n[1] 107\n\na\n\n[1] 101\n\nmulti\n\n[1] 6\n\n\n\n\n\nYou can use those variables for further calculations, e.g., a + multi\nNote that neither a nor multi change their value.",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#working-with-variables-1",
    "href": "W1b_IntroR.html#working-with-variables-1",
    "title": "01b Intro to R",
    "section": "Working with variables",
    "text": "Working with variables\n\na\n\n[1] 101\n\na &lt;- 42\n\na\n\n[1] 42\n\n\n\n\nVariables can be overwritten (R won’t warn you about this!)",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#functions",
    "href": "W1b_IntroR.html#functions",
    "title": "01b Intro to R",
    "section": "Functions",
    "text": "Functions\nThis code with sqrt(9) looked unfamiliar. sqrt() is an R function that calculates the square root of a number. 9 is the argument that we hand over to the function.\nIf you want to know what a function does, which arguments it takes, or which output it generates, you can type into the console: ?functionname\n\n\n?sqrt\n\nThis will open the help file in the Help Pane on the lower right of RStudio.\nYou can also click on a function in the script or console pane and press the F1 key.\n\nSometimes, the help page can be a bit overwhelming (lots of technical details etc.). It might help you to scroll down to the examples at the bottom to see the function in action!\n\nDo this now! Anything unclear?",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#functions-1",
    "href": "W1b_IntroR.html#functions-1",
    "title": "01b Intro to R",
    "section": "Functions",
    "text": "Functions\nFunctions often take more than one argument (which have names):\n\n\nrnorm(n = 6, mean = 3, sd = 1)\nrnorm(6, 3, 1) # this outputs the same as above\n\n\nYou can explicitly name your arguments (check the help file for the argument names!) or just state the values (but these have to be in the correct order then! See help file).\n\n\n\n\n\nrnorm(n = 6, mean = 3, sd = 1)\n\nrnorm(6, 3, 1) # this outputs the same as above\nrnorm(sd = 1, n = 6, mean = 3) # still the same result\nrnorm(1, 6, 3) # different result - R thinks n = 1 and mean = 6!",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#comments",
    "href": "W1b_IntroR.html#comments",
    "title": "01b Intro to R",
    "section": "Comments",
    "text": "Comments\n\nrnorm(n = 6, mean = 3, sd = 1)\nrnorm(6, 3, 1) # this outputs the same as above\n\n# By the way, # denotes a comment - very important for documentation!\n# Anything after # will be ignored by R\n# To (un)comment the line you are in/multiple lines you selected: ctrl + shift + C",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#packages",
    "href": "W1b_IntroR.html#packages",
    "title": "01b Intro to R",
    "section": "Packages",
    "text": "Packages\nThere are a number of functions already included with Base R (i.e., R after a new installation), but you can greatly extend the power of R by loading packages (and we will!). Packages can e.g. contain collections of functions someone else wrote, or even data.\nYou should already have the tidyverse installed (if not, quickly run install.packages(\"tidyverse\") :-) )\n\n\n\nBut installing is not enough to be able to actually use the functions from that package directly. Usually, you also want to load the package with the library() function. This is the first thing you do at the top of an R script:\n\nlibrary(\"tidyverse\") # or library(tidyverse)\n\n\n\n\n\n(If you don’t load a package, you have to call functions explicitly by packagename::function)\n\nOpen Source! Anyone can write a package!\nBase R = mobile phone, comes with some functions, packages = apps\npossibly necessary to install Rtools!",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#new-project",
    "href": "W1b_IntroR.html#new-project",
    "title": "01b Intro to R",
    "section": "New Project",
    "text": "New Project\n\n\n\nCreate a new project by clicking on “File” on the top left and then “New Project…”\nSelect “New Directory” (if you already have a folder for this course, you can choose “Existing directory” and select that folder) and then choose “New Project” at the top of the list.\nChoose a project name, e.g., as “Biostats” (this will create a folder in which the project lives)\nBrowse where you want to put your project folder (e.g., “D:/Documents/Studies/Translational Neuroscience/”)\n\n\n\nPS: R can deal with folder and file names that contain spaces, but since some programms can’t, it’s best practice not to use whitespaces for file/folder naming.",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#existing-projects",
    "href": "W1b_IntroR.html#existing-projects",
    "title": "01b Intro to R",
    "section": "Existing Projects",
    "text": "Existing Projects\nYou will find the current project on the top right corner of RStudio\nIf you click on the current project, you can open new projects by choosing “Open Project” and select the .Rproj file of the project.\nYou can also just double click on .Rproj files and RStudio will open with the project loaded.\n\nExisting projects",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#why-projects",
    "href": "W1b_IntroR.html#why-projects",
    "title": "01b Intro to R",
    "section": "Why Projects",
    "text": "Why Projects\n\nProjects are not only convenient for us (e.g., scripts that we had opened before are re-opened when we open the project), they are also great for reproducibility.\nWe won’t cover the details here - see the “Further Reading” section of the course page!",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#using-scripts",
    "href": "W1b_IntroR.html#using-scripts",
    "title": "01b Intro to R",
    "section": "Using Scripts",
    "text": "Using Scripts\nTo open a new script, click File \\(\\to\\) New File \\(\\to\\) R Script. (Ctrl + Shift + N)\nTo run a line of the script, you can either click Run at the top right of the pane or Ctrl + Enter. It will run the code that is highlighted/selected or automatically select the current line (or the complete multi-line command).\nTo run the whole script/chunk, press Ctrl + Shift + Enter (with full console output) or Ctrl + Shift + S (limited output).\n\n\nUsing scripts",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#working-with-vectors",
    "href": "W1b_IntroR.html#working-with-vectors",
    "title": "01b Intro to R",
    "section": "Working with vectors",
    "text": "Working with vectors\n\nOf course, vectors can be stored in variables.\n\n\n\nmy_vector &lt;- c(1, 2, 10)\n\nshopping_list &lt;- c(\"flour\", \"eggs\", \"apples\")",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#vector-operations",
    "href": "W1b_IntroR.html#vector-operations",
    "title": "01b Intro to R",
    "section": "Vector operations",
    "text": "Vector operations\n\nBut the real fun is that R is “vectorized”, which allows us to do some funny tricks.\nNote that this is different from usual “vector math”.\n\n\n\nc(1, 2, 5) + 1\n\n[1] 2 3 6\n\nc(2, 4, 6) + c(1, 0, 2)\n\n[1] 3 4 8\n\n# Can you spot what happens HERE?!\nc(2, 4, 6, 5, 0, 0) + c(1, 10)\n\n[1]  3 14  7 15  1 10",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#get-the-data",
    "href": "W1b_IntroR.html#get-the-data",
    "title": "01b Intro to R",
    "section": "Get the data",
    "text": "Get the data\nTo read in data files, you need to know which format these files have, e.g. .txt. or .csv files or some other (proprietary) format. There are packages that enable you to read in data of different formats like Excel (.xlsx).\nWe will use the files from Fundamentals of Quantitative Analysis: ahi-cesd.csv and participant-info.csv. Save these directly in your project folder on your computer (do not open them!).\n\n\n\nDid you find the files? Here are the direct links:\n\nhttps://psyteachr.github.io/quant-fun-v2/ahi-cesd.csv\nhttps://psyteachr.github.io/quant-fun-v2/participant-info.csv",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#read-in-the-data",
    "href": "W1b_IntroR.html#read-in-the-data",
    "title": "01b Intro to R",
    "section": "Read in the data",
    "text": "Read in the data\nCreate a new script with the following content:\n\nlibrary(tidyverse) # we will use a function from the tidyverse to read in the data\n\ndat &lt;- read_csv(\"ahi-cesd.csv\")\npinfo &lt;- read_csv(\"participant-info.csv\")\n\nRun the code!",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#looking-at-the-data",
    "href": "W1b_IntroR.html#looking-at-the-data",
    "title": "01b Intro to R",
    "section": "Looking at the Data",
    "text": "Looking at the Data\n\nThere are several options to get a glimpse at the data:\n\nClick on dat and pinfo in your Environment.\nType View(dat) into the console or into the script pane and run it.\nRun str(dat) or str(pinfo) to get an overview of the data.\nRun summary(dat).\nRun head(dat), print(dat), or even just dat.\nWhat is the difference between these commands?",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W1b_IntroR.html#looking-at-the-data-2",
    "href": "W1b_IntroR.html#looking-at-the-data-2",
    "title": "01b Intro to R",
    "section": "Looking at the Data 2",
    "text": "Looking at the Data 2\nWhat is the difference to the objects/variables, that you assigned/saved in your Environment earlier and these objects?\n\nRStudio’s Environment panel\nThe two objects we just read in are data frames, which are “tables” of data (they can contain entire data sets). The objects we assigned earlier were simpler (single values, or “one-dimensional” vectors).\nData frames usually have several rows and columns. The columns are the variables and the rows are the observations (more about that later).",
    "crumbs": [
      "01b Intro to R"
    ]
  },
  {
    "objectID": "W2_Models.html#why-do-we-need-models",
    "href": "W2_Models.html#why-do-we-need-models",
    "title": "02 Models",
    "section": "Why do we need Models?",
    "text": "Why do we need Models?\nWhat can we do with data only? Where can a model be helpful?\n\nsummarize/simplify, generalize, explain",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#what-is-a-model",
    "href": "W2_Models.html#what-is-a-model",
    "title": "02 Models",
    "section": "What is a Model?",
    "text": "What is a Model?\n\n“models” are generally simplifications of things in the real world that nonetheless convey the essence of the thing being modeled\nAll models are wrong but some are useful (George Box)\n\n(ST21, Ch 5)\nAim: Find the model that efficiently and accurately summarizes the data.",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#a-simple-model",
    "href": "W2_Models.html#a-simple-model",
    "title": "02 Models",
    "section": "A Simple Model",
    "text": "A Simple Model\nLet’s say we want to have a model of height of students in this Biostatistics class (or height of children based on the NHANES dataset, as used in ST21, see below).\nWhat do you think would be a good model for the height of a student/child?\n(Or: Which value should we guess for a particular or new student/child?)\n\n\n\n\n\n\n\n\n\n\n\nHave them guess the height of an anonymous new student, discuss what could be relevant information. Gender = not known (prior knowledge!).\nMean = model?",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#basic-structure-of-statistical-models",
    "href": "W2_Models.html#basic-structure-of-statistical-models",
    "title": "02 Models",
    "section": "Basic structure of statistical models",
    "text": "Basic structure of statistical models\n\\[\ndata=model+error\n\\]\n\na statistical model is generally much simpler than the data being described; it is meant to capture the structure of the data as simply as possible.\nTwo parts:\n\none portion that is described by a statistical model, which expresses the values that we expect the data to take given our knowledge,\nerror that reflects the difference between the model’s predictions and the observed data.\n\nExample? (Average) age in classroom? All prior knowledge goes into model\n\n\nIn general, we want to predict single observations (denoted by i) from the model. The fact that we are looking at predictions and not at actual values of the data/observations is denoted by the “hat”:\n\\[ \\widehat{data_i} = model_i \\] The error is then simply the deviation of the actual data from the predicted values:\n\\[  error_i = data_i - \\widehat{data_i} \\]\nThis means that the predicted value of the data for observation i is equal to the value of the model for that observation.",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#a-simple-model-2",
    "href": "W2_Models.html#a-simple-model-2",
    "title": "02 Models",
    "section": "A Simple Model 2",
    "text": "A Simple Model 2\nThe simplest model would be to predict the mean of the height values for every student/child! This would imply that individual deviations of the mean would be interpreted to be (prediction) errors in such a model.\nWe can write such a simple model as a formula:\n\\[\ny_i = \\beta + \\epsilon\n\\]\n\\(y_i\\) denotes the individual observations (hence the \\(i\\)) of heights, \\(\\beta\\) is a so-called parameter, and \\(\\epsilon\\) is the error term. In this example, the parameter \\(\\beta\\) would be the same value (= the mean height) for everyone (hence it doesn’t need an \\(i\\) subscript). Parameters are values that we optimize to find the best model.\n\nWhat would be Yi, beta and error for the height example?",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#a-simple-model-3",
    "href": "W2_Models.html#a-simple-model-3",
    "title": "02 Models",
    "section": "A Simple Model 3",
    "text": "A Simple Model 3\nHow do we find parameters that belong to the best fitting model?\nHow did you come up with model for heights, e.g. the mean?\n\nWe try to minimize the error!\nRemember, the error is the difference between the actual and predicted values of \\(y\\) (height):\n\\[\nerror_i = y_i - \\hat{y_i}\n\\]\nIf we select a predicted value (or mean) of 400cm, all individuals’ errors would hugely deviate (because no one is 4m tall). If we average these errors, it would still be a big value.\nA better candidate for such a simple model is thus the arithmetic mean or average:\n\\[\n\\bar{X} = \\frac{\\sum_{i=1}^{n}x_i}{n}\n\\]\nSumming up all individual’s heights and dividing that number by the number of individuals gives us the mean. By definition, the average (directed) error is now 0 (see book for proof, the individual errors cancel out)! This means that the average has no bias to over- or underestimate observations (while 4m would have been a clear overestimation).",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#a-note-on-errors",
    "href": "W2_Models.html#a-note-on-errors",
    "title": "02 Models",
    "section": "A Note on Errors",
    "text": "A Note on Errors\nWe usually don’t simply average across the individual (signed) errors, but across the squared errors.\nThe reason is that we do not want positive and negative errors to cancel each other out.\nThe mean squared error would be in a different unit than the data (e.g., cm2), which is why we usually take the square root of that value to bring it back to the original unit: This leaves us with the root mean squared error (RMSE)!\nNote: We could also use the absolute values of errors, sum those up, and avoid any of these problems. For historical reasons, we do not.",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#a-slightly-more-complex-model",
    "href": "W2_Models.html#a-slightly-more-complex-model",
    "title": "02 Models",
    "section": "A Slightly More Complex Model",
    "text": "A Slightly More Complex Model\nObviously, the model for predicting height from the average is not very good (RMSE = 27 cm). How can we improve this model?\n\nWe can account for other information that we might have!\nFor example, to account for age might be a good idea: Older children are likely taller than younger ones. We plot height against age to visually inspect the relationship:\n\n\n\n\n\n\n\n\n\n\n\n\nRMSE: On average, 27 cm “wrong” per individual!\nA: raw data, visible strong relationship\nB: only age (linear relationship)\nC: intercept/constant\nD: also account for gender\n–&gt; line fits data increasingly better!",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#a-slightly-more-complex-model-2",
    "href": "W2_Models.html#a-slightly-more-complex-model-2",
    "title": "02 Models",
    "section": "A Slightly More Complex Model 2",
    "text": "A Slightly More Complex Model 2\nAs we can see, the line (~ model) fits the data points increasingly well, e.g. if we include a constant (also called “intercept”) and age. We would write this as this formula:\n\\[\n\\hat{y_i} = \\hat{\\beta_0} + \\hat{\\beta_1} * age_i\n\\]\nRemember from linear algebra that this defines a line:\n\\[\ny = intercept + slope * x\n\\]\nThus \\(\\beta_0\\) is the parameter for the intercept and \\(\\beta_1\\) for the slope of age!\nThe model fit is now much better: RMSE = 8.36 cm.\n\nAdding gender? Does not improve model too much! (compared to age)\n\nw/o intercept: A, no \\(\\beta_0\\)\nStats Software will estimate best values for \\(\\beta\\)’s",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#what-is-a-good-model",
    "href": "W2_Models.html#what-is-a-good-model",
    "title": "02 Models",
    "section": "What is a “Good” Model?",
    "text": "What is a “Good” Model?\nTwo aims:\n\nDescribe data well (= low error/RMSE)\nGeneralize to new data (low error when applied to new data)\n\nCan be conflicting!\n\nWhere does error come from?\nAny ideas? Where could the error come from in your height model?\n\n\n\n\nmeasurement error (noise): random variation in data\n\ndependent variable is hard to measure precisely (difficult/noisy conditions)\ncheap/inadequate equipment for measuring\n\nwrong model specification\n\nimportant variable is missing from model (age!)\ne.g., height has a quadratic relationship with age (old people shrink again)",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#examples-measurement-error",
    "href": "W2_Models.html#examples-measurement-error",
    "title": "02 Models",
    "section": "Examples Measurement Error",
    "text": "Examples Measurement Error\n\nSimulated relationship between blood alcohol content and reaction time on a driving test, with best-fitting linear model represented by the line. A: linear relationship with low measurement error. B: linear relationship with higher measurement error. C: Nonlinear relationship with low measurement error and (incorrect) linear model\nA: very little error, all points close to fitted line\nB: same relationship much more variability across individuals\nC. wrongly specified model (caffeine!), not a linear relationship. Error high (deviations points - line)",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#can-a-model-be-too-good",
    "href": "W2_Models.html#can-a-model-be-too-good",
    "title": "02 Models",
    "section": "Can a Model be “too Good”?",
    "text": "Can a Model be “too Good”?\nYes! This is called overfitting.\n\nIf we fit a line too closely to the data (e.g., with an 8th degree polynomial), the model might not be able to generalize to other data well.\n\n\n\n\n\nAn example of overfitting. Both datasets were generated using the same model, with different random noise added to generate each set. The left panel shows the data used to fit the model, with a simple linear fit in blue and a complex (8th order polynomial) fit in red. The root mean square error (RMSE) values for each model are shown in the figure; in this case, the complex model has a lower RMSE than the simple model. The right panel shows the second dataset, with the same model overlaid on it and the RMSE values computed using the model obtained from the first dataset. Here we see that the simpler model actually fits the new dataset better than the more complex model, which was overfitted to the first dataset.\n\n\n\n\n\n\nHow would overfitting look like in your height examples?\n\nsame formula, different noise (simulation) ~ different individuals\nsimpler model fits new data better!\noverfitting in height examples?",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#central-tendency",
    "href": "W2_Models.html#central-tendency",
    "title": "02 Models",
    "section": "Central Tendency",
    "text": "Central Tendency\nWhy summarize data?\n\nA summary is a model & describes the data! E.g., mean = central tendency of the data\n\n\nMean, Median, Mode?\n\n\nMean = “Balance point” of data; minimizes sum of squared error, but highly influenced by outliers!\nMedian = “middle” of ranked data; minimizes sum of absolute error, less influenced by extreme values\nMode = most often occurring value (i.e., absolute peak)\n\n\nExample:\nIf 4 people earn 50,000 Euros per year and 1 person earns 1,000,000:\nMean: 240,000 Euros\nMedian: (Rank order: 10,000; 10,000; 10,000; 10,000; 1,000,000) -&gt; middle value = 10,000 Euros\nMode: 10,000 Euros\n\nexamples\nmean: income –&gt; if one person earns a million and 3 only 10.000 –&gt; mean = 257.500",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#variability",
    "href": "W2_Models.html#variability",
    "title": "02 Models",
    "section": "Variability",
    "text": "Variability\nHow widespread are the data?\n\nVariance and Standard Deviation\nVariance = Mean Squared Error\n\\[\n\\sigma^2 = \\frac{SSE}{N} = \\frac{\\sum_{i=1}^n (x_i - \\mu)^2}{N}\n\\]\n(Note: \\(x_i\\) = value of ind. observation, \\(\\mu\\) = population mean instead of \\(\\hat{X}\\) = sample mean)\n\n\nStandard Deviation ≈ Root Mean Squared Error\n\\[\nSD = \\sigma = \\sqrt{\\sigma^2}\n\\]\n\n\nWe usually don’t know the population mean \\(\\mu\\), that’s why we estimate the sample variance using the sample mean \\(\\hat{X}\\) (both with the “hat”) and the sample size \\(n\\) instead of the population size \\(N\\):\n\\[\n\\hat\\sigma^2 = \\frac{\\sum_{i=1}^n (x_i - \\hat{X})^2}{n-1}\n\\]\nNote: \\(n-1\\) is used to make the estimate more robust/less biased (I cannot give you an intuition why this is better… please trust me!).\n\nRemember plot above: Points either close to line or wide spread\nVariance = sigma^2, deviations of data points from mean (\\(\\mu\\)) squared and summed, divided by number of oberservations\n\\(n-1\\) = Degrees of Freedom, one value is fixed if we know the mean.",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W2_Models.html#comparing-apples-and-oranges-z-scores",
    "href": "W2_Models.html#comparing-apples-and-oranges-z-scores",
    "title": "02 Models",
    "section": "Comparing apples and oranges: Z-Scores",
    "text": "Comparing apples and oranges: Z-Scores\n\\[\nZ_i(x) = \\frac{x_i - \\mu}{\\sigma}\n\\]\n\n\nstandardizes the distribution: How far is any data point from the mean in units of SD?\ndoesn’t change original relationship of data points!\n\nshifts distribution to have a mean = 0 and scales it to have SD = 1.\n\nuseful if we compare (or use in a model) variables on different scales/units!\n\n\n\n\n\n\n\n\nDensity (top) and cumulative distribution (bottom) of a standard normal distribution, with cutoffs at one standard deviation above/below the mean.\n\n\n\n\n\nZ of x\nx_i is single value/data point\nmu, sigma\nz-scores: Now you can compare apples to oranges! Imagine two siblings from different classes battling it out on test results:\n- I got 70 points, you got only 60!\n- My test only had 70 points in total, yours had 85. I got 86% correct, you only 82%!\n- My test was harder! The average result was 60 with a standard deviation of 10, so I am 1 SD above the class average!\n- On my test, an average of 52 was achieved with an SD of 8, so I am also 1 SD above the class average. But people in your class are really stupid so that’s a very low standard to compare yourself.\nNarrator: And this was the end of comparability between apples and oranges :)",
    "crumbs": [
      "02 Models"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#accessing-variablescolumns",
    "href": "W3_DataWranglingR.html#accessing-variablescolumns",
    "title": "03 Data Wrangling",
    "section": "Accessing Variables/Columns",
    "text": "Accessing Variables/Columns\nWhen wrangling your data in R, you often want to access/use different columns, e.g. to calculate new ones. There are a number of ways you can do that:\n\n# create a small data set for this example:\ntestdata &lt;- data.frame(a = c(1, 2, 3),  # c() creates a vector!\n                       b = c(\"a\", \"b\", \"c\"),\n                       c = c(4, 5, 6),\n                       d = c(7, 8, 9),\n                       e = c(10, 11, 12))\n\nprint(testdata)\n\n  a b c d  e\n1 1 a 4 7 10\n2 2 b 5 8 11\n3 3 c 6 9 12\n\nstr(testdata)\n\n'data.frame':   3 obs. of  5 variables:\n $ a: num  1 2 3\n $ b: chr  \"a\" \"b\" \"c\"\n $ c: num  4 5 6\n $ d: num  7 8 9\n $ e: num  10 11 12\n\n\n\ndata.frame() = function to create a data.frame, which is what holds a data set! (tibbles..)\nc() = function to make a vector. A vector is just like one single column of a data frame: It can hold several values, but all of the same type.",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#accessing-variablescolumns-2",
    "href": "W3_DataWranglingR.html#accessing-variablescolumns-2",
    "title": "03 Data Wrangling",
    "section": "Accessing Variables/Columns 2",
    "text": "Accessing Variables/Columns 2\nWhen wrangling your data in R, you often want to access/use different columns, e.g. to calculate new ones. There are a number of ways you can do that:\n\n# in baseR, we access elements of a data.frame with square brackets\ntestdata[1, 2] # get cell that is in first row and second column\n\n[1] \"a\"\n\ntestdata[1:2, 4:5] # use a colon to create ranges of values: first two rows and column numbers 4 and 5\n\n  d  e\n1 7 10\n2 8 11\n\n# we can leave one part empty to select ALL available columns/rows\ntestdata[1:2, ] # first two rows, all columns\n\n  a b c d  e\n1 1 a 4 7 10\n2 2 b 5 8 11\n\ntestdata[, 4:5] # columns number 4 and 5, all rows\n\n  d  e\n1 7 10\n2 8 11\n3 9 12\n\n\n\nsubsetting: rows, columns –&gt; leave empty!\nSelect range!\nUse either name or index of column!",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#accessing-variablescolumns-3",
    "href": "W3_DataWranglingR.html#accessing-variablescolumns-3",
    "title": "03 Data Wrangling",
    "section": "Accessing Variables/Columns 3",
    "text": "Accessing Variables/Columns 3\nWhen wrangling your data in R, you often want to access/use different columns, e.g. to calculate new ones. There are a number of ways you can do that:\n\n# it is usually better to access columns by their column name:\ntestdata[c(\"d\", \"e\")] # columns with names \"d\" and \"e\", all rows\n\n  d  e\n1 7 10\n2 8 11\n3 9 12\n\n# access a column only:\ntestdata[[\"a\"]] # double square brackets to get a vector (not a data.frame)\n\n[1] 1 2 3\n\ntestdata$a # short notation to get column \"a\" as a vector\n\n[1] 1 2 3\n\n\n\nbetter avoid the comma when accessing by column name:\n\n\n  a b\n1 1 a\n2 2 b\n3 3 c\n\n\n[1] 1 2 3\n\n\n  a b\n1 1 a\n2 2 b\n3 3 c\n\n\n  a\n1 1\n2 2\n3 3\n\n\n[1] 1 2 3\n\n\n=&gt; consistent data format without leading comma",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#accessing-variablescolumns-4",
    "href": "W3_DataWranglingR.html#accessing-variablescolumns-4",
    "title": "03 Data Wrangling",
    "section": "Accessing Variables/Columns 4",
    "text": "Accessing Variables/Columns 4\nWhen wrangling your data in R, you often want to access/use different columns, e.g. to calculate new ones. There are a number of ways you can do that:\n\n# tidy versions (see next slides)\nlibrary(tidyverse) # load tidyverse (if not already done)\npull(testdata, a) # same as testdata$a but can be used better in pipes (see next slide)\n\n[1] 1 2 3\n\nselect(testdata, a, b) # get column(s) as a data.frame; no c() needed!\n\n  a b\n1 1 a\n2 2 b\n3 3 c",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#tidyverse-2",
    "href": "W3_DataWranglingR.html#tidyverse-2",
    "title": "03 Data Wrangling",
    "section": "Tidyverse 2",
    "text": "Tidyverse 2\nBase R:\noutput_data1 &lt;- function1(data)\noutput_data2 &lt;- function2(output_data1, param1)\noutput_data3 &lt;- function3(output_data2, param2, param3)\n\nOr:\noutput_data &lt;- function3(function2(function1(data), param1), param2, param3)\n\n\nTidyverse:\noutput_data &lt;- data %&gt;% function1() %&gt;% function2(param1) %&gt;% function3(param2, param3)\n\n\nYou can insert a pipe %&gt;% (including spaces) by pressing Ctrl + Shift + M\n\n\nThe shortcut for the pipe (and other useful things like the assignment operator) can be adjusted in Tools -&gt; Modify Keyboard Shortcuts...\n\n\n\n%&gt;% is called the pipe. It takes the output of whatever happens to its left and “hands it over” to the right.\nSince R 4.1.0, there’s also a new base-R-pipe: |&gt;. It is very similar, but has a slightly limited functionality (see here).",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#tidyverse-3",
    "href": "W3_DataWranglingR.html#tidyverse-3",
    "title": "03 Data Wrangling",
    "section": "Tidyverse 3",
    "text": "Tidyverse 3\nlibrary(tidyverse) will load a number of packages, such as dplyr, ggplot2, readr, forcats, tibble etc., which are all usefuls for data wrangling.\nWe will work mainly with functions from the dplyr package, but also use readr to read in data. We will also use ggplot2 to visualize data.\nThe most important dplyr functions for data wrangling are:\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nselect()\nInclude or exclude certain columns (variables)\n\n\nfilter()\nInclude or exclude certain rows (observations)\n\n\nmutate()\nCreate new columns (variables)\n\n\nsummarize()\nCreate new columns that aggregate data/create summary variables for groups of observations (data frame will become smaller)\n\n\ngroup_by()\nOrganize the rows (observations) into groups\n\n\narrange()\nChange the order of rows (observations)\n\n\n\n\nfunction names very self-explanatory!\nWe don’t create new observations in R - this is job of the data acquisition - we just read the existing data",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#setting-up-libraries",
    "href": "W3_DataWranglingR.html#setting-up-libraries",
    "title": "03 Data Wrangling",
    "section": "Setting up libraries",
    "text": "Setting up libraries\n\nOpen your Biostats R project.\nCreate a new R script and save it, e.g. as “DataWrangling1.R”.\nInsert code to make sure the packages “tidyverse” and “babynames” are installed and loaded.\n\n\n\n# install.packages(\"tidyverse\")\n# install.packages(\"babynames\")\n\nlibrary(babynames)\nlibrary(tidyverse)\n\n\nload tidyverse last, otherwise functions with same name will be masked from package that is loaded first. Since we often need tidyverse functions, it’s safest to load it last!",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#look-at-the-data",
    "href": "W3_DataWranglingR.html#look-at-the-data",
    "title": "03 Data Wrangling",
    "section": "Look at the Data",
    "text": "Look at the Data\n\n\nType the word babynames into your console pane and press enter. What kind of information do you get?\n\n“A tibble: 1,924,665 x 5”\n\ntibble is an extension of the data.frame with more convenient output (e.g., values rounded to significant digits)\n~1.9 million rows/observations\n5 columns/variables\n\n\nWhat kind of columns/variables do we have?\n\ndbl = double/numeric (can take decimals)\nchr = character/string (letters or words)\nint = integer (only whole numbers)\n\n\n\n\nask first for 1 and 2",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#selecting-variables-of-interest",
    "href": "W3_DataWranglingR.html#selecting-variables-of-interest",
    "title": "03 Data Wrangling",
    "section": "Selecting Variables of Interest",
    "text": "Selecting Variables of Interest\nUse select() to choose only the columns year, sex, name, and prop and store it as a new tibble called babynames_reduced.\nRemember that you can run ?select in the console if you need help about, e.g., input/arguments to the function.\n\n\n# my favorite:\nbabynames_reduced &lt;- \n  babynames %&gt;% \n  select(year, sex, name, prop)\n\n# or alternatively:\nbabynames_reduced &lt;- \n  babynames %&gt;% \n  select(-n) # remove columns by using -\n\nRemoving columns vs. selecting columns: Results may change if the data get updated!\n\n\nSimilar to optional spaces for better readability, R allows for optional line breakes. You can try out what works best for you or look up some style guides.\n\n\n\nIt is encouraged to use many line breakes for better readability. Check out the Tidyverse Style Guide for suggestions.",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#arranging-data",
    "href": "W3_DataWranglingR.html#arranging-data",
    "title": "03 Data Wrangling",
    "section": "Arranging Data",
    "text": "Arranging Data\nChange the order of the data (oberservations/rows)!\n\n\nUsing arrange(), try sorting the data according to the names column. What happens?\nHow can you sort a column in a descending fashion? Check out the help file (?arrange).\nLet’s sort by year descendingly and within each year, sort names alphabetically.\n\n\n\n\nsort_asc &lt;- babynames %&gt;% arrange(name)\n\nsort_desc &lt;- babynames %&gt;% arrange(desc(year)) \n\nbabynames %&gt;% arrange(desc(year), name) \n\n# A tibble: 1,924,665 × 5\n    year sex   name          n       prop\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;      &lt;dbl&gt;\n 1  2017 M     Aaban        11 0.0000056 \n 2  2017 F     Aabriella     6 0.0000032 \n 3  2017 M     Aadam        18 0.00000917\n 4  2017 M     Aadan         8 0.00000407\n 5  2017 M     Aadarsh      15 0.00000764\n 6  2017 M     Aaden       240 0.000122  \n 7  2017 M     Aadesh        7 0.00000357\n 8  2017 M     Aadhav       31 0.0000158 \n 9  2017 M     Aadhavan      6 0.00000306\n10  2017 M     Aadhi        10 0.00000509\n# ℹ 1,924,655 more rows\n\n\n\nremember to save data in new tibble/data frame!",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#filter-observations",
    "href": "W3_DataWranglingR.html#filter-observations",
    "title": "03 Data Wrangling",
    "section": "Filter Observations",
    "text": "Filter Observations\nWe have already used select() to keep only certain variables (columns), but often we also want to keep only certain observations (rows), e.g. babies born in the year 2000 and later.\nWe use the function filter() for this.\n\nLook at the following code and think about what it might do.\n\nbabynames %&gt;% \n  filter(year &gt; 2000)\n\n\n\n\n\n# A tibble: 562,156 × 5\n    year sex   name          n    prop\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     &lt;int&gt;   &lt;dbl&gt;\n 1  2001 F     Emily     25055 0.0127 \n 2  2001 F     Madison   22164 0.0112 \n 3  2001 F     Hannah    20712 0.0105 \n 4  2001 F     Ashley    16526 0.00835\n 5  2001 F     Alexis    16401 0.00828\n 6  2001 F     Sarah     15896 0.00803\n 7  2001 F     Samantha  15862 0.00801\n 8  2001 F     Abigail   14807 0.00748\n 9  2001 F     Elizabeth 14784 0.00747\n10  2001 F     Olivia    13978 0.00706\n# ℹ 562,146 more rows\n\n\nThe data starts at 2001! :(",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#boolean-expressions",
    "href": "W3_DataWranglingR.html#boolean-expressions",
    "title": "03 Data Wrangling",
    "section": "Boolean Expressions",
    "text": "Boolean Expressions\nThe second argument, year &gt; 2000, is a Boolean or logical expression, which means that it results in a value of either TRUE or FALSE. filter() runs this expression and then removes all values/rows that contain FALSE.",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#boolean-expressions-2",
    "href": "W3_DataWranglingR.html#boolean-expressions-2",
    "title": "03 Data Wrangling",
    "section": "Boolean Expressions 2",
    "text": "Boolean Expressions 2\n\nBoolean expressions\n\n\n\n\n\n\n\nOperator\nName\nis TRUE if and only if\n\n\n\n\nA &lt; B\nless than\nA is less than B\n\n\nA &lt;= B\nless than or equal\nA is less than or equal to B\n\n\nA &gt; B\ngreater than\nA is greater than B\n\n\nA &gt;= B\ngreater than or equal\nA is greater than or equal to B\n\n\nA == B\nequivalence\nA exactly equals B\n\n\nA != B\nnot equal\nA does not exactly equal B\n\n\nA %in% B\nin\nA is an element of vector B\n\n\n\n\n\nA double equality sign == is a comparison, a single equals = is a variable or parameter assignment.\nThis is why R users like to make the distinction even bigger by using &lt;- for variable assignment (your environment in the top right pane) and = for parameter assignment in functions (a hidden so-called local environment only visible to the function).\nAlso, there are slight differences between &lt;- and = for variable assignment, see here.",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#filter-some-more-1",
    "href": "W3_DataWranglingR.html#filter-some-more-1",
    "title": "03 Data Wrangling",
    "section": "Filter some more 1",
    "text": "Filter some more 1\n\nKeep only those observations with the name “Mary”.\nDiscard all observations with name “Mary” and keep only those from year &gt; 2000.\nKeep only those with names of former Queens (Mary, Elizabeth, Victoria).\nDiscard the ones with the Queen names!\n\n\nFirst task:\n\nmarys &lt;- \n  babynames %&gt;% \n  filter(name == \"Mary\")",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#filter-some-more-2",
    "href": "W3_DataWranglingR.html#filter-some-more-2",
    "title": "03 Data Wrangling",
    "section": "Filter some more 2",
    "text": "Filter some more 2\n\nKeep only those observations with the name “Mary”.\nDiscard all observations with name “Mary” and keep only those from year &gt; 2000.\nKeep only those with names of former Queens (Mary, Elizabeth, Victoria).\nDiscard the ones with the Queen names!\n\nSecond task:\nThis might be difficult because you have two expressions, name != \"Mary\" and year &gt; 2000. You can simply add several expressions separated by commas in filter (commas are treated like a “logical and” &):\n\nno_marys_young &lt;- \n  babynames %&gt;% \n  filter(name != \"Mary\", year &gt; 2000)",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#filter-some-more-3",
    "href": "W3_DataWranglingR.html#filter-some-more-3",
    "title": "03 Data Wrangling",
    "section": "Filter some more 3",
    "text": "Filter some more 3\n\nKeep only those observations with the name “Mary”.\nDiscard all observations with name “Mary” and keep only those from year &gt; 2000.\nKeep only those with names of former Queens (Mary, Elizabeth, Victoria).\nDiscard the ones with the Queen names!\n\nThird task:\n\nqueens &lt;- \n  babynames %&gt;% \n  filter(\n    name == \"Mary\" | # the vertical line is a logical OR\n    name == \"Elizabeth\" | \n    name == \"Victoria\"\n  ) \n\n\nA better shorthand exists with the operator %in%:\n\nqueens &lt;- \n  babynames %&gt;% \n  filter(name %in% c(\"Mary\", \"Elizabeth\", \"Victoria\"))",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#filter-some-more-4",
    "href": "W3_DataWranglingR.html#filter-some-more-4",
    "title": "03 Data Wrangling",
    "section": "Filter some more 4",
    "text": "Filter some more 4\n\nKeep only those observations with the name “Mary”.\nDiscard all observations with name “Mary” and keep only those from year &gt; 2000.\nKeep only those with names of former Queens (Mary, Elizabeth, Victoria).\nDiscard the ones with the Queen names!\n\nFourth task:\nThis is very tricky! You could use three filters in a row with:\nname != \"Mary\", name != \"Elizabeth\", name != \"Victoria\".\nThere is no function “not in” but you can negate the result in two ways:\n\nno_queens &lt;- \n  babynames %&gt;% \n  filter(!name %in% c(\"Mary\", \"Elizabeth\", \"Victoria\")) # ! is a negation (\"not\")\n\nno_queens &lt;- \n  babynames %&gt;% \n  filter(name %in% c(\"Mary\", \"Elizabeth\", \"Victoria\") == FALSE)\n\n\nCareful with precedence! %in% is evaluated before !:\n!(name %in% c(\"Mary\", \"Elizabeth\", \"Victoria\"))\n=&gt; I prefer to add == FALSE in the end",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#your-first-plot",
    "href": "W3_DataWranglingR.html#your-first-plot",
    "title": "03 Data Wrangling",
    "section": "Your First Plot",
    "text": "Your First Plot\nIn your script, insert and run the following code:\n\nbabynames %&gt;% \n  filter(\n    sex == \"F\", # only female babies\n    name %in% c(\"Emily\", \"Kathleen\", \"Alexandra\", \"Beverly\") # reduce to these 4 names\n  ) %&gt;% \n  ggplot(aes(x = year, y = prop, colour = name)) +\n  geom_line(linewidth = 2) # plot data as a line (with increased size)\n\n\n\nAlter the code to check for male babies with the same names (change sex == \"F\" to sex == \"M\").\nOptional: Plot the absolute number n instead of the relative proportion prop.",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#create-new-variables",
    "href": "W3_DataWranglingR.html#create-new-variables",
    "title": "03 Data Wrangling",
    "section": "Create New Variables",
    "text": "Create New Variables\nIf we want to create variables that do not exist yet (i.e. by calculating values, combining other variables, etc.), we can use mutate()!\n\nAdd a variable called “country” that contains the value “USA” for all observations\n\n\n\nbaby_where &lt;- \n  babynames %&gt;% \n  mutate(country = \"USA\")\n\n\n\nBut mutate is much more powerful and can create variables that differ per observation, depending on other values in the tibble/data frame:",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#create-new-variables-2",
    "href": "W3_DataWranglingR.html#create-new-variables-2",
    "title": "03 Data Wrangling",
    "section": "Create New Variables 2",
    "text": "Create New Variables 2\n\nCreate a variable that denotes the decade a baby was born:\n\n\n\n# we can only use floor to round down to full numbers =&gt; divide year by 10, floor it, and then multiply by 10 again\nbaby_decades &lt;- \n  babynames %&gt;% \n  mutate(decade = floor(year / 10) * 10) # round(year, -1) works but not floor(year, -1) :(\n\n\n\n# A tibble: 10 × 2\n    year decade\n   &lt;dbl&gt;  &lt;dbl&gt;\n 1  1906   1900\n 2  1911   1910\n 3  1916   1910\n 4  1919   1910\n 5  1927   1920\n 6  1960   1960\n 7  1983   1980\n 8  1989   1980\n 9  2001   2000\n10  2013   2010",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#summarizing",
    "href": "W3_DataWranglingR.html#summarizing",
    "title": "03 Data Wrangling",
    "section": "Summarizing",
    "text": "Summarizing\nThe goal of data wrangling is often to summarize (or aggregate) the data, e.g. to have an average value per condition. Sometimes you’d also want to calculate descriptive statistics to report.\n\nYou can do so using the function summarize():\n\n# run the filter function just like above again:\ndat &lt;- \n  babynames %&gt;% \n  filter(\n    name %in% c(\"Emily\", \"Kathleen\", \"Alexandra\", \"Beverly\"), \n    sex == \"F\"\n  )\n\n# summarize the data, calculating the number of oberservations:\ndat_sum &lt;- dat %&gt;% summarize(total = sum(n))\ndat_sum\n\n# A tibble: 1 × 1\n    total\n    &lt;int&gt;\n1 2161374",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#summarizing-2",
    "href": "W3_DataWranglingR.html#summarizing-2",
    "title": "03 Data Wrangling",
    "section": "Summarizing 2",
    "text": "Summarizing 2\n\ndat_sum\n\n# A tibble: 1 × 1\n    total\n    &lt;int&gt;\n1 2161374\n\n\nAs you can see, a new variable named total is created, which contains the total number of observations (in this case, it is different from the number of rows because each row already contains a count n).\nThere’s just one row in the resulting data frame, because summarize() reduces the data frame (to only include the necessary information)!",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#grouping-and-summarizing",
    "href": "W3_DataWranglingR.html#grouping-and-summarizing",
    "title": "03 Data Wrangling",
    "section": "Grouping and Summarizing",
    "text": "Grouping and Summarizing\nOften, we want to summarize data for specific subgroups. For this aim, summarize() has the .by parameter:\n\ngroup_sum &lt;- \n  dat %&gt;% \n  summarize(total = sum(n), .by = name) \n\ngroup_sum\n\n# A tibble: 4 × 2\n  name       total\n  &lt;chr&gt;      &lt;int&gt;\n1 Emily     841491\n2 Kathleen  711605\n3 Beverly   376914\n4 Alexandra 231364",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#grouping-and-summarizing-2",
    "href": "W3_DataWranglingR.html#grouping-and-summarizing-2",
    "title": "03 Data Wrangling",
    "section": "Grouping and Summarizing 2",
    "text": "Grouping and Summarizing 2\nYou can also subgroup by a combination of variables:\n\nbabynames %&gt;% \n  filter(name %in% c(\"Emily\", \"Kathleen\", \"Alexandra\", \"Beverly\")) %&gt;% # we start with the 4 names regardless of sex\n  summarize(\n    total = sum(n),\n    .by = c(name, sex) # and then summarize by name, separated for sex\n  )\n\n# A tibble: 8 × 3\n  name      sex    total\n  &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;\n1 Emily     F     841491\n2 Kathleen  F     711605\n3 Beverly   M       4633\n4 Beverly   F     376914\n5 Alexandra F     231364\n6 Emily     M       1744\n7 Kathleen  M       1692\n8 Alexandra M        859",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#grouping-and-summarizing-3",
    "href": "W3_DataWranglingR.html#grouping-and-summarizing-3",
    "title": "03 Data Wrangling",
    "section": "Grouping and Summarizing 3",
    "text": "Grouping and Summarizing 3\nIn earlier versions, we had to use summarize() together with group_by():\n\ngroup_sum &lt;- dat %&gt;% group_by(name) %&gt;% summarize(total = sum(n)) \n\nWe avoid using group_by() like this because it can have unintended side effects.\nIt is just part of this class because you will likely encounter it in somebody else’s (old) code.\n\nIf you do have to use it, make sure to ungroup() after summarize() (or mutate()) to avoid unintended effects:\n\ngroup_sum &lt;- dat %&gt;% group_by(name) %&gt;% summarize(total = sum(n)) %&gt;% ungroup()\ngroup_sum &lt;- dat %&gt;% group_by(name) %&gt;% summarize(total = sum(n), .groups = \"drop\")\n\n\nUnintended side effects: grouping stays active and affects future calls to summarize or mutate, which may be hundreds of lines of code away!\n=&gt; Fatal when, e.g., calculating z-scores after having summarized the trial-level data into subject-level averages.",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#grouping-and-summarizing-4",
    "href": "W3_DataWranglingR.html#grouping-and-summarizing-4",
    "title": "03 Data Wrangling",
    "section": "Grouping and Summarizing 4",
    "text": "Grouping and Summarizing 4\nUse the baby_decades data frame to calculate the mean and median number of observations, grouped by sex & decade.\n\n\nbaby_decades %&gt;% \n  summarize(\n    mean_year = mean(n),\n    median_year = median(n),\n    .by = c(sex, decade)\n  )\n\n# A tibble: 28 × 4\n   sex   decade mean_year median_year\n   &lt;chr&gt;  &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n 1 F       1880     111.           13\n 2 M       1880     101.           12\n 3 F       1890     128.           13\n 4 M       1890      93.6          12\n 5 F       1900     131.           12\n 6 M       1900      94.4          12\n 7 F       1910     187.           12\n 8 M       1910     181.           12\n 9 F       1920     211.           12\n10 M       1920     227.           13\n# ℹ 18 more rows",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#counting-data",
    "href": "W3_DataWranglingR.html#counting-data",
    "title": "03 Data Wrangling",
    "section": "Counting Data",
    "text": "Counting Data\nThere are several ways to get the number of rows per group. You can use the function n() within a call to summarize() (or mutate()). A shortcut is to use count():\n\ndat %&gt;% summarize(n = n(), .by = name)\n\n# A tibble: 4 × 2\n  name          n\n  &lt;chr&gt;     &lt;int&gt;\n1 Emily       138\n2 Kathleen    138\n3 Beverly     122\n4 Alexandra   117\n\ndat %&gt;% count(name)\n\n# A tibble: 4 × 2\n  name          n\n  &lt;chr&gt;     &lt;int&gt;\n1 Alexandra   117\n2 Beverly     122\n3 Emily       138\n4 Kathleen    138\n\n\nInterestingly, the order of the output may vary. summarize() leaves the data in the original order (i.e., by prop, which (likely) translates to an order by n()). count() arranges the output by the variables for which the counting is done (here: alphabetically by name).",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#bigger-pipes",
    "href": "W3_DataWranglingR.html#bigger-pipes",
    "title": "03 Data Wrangling",
    "section": "Bigger Pipes!",
    "text": "Bigger Pipes!\nSo far we have often saved intermediate steps in tibbles and used those as input for the next function. With the pipe, we can chain several functions and save relevant results only, no need for crowding the environment with intermediate data.frames or tibbles!\n\npipe_summary &lt;- \n  babynames %&gt;%\n  mutate(decade = floor(year / 10) * 10) %&gt;%\n  filter(\n    name %in% c(\"Emily\", \"Kathleen\", \"Alexandra\", \"Beverly\"),\n    sex == \"F\"\n  ) %&gt;%\n  summarize(\n    mean_decade = mean(n),\n    .by = c(name, decade)\n  )\n\nIt’s not easy to decide which intermediate steps to save and which not. Usually, it involves some sort of trial and error. Sometimes you go back and break a pipe apart. Sometimes you get overwhelmed by the number of variables in your environment and create bigger pipes.\nAs a rule of thumb: If an intermediate step is only used once, you should probably delete it (unless it makes the code easier to comprehend).",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#tidy-data",
    "href": "W3_DataWranglingR.html#tidy-data",
    "title": "03 Data Wrangling",
    "section": "Tidy Data",
    "text": "Tidy Data\nTidy data: Data that is easily processed by tidyverse functions (also for visualizations and statistical analyses).\nThree principles:\n\nEach variable has its own column.\nEach observation has its own row.\nEach value has its own cell.",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#tidy-data-wide-vs.-long-format",
    "href": "W3_DataWranglingR.html#tidy-data-wide-vs.-long-format",
    "title": "03 Data Wrangling",
    "section": "Tidy Data: wide vs. long format",
    "text": "Tidy Data: wide vs. long format\n\n\nWide format: Each participant/animal has one row;\nrepeated observations are in several columns\n\n\n\nID\nTime_1\nTime_2\n\n\n\n\na1\n230\n310\n\n\na2\n195\n220\n\n\na3\n245\n290\n\n\n\n\nLong format: Each observation has its own row;\nthere are (usually) several rows per participant\n\n\n\nID\nTime\nValue\n\n\n\n\na1\n1\n230\n\n\na1\n2\n310\n\n\na2\n1\n195\n\n\na3\n2\n220\n\n\na3\n1\n245\n\n\na3\n2\n290\n\n\n\n\n\n\nWide format implements a sparser representation of the data but less tidy!\nIf you want to convert Time from milliseconds into seconds, what do you have to do in both formats?\n\nData often does not come in this format but is rather messy! That’s why we wrangle.\nTidy data is in between wide and long (you can always go longer! :D)",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#tidy-data-2",
    "href": "W3_DataWranglingR.html#tidy-data-2",
    "title": "03 Data Wrangling",
    "section": "Tidy Data 2",
    "text": "Tidy Data 2\nWhat do you think, which of the following data sets is tidy?\n1:\n\n\n# A tibble: 12 × 4\n   country      year type            count\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;\n 1 Afghanistan  1999 cases             745\n 2 Afghanistan  1999 population   19987071\n 3 Afghanistan  2000 cases            2666\n 4 Afghanistan  2000 population   20595360\n 5 Brazil       1999 cases           37737\n 6 Brazil       1999 population  172006362\n 7 Brazil       2000 cases           80488\n 8 Brazil       2000 population  174504898\n 9 China        1999 cases          212258\n10 China        1999 population 1272915272\n11 China        2000 cases          213766\n12 China        2000 population 1280428583\n\n\n2:\n\n\n# A tibble: 6 × 4\n  country      year  cases population\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;\n1 Afghanistan  1999    745   19987071\n2 Afghanistan  2000   2666   20595360\n3 Brazil       1999  37737  172006362\n4 Brazil       2000  80488  174504898\n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\n\n3:\n\n\n# A tibble: 6 × 3\n  country      year rate             \n  &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;            \n1 Afghanistan  1999 745/19987071     \n2 Afghanistan  2000 2666/20595360    \n3 Brazil       1999 37737/172006362  \n4 Brazil       2000 80488/174504898  \n5 China        1999 212258/1272915272\n6 China        2000 213766/1280428583\n\n\n4:\n\n\n# A tibble: 3 × 5\n  country     `1999_cases` `2000_cases` `1999_population` `2000_population`\n  &lt;chr&gt;              &lt;dbl&gt;        &lt;dbl&gt;             &lt;dbl&gt;             &lt;dbl&gt;\n1 Afghanistan          745         2666          19987071          20595360\n2 Brazil             37737        80488         172006362         174504898\n3 China             212258       213766        1272915272        1280428583\n\n\n\n\nThe second table is the tidyest!\nTable 1 has cases and population mixed together in count variable.\nTable 3 mixes them in an awkward character row rate.\nTable 4 is standard wide format.",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#analyzing-the-autism-spectrum-quotient",
    "href": "W3_DataWranglingR.html#analyzing-the-autism-spectrum-quotient",
    "title": "03 Data Wrangling",
    "section": "Analyzing the Autism Spectrum Quotient",
    "text": "Analyzing the Autism Spectrum Quotient\nFor the following activities, we will need the following files:\n\nresponses.csv containing the AQ survey responses to each of the 10 questions for the 66 participants\nqformats.csv containing information on how a question should be coded - i.e. forward or reverse coding\nscoring.csv containing information on how many points a specific response should get; depending on whether it is forward or reverse coded\npinfo.csv containing participant information such as Age, Sex and importantly ID number.",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#set-up",
    "href": "W3_DataWranglingR.html#set-up",
    "title": "03 Data Wrangling",
    "section": "Set Up",
    "text": "Set Up\n\nCreate a new script, e.g. as “DataWrangling3.R” (remember we skipped #2 in the book).\nDownload the data into your project folder:\nresponses.csv\nqformats.csv\nscoring.csv\npinfo.csv\nClear your environment (the brush in the top right pane) and/or restart the R session (Session -&gt; Restart R).\nLoad the four .csv files into your environment, e.g.:\n\n\nlibrary(tidyverse)\nresponses &lt;- read_csv(\"responses.csv\") \nqformats &lt;- read_csv(\"qformats.csv\")\nscoring &lt;- read_csv(\"scoring.csv\")\npinfo &lt;- read_csv(\"pinfo.csv\")",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#look-at-the-data-1",
    "href": "W3_DataWranglingR.html#look-at-the-data-1",
    "title": "03 Data Wrangling",
    "section": "Look at the Data",
    "text": "Look at the Data\nIs the data (responses) in a tidy format?\n\n\n# A tibble: 6 × 11\n     Id Q1                 Q2    Q3    Q4    Q5    Q6    Q7    Q8    Q9    Q10  \n  &lt;dbl&gt; &lt;chr&gt;              &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1    16 Slightly Disagree  Defi… Slig… Defi… Slig… Slig… Slig… Defi… Slig… Slig…\n2    17 Definitely Agree   Slig… Slig… Defi… Defi… Defi… Slig… Slig… Slig… Slig…\n3    18 Definitely Agree   Defi… Slig… Defi… Defi… Defi… Slig… Defi… Defi… Defi…\n4    19 Definitely Agree   Defi… Defi… Slig… Defi… Defi… Slig… Slig… Defi… Slig…\n5    20 Definitely Disagr… Slig… Defi… Slig… Slig… Slig… Slig… Slig… Slig… Slig…\n6    21 Slightly Disagree  Slig… Defi… Slig… Slig… Slig… Defi… Defi… Slig… Slig…\n\n\n\nWhy is it not tidy?\n\nwide format",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#reformatting-the-data",
    "href": "W3_DataWranglingR.html#reformatting-the-data",
    "title": "03 Data Wrangling",
    "section": "Reformatting the Data",
    "text": "Reformatting the Data\nLet’s bring the wide data in a longer, tidy format!\n\nThere are several functions in R to reformat data, but the newest ones are pivot_longer() and pivot_wider().\nRun the code and see what changes:\n\nrlong &lt;- \n  responses %&gt;% \n  pivot_longer(\n    cols = Q1:Q10, # we can select a range of column names\n    # cols = starts_with(\"Q\"), # alternative\n    names_to = \"Question\", \n    values_to = \"Response\"\n  )\n\n\n\nDescribe what the function does, what does the input/the arguments mean?",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#joining-the-data",
    "href": "W3_DataWranglingR.html#joining-the-data",
    "title": "03 Data Wrangling",
    "section": "Joining the Data",
    "text": "Joining the Data\nWe now want to combine the different data sets: We want to have the information how the questionnaire has to be scored included with the items.\nWe can find the scoring information (i.e. how the questions are framed, positive or negative/whether they need to be reversed) in the qformats tibble. Furthermore, we can find how many points are given to each item/response in scoring.\nWe can use the function inner_join() to merge the tibbles into one bigger tibble.\n\nActivity: Replace the NULL values in the below code with the necessary variable names to join rlong and qformats by Question.\n\nrlong2 &lt;- \n  inner_join(x = NULL, y = NULL, by = \"NULL\")\n\n\n\n\nrlong2 &lt;- \n  inner_join(\n    x = rlong, \n    y = qformats, \n    by = \"Question\"\n  )\n\n\nDescribe what happened?\nwhat is forward and reverse scoring?",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#combining-more-data",
    "href": "W3_DataWranglingR.html#combining-more-data",
    "title": "03 Data Wrangling",
    "section": "Combining more Data",
    "text": "Combining more Data\nYou can only join two data frames/tibbles at once.\nNow add the scoring data:\n\nrscores &lt;- \n  rlong2 %&gt;% \n  inner_join(\n    scoring, \n    c(\"QFormat\", \"Response\")\n  )\n\n\nYou can also let the function figure out by itself which columns should be used for joining:\n\nrscores &lt;- inner_join(rlong2, scoring)\n\nJoining with `by = join_by(Response, QFormat)`\n\n\n\n\nAnd if you are happy with the result, copy the information into your code to make the join explicit:\n\nrscores &lt;- inner_join(rlong2, scoring, \n                      by = join_by(Response, QFormat)) #same as by = c(\"QFormat\", \"Response\")",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#calculate-the-questionnaire-scores",
    "href": "W3_DataWranglingR.html#calculate-the-questionnaire-scores",
    "title": "03 Data Wrangling",
    "section": "Calculate the Questionnaire Scores",
    "text": "Calculate the Questionnaire Scores\nHow do we need to group and summarize the data to get a sum score per person? (Ignoring the reverse coding for now!) Add the correct column names instead of the NULL.\n\naq_scores &lt;- \n  rscores %&gt;% \n  summarize(\n    AQ = sum(NULL), \n    .by = NULL\n  )\n\n\n\naq_scores &lt;- \n  rscores %&gt;% \n  summarize(\n    AQ = sum(Score), # sum column Score to obtain AQ scores.\n    .by = Id # separately for each Id (participant)\n  )",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#pipe-it-all-together",
    "href": "W3_DataWranglingR.html#pipe-it-all-together",
    "title": "03 Data Wrangling",
    "section": "Pipe it all together!",
    "text": "Pipe it all together!\n\naq_scores2 &lt;- \n  responses %&gt;% \n  pivot_longer(\n    cols = Q1:Q10,\n    names_to = \"Question\", \n    values_to = \"Response\"\n  ) %&gt;%  \n  inner_join(qformats, \"Question\") %&gt;% \n  inner_join(scoring, c(\"QFormat\", \"Response\")) %&gt;% \n  summarize(AQ = sum(Score), .by = Id)",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#background",
    "href": "W3_DataWranglingR.html#background",
    "title": "03 Data Wrangling",
    "section": "Background",
    "text": "Background\nWe’ll use data from a paper that investigates whether the ability to perform an action influences perception. In particular, the authors wondered whether participants who played Pong would perceive the ball to move faster when they have a small paddle.\n\n\nDownload the data, create a new script.\nClear the environment if you prefer.\nLook at the data.",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#solutions",
    "href": "W3_DataWranglingR.html#solutions",
    "title": "03 Data Wrangling",
    "section": "Solutions",
    "text": "Solutions\n\nlibrary(\"tidyverse\")\npong_data &lt;- read_csv(\"Data/PongBlueRedBack 1-16 Codebook.csv\") # I put the data into a separate subfolder \"Data\"\nsummary(pong_data)\n\n  Participant     JudgedSpeed      PaddleLength   BallSpeed    TrialNumber    \n Min.   : 1.00   Min.   :0.0000   Min.   : 50   Min.   :2.0   Min.   :  1.00  \n 1st Qu.: 4.75   1st Qu.:0.0000   1st Qu.: 50   1st Qu.:3.0   1st Qu.: 72.75  \n Median : 8.50   Median :1.0000   Median :150   Median :4.5   Median :144.50  \n Mean   : 8.50   Mean   :0.5471   Mean   :150   Mean   :4.5   Mean   :144.50  \n 3rd Qu.:12.25   3rd Qu.:1.0000   3rd Qu.:250   3rd Qu.:6.0   3rd Qu.:216.25  \n Max.   :16.00   Max.   :1.0000   Max.   :250   Max.   :7.0   Max.   :288.00  \n BackgroundColor      HitOrMiss       BlockNumber   \n Length:4608        Min.   :0.0000   Min.   : 1.00  \n Class :character   1st Qu.:0.0000   1st Qu.: 3.75  \n Mode  :character   Median :1.0000   Median : 6.50  \n                    Mean   :0.6866   Mean   : 6.50  \n                    3rd Qu.:1.0000   3rd Qu.: 9.25  \n                    Max.   :1.0000   Max.   :12.00  \n\n# look at the data (can also use summary(), str(), head() etc.)\nglimpse(pong_data)\n\nRows: 4,608\nColumns: 8\n$ Participant     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ JudgedSpeed     &lt;dbl&gt; 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, …\n$ PaddleLength    &lt;dbl&gt; 50, 250, 50, 250, 250, 50, 250, 50, 250, 50, 50, 250, …\n$ BallSpeed       &lt;dbl&gt; 5, 3, 4, 3, 7, 5, 6, 2, 4, 4, 7, 7, 3, 6, 5, 7, 2, 5, …\n$ TrialNumber     &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,…\n$ BackgroundColor &lt;chr&gt; \"red\", \"blue\", \"red\", \"red\", \"blue\", \"blue\", \"red\", \"r…\n$ HitOrMiss       &lt;dbl&gt; 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, …\n$ BlockNumber     &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W3_DataWranglingR.html#solutions-2",
    "href": "W3_DataWranglingR.html#solutions-2",
    "title": "03 Data Wrangling",
    "section": "Solutions 2",
    "text": "Solutions 2\n\nnew_pong_data &lt;- pong_data %&gt;% \n  select(BallSpeed, HitOrMiss, JudgedSpeed, Participant, TrialNumber) %&gt;% \n  arrange(desc(HitOrMiss), desc(JudgedSpeed)) %&gt;% \n  filter(\n    JudgedSpeed == 1,\n    BallSpeed %in% c(\"2\", \"4\", \"5\", \"7\"),\n    HitOrMiss == 0\n  ) %&gt;% \n  filter(TrialNumber &gt; 2) %&gt;% \n  mutate(TrialNumber = TrialNumber -1) \n  \n  # summarize (use old data frame because we removed variables)\npong_data_hits &lt;- \n  pong_data %&gt;% \n  summarize(\n    total_hits = sum(HitOrMiss, na.rm = TRUE),\n    meanhits = mean(HitOrMiss, na.rm = TRUE),\n    .by = c(BackgroundColor, PaddleLength)\n  )",
    "crumbs": [
      "03 Data Wrangling"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#ggplot",
    "href": "W4_DataVizR.html#ggplot",
    "title": "04 Data Visualization",
    "section": "ggplot",
    "text": "ggplot\nWe will use a package called ggplot2 (part of the tidyverse). ggplot2 is a very versatile package that allows us to make beautiful, publication-ready(-ish) figures.\nggplot2 follows the “grammar of graphics” by Leland Wilkinson, a formal guide to visualization principles. A core feature are the layers each plot consists of. The main function to “start” plotting is ggplot() - we will then add layers of data and layers to tweak the appearance.\n\nLayers of a ggplot",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#activity-1-set-up",
    "href": "W4_DataVizR.html#activity-1-set-up",
    "title": "04 Data Visualization",
    "section": "Activity 1: Set Up",
    "text": "Activity 1: Set Up\n\nWithin your biostats project in RStudio, create a new script called DataVisualisation1.R.\nMake sure you have the following two files downloaded into your project folder (we already used them in Intro to R presentation): ahi-cesd.csv and participant-info.csv.\nCopy and run the code below to load the tidyverse package and the data files:\n\n\nlibrary(tidyverse) \n\ndat &lt;- read_csv(\"ahi-cesd.csv\")\npinfo &lt;- read_csv(\"participant-info.csv\")",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#activity-1-set-up-1",
    "href": "W4_DataVizR.html#activity-1-set-up-1",
    "title": "04 Data Visualization",
    "section": "Activity 1: Set Up",
    "text": "Activity 1: Set Up\n\nRun the following code to combine both files and select our variables of interest:\n\n\nall_dat &lt;- \n  dat %&gt;% \n  inner_join(\n    pinfo, # combine dat with pinfo\n    by = c(\"id\", \"intervention\") # common variables that tell R which data belongs together\n  ) %&gt;% \n  arrange(id, occasion) #joining messes up the order of the data frame =&gt; arrange again\n\n# we throw out several variables even though they would be important for a comprehensive data analysis\nsummarydata &lt;- \n  all_dat %&gt;% \n  select(\n    id, ahiTotal, cesdTotal, # ID & questionnaire scores\n    sex, age, educ, income # demographic variables\n  ) \n\n\nwhat happens in the code chunk?",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#look-at-the-data",
    "href": "W4_DataVizR.html#look-at-the-data",
    "title": "04 Data Visualization",
    "section": "Look at the Data",
    "text": "Look at the Data\nHave a look at the types of data:\n\nglimpse(summarydata)\n\nRows: 992\nColumns: 7\n$ id        &lt;dbl&gt; 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, …\n$ ahiTotal  &lt;dbl&gt; 63, 73, 73, 89, 89, 93, 80, 77, 77, 85, 60, 67, 56, 61, 41, …\n$ cesdTotal &lt;dbl&gt; 14, 6, 7, 10, 13, 8, 15, 12, 3, 5, 31, 31, 41, 35, 27, 32, 2…\n$ sex       &lt;dbl&gt; 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, …\n$ age       &lt;dbl&gt; 35, 35, 59, 59, 59, 59, 59, 59, 51, 51, 50, 50, 50, 50, 58, …\n$ educ      &lt;dbl&gt; 5, 5, 1, 1, 1, 1, 1, 1, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, …\n$ income    &lt;dbl&gt; 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, …\n\n\nWhat do you see?\n\nAll variables are loaded as numeric. However, are all of those numeric?\n\n\nsex, educ and income don’t seem to really be numbers but factors with individual categories (factor levels)!\nWe should convert these data to factor. Checking and adjusting data types (as part of data wrangling) will be important for plotting and analyzing the data, you might otherwise get strange/wrong results!",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#activity-2-transform-to-factor",
    "href": "W4_DataVizR.html#activity-2-transform-to-factor",
    "title": "04 Data Visualization",
    "section": "Activity 2: Transform to factor",
    "text": "Activity 2: Transform to factor\nCopy and run the below code to change the categories to factors.\n\nsummarydata1 &lt;- \n  summarydata %&gt;%\n  mutate(\n    sex = as_factor(sex),\n    educ = as_factor(educ),\n    income = as_factor(income)\n  )\n\n\n\nIf you mutate a new column with the same name as the old one, it will overwrite the column.\n\n\n\n\nglimpse(summarydata1)\n\nRows: 992\nColumns: 7\n$ id        &lt;dbl&gt; 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, …\n$ ahiTotal  &lt;dbl&gt; 63, 73, 73, 89, 89, 93, 80, 77, 77, 85, 60, 67, 56, 61, 41, …\n$ cesdTotal &lt;dbl&gt; 14, 6, 7, 10, 13, 8, 15, 12, 3, 5, 31, 31, 41, 35, 27, 32, 2…\n$ sex       &lt;fct&gt; 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, …\n$ age       &lt;dbl&gt; 35, 35, 59, 59, 59, 59, 59, 59, 51, 51, 50, 50, 50, 50, 58, …\n$ educ      &lt;fct&gt; 5, 5, 1, 1, 1, 1, 1, 1, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, …\n$ income    &lt;fct&gt; 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, …",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#activity-2-transform-to-factor-1",
    "href": "W4_DataVizR.html#activity-2-transform-to-factor-1",
    "title": "04 Data Visualization",
    "section": "Activity 2: Transform to factor",
    "text": "Activity 2: Transform to factor\n\nglimpse(summarydata1)\n\nRows: 992\nColumns: 7\n$ id        &lt;dbl&gt; 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6, …\n$ ahiTotal  &lt;dbl&gt; 63, 73, 73, 89, 89, 93, 80, 77, 77, 85, 60, 67, 56, 61, 41, …\n$ cesdTotal &lt;dbl&gt; 14, 6, 7, 10, 13, 8, 15, 12, 3, 5, 31, 31, 41, 35, 27, 32, 2…\n$ sex       &lt;fct&gt; 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, …\n$ age       &lt;dbl&gt; 35, 35, 59, 59, 59, 59, 59, 59, 51, 51, 50, 50, 50, 50, 58, …\n$ educ      &lt;fct&gt; 5, 5, 1, 1, 1, 1, 1, 1, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, …\n$ income    &lt;fct&gt; 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, …\n\n\n\n\nsummarydata1 %&gt;% pull(educ) %&gt;% unique()\n\n[1] 5 1 4 2 3\nLevels: 1 2 3 4 5\n\n\n\n\n\nAt first glance, the data look the same. But the 1s and 2s in sex are now e.g. not treated as numbers anymore, but as factor levels (categories). This e.g. changes how the data behave in different analyses, or plotting (continuous vs. categorical data).",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#set-labels",
    "href": "W4_DataVizR.html#set-labels",
    "title": "04 Data Visualization",
    "section": "Set labels",
    "text": "Set labels\nA simple change to a factor is not always helpful. We still don’t know what a 1 in sex or a 5 in educ stands for:\n\nsex: 1 = female, 2 = male\neduc: 1 = no graduation, 2 = school graduation, 3 = vocational training, 4 = bachelor’s degree, 5 = post graduate\nincome: 1 = low, 2 = middle, 3 = high\n\n\n\nThere is very sparse information on the variables at https://doi.org/10.5334/jopd.35, so I guesstimated some of the factor levels.",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#set-labels-1",
    "href": "W4_DataVizR.html#set-labels-1",
    "title": "04 Data Visualization",
    "section": "Set labels",
    "text": "Set labels\nmatch_case() allows us to label our numeric data with more human-readable descriptions. if_else() is a useful shorthand for cases where we only have two categories.\n\nsummarydata2 &lt;- \n  summarydata %&gt;% \n  mutate(\n    sex = if_else(sex == 1, \"female\", \"male\") %&gt;% as_factor(), #wrong if non-binary entries exist\n    educ = educ %&gt;% \n      case_match(\n        1 ~ \"no graduation\",\n        2 ~ \"school graduation\",\n        3 ~ \"vocational training\",\n        4 ~ \"bachelor's degree\",\n        5 ~ \"post grad\"\n      ) %&gt;%\n      as_factor(), # need to transform to factor in the end\n    income = income %&gt;% \n      case_match(1 ~ \"low\", 2 ~ \"middle\", 3 ~ \"high\") %&gt;% \n      as_factor()\n  )",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#set-labels-2",
    "href": "W4_DataVizR.html#set-labels-2",
    "title": "04 Data Visualization",
    "section": "Set labels",
    "text": "Set labels\n\nsummarydata2 %&gt;% pull(educ) %&gt;% unique()\n\n[1] post grad           no graduation       bachelor's degree  \n[4] school graduation   vocational training\n5 Levels: post grad no graduation bachelor's degree ... vocational training\n\n\nFactor is now ordered by occurrence in data! :( (E.g., the order on the axis of a plot would be wrong.)",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#set-factor-order-levels",
    "href": "W4_DataVizR.html#set-factor-order-levels",
    "title": "04 Data Visualization",
    "section": "Set factor order (levels)",
    "text": "Set factor order (levels)\nUsing factor(), we can explicitly order the categories using the argument levels.\n\nsummarydata %&gt;% \n  mutate(\n    income = income %&gt;%\n      case_match(1 ~ \"low\", 2 ~ \"middle\", 3 ~ \"high\") %&gt;% \n      as_factor()\n  ) %&gt;% \n  pull(income) %&gt;% unique()\n\n[1] high   low    middle\nLevels: high low middle\n\n\n\nsummarydata %&gt;% \n  mutate(\n    income = income %&gt;% \n      case_match(1 ~ \"low\", 2 ~ \"middle\", 3 ~ \"high\") %&gt;% \n      factor(levels = c(\"low\", \"middle\", \"high\")) # factor(), not as_factor()!\n  ) %&gt;% \n  pull(income) %&gt;% unique()\n\n[1] high   low    middle\nLevels: low middle high",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#put-it-all-together",
    "href": "W4_DataVizR.html#put-it-all-together",
    "title": "04 Data Visualization",
    "section": "Put it all together",
    "text": "Put it all together\nIn this case, we can arrange the data by the numerical values before switching them to text labels.\n\nsummarydata3 &lt;- \n  summarydata %&gt;% \n  arrange(sex, educ, income) %&gt;% # can be a problem if some condition combinations don't exist\n  mutate(\n    sex = if_else(sex == 1, \"female\", \"male\") %&gt;% as_factor(), # wrong if non-binary entries exist\n    educ = educ %&gt;% \n      case_match(\n        1 ~ \"no graduation\",\n        2 ~ \"school graduation\",\n        3 ~ \"vocational training\",\n        4 ~ \"bachelor's degree\",\n        5 ~ \"post grad\"\n      ) %&gt;%\n      as_factor(),\n    income = income %&gt;% \n      case_match(1 ~ \"low\", 2 ~ \"middle\", 3 ~ \"high\") %&gt;% \n      as_factor()\n  )\n\n# summarydata3 %&gt;% select(sex, educ, income) %&gt;% summary()",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#the-first-layer",
    "href": "W4_DataVizR.html#the-first-layer",
    "title": "04 Data Visualization",
    "section": "The First Layer",
    "text": "The First Layer\n\nThe first line (or layer) sets up the base of the graph: the data to use and the aesthetics (aes()) (what will go on the x and y axis, how the plot will be grouped).\naes() includes anything that is directly related to your data: e.g., what goes on the x and y axis, or whether the plot should be grouped by a variable in your data.\nWe can provide x and y as arguments, however, in a bar plot, the count per category is calculated automatically, so we don’t need to put anything on the y-axis ourselves.\n\n\n\nggplot(summarydata3, aes(x = sex))",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#the-second-layer",
    "href": "W4_DataVizR.html#the-second-layer",
    "title": "04 Data Visualization",
    "section": "The Second Layer",
    "text": "The Second Layer\nThe next layer adds a geom or a shape. In this case we use geom_bar() as we want to draw a bar plot.\n\nNote that we are adding layers, using a + between layers. This is a very important difference between pipes and visualization.\n\n\n\nggplot(summarydata3, aes(x = sex)) +\n  geom_bar()",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#the-second-layer-with-color",
    "href": "W4_DataVizR.html#the-second-layer-with-color",
    "title": "04 Data Visualization",
    "section": "The Second Layer with color",
    "text": "The Second Layer with color\n\nAdding fill to the first layer will separate the data into each level of the grouping variable and fill it with a different color. Note that fill colors the inside of the bar, while color colors the bar’s outlines.\nWe can get rid of the (in this case redundant legend) with show.legend = FALSE.\n\n\n\nggplot(summarydata3, aes(x = sex, fill = sex)) +\n  geom_bar() #geom_bar(show.legend = FALSE)",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#the-next-layers---improving-the-plot",
    "href": "W4_DataVizR.html#the-next-layers---improving-the-plot",
    "title": "04 Data Visualization",
    "section": "The Next Layers - Improving the Plot",
    "text": "The Next Layers - Improving the Plot\nWe might want to make the plot a bit prettier and easier to read. What would you improve?\n\nWe could add better axis labels, and custom colors. We can do so with the functions scale_x_discrete() and scale_y_continuous(), which adjust the x and y axes.\nBoth functions can change several aspects of our axes; here, we use the argument name to set a new axis name.\n\n\nggplot(summarydata3, aes(x = sex, fill = sex)) +\n  geom_bar(show.legend = FALSE) +\n  scale_x_discrete(name = \"Participant Sex\") + \n  scale_y_continuous(name = \"Number of participants\")\n\n\n\n\n\n\n\n\n\n\n\nThere’s also the counterparts scale_x_continuous() and scale_y_discrete(). What do you think, why do we use the ones mentioned above and when would we use the other ones?",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#themes-changing-the-appearance",
    "href": "W4_DataVizR.html#themes-changing-the-appearance",
    "title": "04 Data Visualization",
    "section": "Themes: Changing the Appearance",
    "text": "Themes: Changing the Appearance\nThere are a number of built-in themes that you can use to change the appearance (background, whether axes are shown etc.), but you can also tweak the themes further manually.\nWe will now change the default theme to theme_minimal(), but you can also try other themes (just type “theme_” and see what the autocomplete brings up).\n\n\nggplot(summarydata3, aes(x = sex, fill = sex)) +\n  geom_bar(show.legend = FALSE) +\n  scale_x_discrete(name = \"Participant Sex\") + \n  scale_y_continuous(name = \"Number of participants\") +\n  theme_minimal()",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#colors",
    "href": "W4_DataVizR.html#colors",
    "title": "04 Data Visualization",
    "section": "Colors",
    "text": "Colors\nThere are various ways to change the colors of the bars. You can manually indicate the colors you want to use but you can also easily use pre-determined color palettes that are already checked for color-blind friendliness.\nA popular palette is viridis. We can simply add a function/layer to your ggplot named scale_fill_viridis_d() (d for discrete). The function has an option parameter that takes 5 different values (A - E).\n\nRun the code below. Try changing the option to either A, B, C or D and see which one you like!\n\n\n\nggplot(summarydata3, aes(x = sex, fill = sex)) +\n  geom_bar(show.legend = FALSE) +\n  scale_x_discrete(name = \"Participant Sex\") +\n  scale_y_continuous(name = \"Number of participants\") +\n  theme_minimal() +\n  scale_fill_viridis_d(option = \"E\")",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#transparency",
    "href": "W4_DataVizR.html#transparency",
    "title": "04 Data Visualization",
    "section": "Transparency",
    "text": "Transparency\nYou can also add transparency to your plot, which can be helpful if you plot several layers of data that overlap.\nTo do so, you can simply add alpha to the geom_bar() - try changing the value of alpha (between 0 and 1):\n\n\nggplot(summarydata3, aes(x = sex, fill = sex)) +\n  geom_bar(show.legend = FALSE, \n           alpha = .8) +\n  scale_x_discrete(name = \"Participant Sex\") +\n  scale_y_continuous(name = \"Number of participants\") +\n  theme_minimal() +\n  scale_fill_viridis_d(option = \"E\")",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#grouped-plots",
    "href": "W4_DataVizR.html#grouped-plots",
    "title": "04 Data Visualization",
    "section": "Grouped Plots",
    "text": "Grouped Plots\nImagine that you have several factors that you want to use to group your data, such as gender and income. In this case, you could use a grouped bar plot:\n\n\nggplot(summarydata3, aes(x = sex, fill = income)) +\n  geom_bar(\n    # the default are stacked bars; we use \"dodge\" to put them side by side\n    position = \"dodge\",\n    alpha = .8\n  ) +\n  scale_x_discrete(name = \"Participant Sex\") +\n  scale_y_continuous(name = \"Number of participants\") +\n  theme_minimal() +\n  scale_fill_viridis_d(option = \"E\")\n\n\n\n\n\n\n\n\n\n\n\nWithout position = dodge, you would get a stacked barplot",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#facetting",
    "href": "W4_DataVizR.html#facetting",
    "title": "04 Data Visualization",
    "section": "Facetting",
    "text": "Facetting\nYou could also use facets to divide your data visualizations into several subplots: facet_wrap for one variable.\n\nggplot(summarydata3, aes(x = sex, fill = sex)) +\n  geom_bar(show.legend = FALSE, alpha = .8) +\n  scale_x_discrete(name = \"Participant Sex\") +\n  scale_y_continuous(name = \"Number of participants\") +\n  theme_minimal() +\n  scale_fill_viridis_d(option = \"E\")  +\n  facet_wrap(vars(income)) # here, you need to use vars() around variable names\n\n\n\nWhat is problematic here? We needed percentages for females and males for a better comparison",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#facetting-2",
    "href": "W4_DataVizR.html#facetting-2",
    "title": "04 Data Visualization",
    "section": "Facetting 2",
    "text": "Facetting 2\nYou could also use facets to divide your data visualizations into several subplots: facet_grid for a matrix of (combinations of) two variables.\n\nggplot(summarydata3, aes(x = sex, fill = sex)) +\n  geom_bar(show.legend = FALSE, alpha = .8) +\n  scale_x_discrete(name = \"Participant Sex\") +\n  scale_y_continuous(name = \"Number of participants\") +\n  theme_minimal() +\n  scale_fill_viridis_d(option = \"E\")  +\n  facet_grid(\n    rows = vars(income),\n    cols = vars(educ),\n    labeller = \"label_both\" # this adds the variable name into the facet legends\n  )",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#a-closer-look",
    "href": "W4_DataVizR.html#a-closer-look",
    "title": "04 Data Visualization",
    "section": "A closer look",
    "text": "A closer look",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#violin-boxplot",
    "href": "W4_DataVizR.html#violin-boxplot",
    "title": "04 Data Visualization",
    "section": "Violin-Boxplot",
    "text": "Violin-Boxplot\nLet’s look at the code. How does the code differ from the one for the barplot above?\n\n\nggplot(summarydata3, aes(x = income, \n                         y = ahiTotal, # new variable!\n                         fill = income)) +\n  geom_violin(trim = FALSE, # smooth on edges\n              alpha = .4) +\n  geom_boxplot(width = .2, # small boxplot contained in violin\n               alpha = .7) +\n  scale_x_discrete(\n    name = \"Income\",\n    # set new labels\n    labels = c(\"Below Average\", \"Average\", \"Above Average\")) +\n  scale_y_continuous(name = \"Authentic Happiness Inventory Score\")+\n  theme_minimal() +\n  # no need to switch of axis for every geom individually\n  theme(legend.position = \"none\") + \n  scale_fill_viridis_d()\n\n\n\n\n\n\n\n\n\n\n\nIn this case, not the count on the y-axis, but another cont. variable!",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#layer-order",
    "href": "W4_DataVizR.html#layer-order",
    "title": "04 Data Visualization",
    "section": "Layer Order",
    "text": "Layer Order\nThe order of layers is crucial, as the plot will be built up in that order (later layers on top):\n\n\n\nggplot(summarydata3, aes(x = income, y = ahiTotal)) +\n  geom_violin() +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\nggplot(summarydata3, aes(x = income, y = ahiTotal)) +\n  geom_boxplot() +\n  geom_violin()",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#scatterplot",
    "href": "W4_DataVizR.html#scatterplot",
    "title": "04 Data Visualization",
    "section": "Scatterplot",
    "text": "Scatterplot\nIf we have continuous data of two variables, we often want to make a scatter plot:\n\n\nggplot(summarydata3, aes(x = age, y = cesdTotal)) +\n  geom_point() +\n  # if you don't want the shaded CI, add se = FALSE to this\n  geom_smooth(method = lm)",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#saving-your-figures",
    "href": "W4_DataVizR.html#saving-your-figures",
    "title": "04 Data Visualization",
    "section": "Saving your Figures",
    "text": "Saving your Figures\nYou can use ggsave() to save your plots. If you don’t tell ggsave() which plot you want to save, by default it will save the last plot you created.\nYou just have to enter the name of the file to be saved (in your working directory) like this:\n\nggsave(\"violin-boxplot.png\")\n\nCheck whether indeed the last plot was saved!\n\nYou can also specify the dimensions of your plot to be saved:\n\nggsave(\"violin-boxplot.png\",\n       width = 6.5, #width of a typical page in inches minus border (according to APA format)\n       height = 6.5 / sqrt(2), #golden ratio :)\n       units = \"in\")\n\nor\n\nggsave(\"violin-boxplot.png\",\n       width = 1920,\n       height = 1080,\n       units = \"px\") #full HD picture in pixels: 1920 x 1080",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W4_DataVizR.html#saving-your-figures-2",
    "href": "W4_DataVizR.html#saving-your-figures-2",
    "title": "04 Data Visualization",
    "section": "Saving your Figures 2",
    "text": "Saving your Figures 2\nYou can also assign the plot to a variable in your environment and then tell ggsave() which object to save. This is a bit safer.\nRun the code for the violin-boxplot again and save the plot in an object called viobox. You’d then have to explicitly tell ggsave() to save the object viobox:\n\nviobox &lt;- \n  ggplot(summarydata3, aes(x = income, y = ahiTotal, fill = income)) +\n  geom_violin(trim = FALSE, alpha = .4) +\n  geom_boxplot(width = .2, alpha = .7) +\n  scale_x_discrete(\n    name = \"Income\",\n    labels = c(\"Below Average\", \"Average\", \"Above Average\")) +\n  scale_y_continuous(name = \"Authentic Happiness Inventory Score\")+\n  theme_minimal() +\n  theme(legend.position = \"none\") + \n  scale_fill_viridis_d()\n\nggsave(\"violin-boxplot-stored.png\", plot = viobox)\n\n\nDo not add ggsave() to the plot with a +. Instead run it on a separate line!\nIf plot is assigned to object, it won’t be displayed unless you type viobox in the console!",
    "crumbs": [
      "04 Data Visualization"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#null-hypothesis-significance-testing",
    "href": "W7_Hypothesis.html#null-hypothesis-significance-testing",
    "title": "07 Hypothesis Testing",
    "section": "Null Hypothesis Significance Testing",
    "text": "Null Hypothesis Significance Testing\nExample: We have two groups (treatment and control). We also have a hypothesis: The treatment group has lower scores on measure X (e.g., symptoms). We have the data (X for both groups), now what?\n\n\nWe take the hypothesis (treatment = lower X than control) and negate it (Treatment not lower/equal X compared to control). This is our null hypothesis.\nThen we look at the data and determine how likely they would be if the null hypothesis were true.\nI.e., we want to know the conditional probability: \\(P(Data|H_0)\\)\nIf the data are very unlikely we reject the null hypothesis in favor of the alternative hypothesis (our hypothesis).\n(If the data are not very unlikely, we stick with - or fail to reject - the null hypothesis.)\n\n\n\nHow would you compare the two groups? Calculate the likelihood that there is a reduction in X between the groups? No, more complicated! And counterintuitive!",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#the-process-of-nhst",
    "href": "W7_Hypothesis.html#the-process-of-nhst",
    "title": "07 Hypothesis Testing",
    "section": "The Process of NHST",
    "text": "The Process of NHST\nTo be more precise, we can break down the process of null hypothesis testing in six steps:\n\n\nFormulate a hypothesis that embodies our prediction (before seeing the data)\nSpecify null and alternative hypotheses that reflect the hypothesis formulated in step 1\nCollect some data relevant to the hypothesis\nFit a model to the data that represents the alternative hypothesis and compute a test statistic\nCompute the probability of the observed value of that statistic assuming that the null hypothesis is true\nAssess the “statistical significance” of the result\n\n\n\nLet’s go through these steps, using the NHANES dataset and the research question: Is physical activity related to body mass index (BMI)?",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#step-1-formulate-a-hypothesis-of-interest",
    "href": "W7_Hypothesis.html#step-1-formulate-a-hypothesis-of-interest",
    "title": "07 Hypothesis Testing",
    "section": "Step 1: Formulate a Hypothesis of Interest",
    "text": "Step 1: Formulate a Hypothesis of Interest\nHypothesis:\n\n“BMI is greater for people who do not engage in physical activity than for those who do.”\n\nask for hypothesis?",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#step-2-specify-the-null-and-alternative-hypotheses",
    "href": "W7_Hypothesis.html#step-2-specify-the-null-and-alternative-hypotheses",
    "title": "07 Hypothesis Testing",
    "section": "Step 2: Specify the Null and Alternative Hypotheses",
    "text": "Step 2: Specify the Null and Alternative Hypotheses\nThe null hypothesis (\\(H_0\\)) is the baseline against which we test our hypothesis of interest.\nThe alternative hypothesis (\\(H_A\\)) describes what we expect if there is an effect.\nNHST works under the assumption that the \\(H_0\\) is true (unless the evidence shows otherwise).\n\nWe also have to decide whether we want to test a non-directional (\\(A \\neq B\\)) or directional (\\(A&gt;B\\) or \\(A&lt;B\\)) hypothesis.\nWhat do we specify if we hypothesize that “BMI is greater…”?\n\n\n\\(H_0 = BMI_{active} \\ge BMI_{inactive}\\)\n\\(H_A = BMI_{active} &lt; BMI_{inactive}\\)\n\nTest against \\(H_0\\): What would we expect the data to look like if there was no effect?\nNon-directional: no direction! :D Directional: prior knowledge",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#step-3-collect-data",
    "href": "W7_Hypothesis.html#step-3-collect-data",
    "title": "07 Hypothesis Testing",
    "section": "Step 3: Collect Data",
    "text": "Step 3: Collect Data\nFor this example, we sample 250 individuals from the NHANES dataset.\n\n\n\nSummary of BMI data for active versus inactive individuals\n\n\nPhysActive\nN\nmean\nsd\n\n\n\n\nNo\n131\n30.1942\n8.9851\n\n\nYes\n119\n26.6386\n5.2499",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#step-4-fit-a-model",
    "href": "W7_Hypothesis.html#step-4-fit-a-model",
    "title": "07 Hypothesis Testing",
    "section": "Step 4: Fit a Model",
    "text": "Step 4: Fit a Model\nWe want to compute a test statistic that helps us decide whether to reject \\(H_0\\) or not.\n\nThe model we fit needs to quantify (= provide the test statistic) the amount of evidence in favor of \\(H_A\\) relative to the variability of the data.\nThe test statistic will have a probability distribution, allowing us to determine how likely our observed value of the statistic is under \\(H_0\\).\n\n\nIn general, we want to relate an effect (e.g., a mean or a difference of means) to the amount of uncertainty in the data (e.g., the SEM).\n\n\nIn the example, we need a test statistic that tests the difference between two means (we have one BMI mean for each group): The t statistic.\n\\[t = \\frac{\\bar{X_1} - \\bar{X_2}}{\\sqrt{\\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}}}\\]\n\\(\\bar{X_1}\\) and \\(\\bar{X_2}\\) are the means of the two group, \\(S_1^2\\) and \\(S_2^2\\) are the estimated variances of the groups, \\(n_1\\) and \\(n_2\\) are the sizes of the two groups.\n\n\n\\(\\sqrt{\\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}}\\) is something like the pooled (“averaged”) SEM of both groups.\n\nThe t statistic is appropriate for comparing the means of two groups when the sample sizes are relatively small and the population standard deviation is unknown.\n\\(\\sqrt{\\frac{S_1^2}{n_1}}\\) alone would be the SEM of subsample 1. But we have to add first before we take the square root.\nReason for adding: The variance of a difference between (or sum of) two independent variables is the sum of the variances of each individual variable (\\(Var(A−B)=Var(A)+Var(B)\\))\none can view the the t statistic as a way of quantifying how large the difference between groups is in relation to the sampling variability of the difference between means",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#the-t-distribution",
    "href": "W7_Hypothesis.html#the-t-distribution",
    "title": "07 Hypothesis Testing",
    "section": "The t Distribution",
    "text": "The t Distribution\nThe t statistic is distributed according to the t distribution, which looks similar to a normal distribution (the more degrees of freedom, the more “normal”).\nDegrees of freedom for the t test: \\(observations - 2\\) = \\(n_1 + n_2 - 2\\) (when the groups are the same size).\nDegrees of freedom: values that can freely vary when estimating parameters. Usually sample size minus values that you already calculated (e.g. means for the test statistic).\n\n\n\n\n\n\n\n\n\n\nIf the group sizes are unequal: \\(\\mathrm{d.f.} = \\frac{\\left(\\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}\\right)^2}{\\frac{\\left(S_1^2/n_1\\right)^2}{n_1-1} + \\frac{\\left(S_2^2/n_2\\right)^2}{n_2-1}}\\)\nFortunately, R does all these calculations for us :)\n\nDF: we have calculated two means and have thus given up two DFs (these are fixed already)\nWill be smaller if sample sizes unequal (here 241.12 vs 248 for equal)\nDegrees of freedom are the number of independent values that a statistical analysis can estimate. You can also think of it as the number of values that are free to vary as you estimate parameters",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#step-5-determine-the-probability-of-the-observed-result-under-the-null-hypothesis",
    "href": "W7_Hypothesis.html#step-5-determine-the-probability-of-the-observed-result-under-the-null-hypothesis",
    "title": "07 Hypothesis Testing",
    "section": "Step 5: Determine the Probability of the Observed Result under the Null Hypothesis",
    "text": "Step 5: Determine the Probability of the Observed Result under the Null Hypothesis\nWe do not check likelihood of the alternative distribution or likelihood that the null hypothesis is true, but rather:\nHow likely is it, given that we assume \\(H_0\\) is true, to observe a statistic at least as extreme as the one we observed.\n--&gt; We need to know the distribution of the expected statistic, assuming \\(H_0\\) is true. Then we can calculate how (un-)likely it is to find the statistic (or a more extreme value) we found in our data.\n\n\n\n\n\n\n\n\n\n\n\ncounter-intuitive: We check the nulldistribution not the one of \\(H_A\\)! But we also don’t check how likely it is that \\(H_0\\) is true, but rather the likelihood under the null hypothesis of observing a statistic at least as extreme as the one we observed.\nat least as extreme: Prob of each particular value = 0\ntry to find out how weird statistic found is (or weirder) –&gt; count all weird(er) possibilities",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#a-simple-example",
    "href": "W7_Hypothesis.html#a-simple-example",
    "title": "07 Hypothesis Testing",
    "section": "A Simple Example",
    "text": "A Simple Example\nIs a coin biased if we flip a coin 100x and we get 70 heads?\n\\(H_0: P(heads) \\le 0.5\\) and \\(H_A: P(heads) &gt; 0.5\\)\nTest statistic = number of heads counted.\nHow likely is it that we would observe 70 or more heads if the coin is unbiased (chance of 50% for heads)?\n\nIf we flip a (fair) coin 100 times, we would get the following distribution (100000 replications):\n\n\n\n\n\n\n\n\n\nIt is very unlikely to get 70 heads if the coin is fair!\n\nfair coin: null distribution",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#p-value",
    "href": "W7_Hypothesis.html#p-value",
    "title": "07 Hypothesis Testing",
    "section": "P-Value",
    "text": "P-Value\nLet’s go back to out BMI example.\nWe first need to calculate the t statistic:\n\n\n\nSummary of BMI data for active versus inactive individuals\n\n\nPhysActive\nN\nmean\nsd\n\n\n\n\nNo\n131\n30.1942\n8.9851\n\n\nYes\n119\n26.6386\n5.2499\n\n\n\n\n\n\\[t = \\frac{\\bar{X_1} - \\bar{X_2}}{\\sqrt{\\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}}}\\]\n\\[t = \\frac{30 - 27}{\\sqrt{\\frac{9^2}{131} + \\frac{5.2^2}{119}}}\\]\n\\[t = 3.86\\]\n\nThe question is: What is the likelihood that we would find a t statistic of this size or more extreme given the number of degrees of freedom and if the true difference between the groups is zero.\n\n\n\n\\(t\\) statistics if we use the unrounded values!",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#p-value-2",
    "href": "W7_Hypothesis.html#p-value-2",
    "title": "07 Hypothesis Testing",
    "section": "P-Value 2",
    "text": "P-Value 2\nWe can use the t distribution to calculate this probability. We just need the degrees of freedom, which are \\(DF = 241.12\\), and we can then use all these values (e.g. in a function in R):\n\n\n[1] 7.282672e-05\n\n\nThis small probability tells us that our observed t value is relatively unlikely if \\(H_0\\) is really true.\n\nThis is the p-Value for a directional hypothesis. In this case, we only looked at the upper tail probability. With a non-directional hypothesis, we would want to account for both tail probabilities, i.e. how likely it is that a \\(t &gt; 3.86\\) OR \\(t &lt; -3.86\\) is found. In this case, we can simply multiply the p-Value found above by 2 (since it is a symmetric distribution):\n\\(p = 0.000145\\)",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#p-value-using-randomization",
    "href": "W7_Hypothesis.html#p-value-using-randomization",
    "title": "07 Hypothesis Testing",
    "section": "P-Value using Randomization",
    "text": "P-Value using Randomization\nWe can also use our simulation skills to determine the null distribution!\n\nWe can randomly rearrange (or permute) data so that no relationship is present, e.g. assigning group membership to the participants randomly. In this case, \\(H_0\\) should thus be true.\nWe would do this a large amount of times (e.g. 10000), calculate the t statistics for each iteration, and draw a histogram to show the distribution.",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#p-values-using-randomization-2",
    "href": "W7_Hypothesis.html#p-values-using-randomization-2",
    "title": "07 Hypothesis Testing",
    "section": "P-Values using Randomization 2",
    "text": "P-Values using Randomization 2\n\n# create function to shuffle BMI data\nshuffleBMIstat &lt;- function() {\n  bmiDataShuffled &lt;- \n    NHANES_sample %&gt;%\n    select(BMI, PhysActive) %&gt;%\n    mutate(\n      BMI = sample(BMI) #randomly shuffle BMI values\n    )\n  # compute the difference\n  simResult &lt;- t.test( #t.test function is more convenient than pt function!\n    BMI ~ PhysActive,\n    data = bmiDataShuffled,\n  )\n  return(simResult$statistic)\n}\n# run function 5000 times and save output\nnRuns &lt;- 5000\nmeanDiffSimDf &lt;- tibble(meanDiffSim = replicate(nRuns, shuffleBMIstat()))\n#run t test of actual data\nbmtTTest &lt;- \n  t.test(\n  BMI ~ PhysActive,\n  data = NHANES_sample,\n  alternative = \"greater\"\n)\n#compare actual data with simulation\nbmiPvalRand &lt;- \n  mean(meanDiffSimDf$meanDiffSim &gt;= bmtTTest$statistic)\n\n#plot everything\nplot = meanDiffSimDf %&gt;% \n  ggplot(aes(meanDiffSim)) +\n  geom_histogram(bins = 200) +\n  geom_vline(xintercept = bmtTTest$statistic, color = \"blue\") +\n  xlab(\"T stat: BMI difference between groups\") +\n  geom_histogram(\n    data = meanDiffSimDf %&gt;% \n      filter(meanDiffSim &gt;= bmtTTest$statistic), \n    aes(meanDiffSim), \n    bins = 200, \n    fill = \"gray\"\n  )\nprint(plot)",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#p-values-using-randomization-3",
    "href": "W7_Hypothesis.html#p-values-using-randomization-3",
    "title": "07 Hypothesis Testing",
    "section": "P-Values using Randomization 3",
    "text": "P-Values using Randomization 3\n\nThe blue line is the observed t statistic. We can calculate a p-Value by counting how many of the simulated t-values are at least as extreme as our observed one and dividing it by the number of simulations. The p-value obtained from randomization (0.000000) is kind of similar to the one obtained using the t distribution (0.000075).\n\nUsing simulations to get the null distribution can be helpful if the assumptions (normal distribution in each group) are violated or if we don’t know the theoretical distribution of the test statistic!\n\nexchangeability: We can use permutations if all observsations are distributed in the same way, such that we can shuffle them without changing the overall distribution.\nNot the case if we have dependent observations, e.g. siblings…",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#step-6-assess-the-statistical-significance-of-the-result",
    "href": "W7_Hypothesis.html#step-6-assess-the-statistical-significance-of-the-result",
    "title": "07 Hypothesis Testing",
    "section": "Step 6: Assess the “Statistical Significance” of the Result",
    "text": "Step 6: Assess the “Statistical Significance” of the Result\nIs the p-value determined small enough to reject the null hypothesis (and thus conclude that the alternative hypothesis is true)?\n\nTraditionally, we reject \\(H_0\\) if the p-value is less than 0.05. (Fisher’s approach)\n\n\n(Either there is an effect/\\(H_A\\) is true or there is a small chance (5%) that there is actually no effect but we coincidentally found such a large value –&gt; false positive)\n\n\nNeyman-Pearson approach: In the long run, we will know how often we are wrong:\n\n\\(\\alpha = .05\\) (false positives or Type I error: We reject \\(H_0\\) although it is correct),\n\\(\\beta = .2\\) (false negatives or Type II error: We accept \\(H_0\\) although it is wrong),\nWe will be correct if we reject \\(H_0\\) when it is wrong (there is actually a difference/an effect) or if we do not reject \\(H_0\\) when it is correct (and there is no difference between groups).\n\nIn both cases, a significance level of \\(\\alpha = .05\\) is usually used.\n\nHow much evidence do we require?\n0.05 Fisher never intended it to be fixed\nBefore computers, tables were used, and all tables had .05 in it!\nFisher: Evidence for hypothesis, NP: long-run error rate",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#what-does-a-significant-result-mean",
    "href": "W7_Hypothesis.html#what-does-a-significant-result-mean",
    "title": "07 Hypothesis Testing",
    "section": "What does a significant result mean?",
    "text": "What does a significant result mean?\nThere is a lot of discussion about the usefulness of using \\(\\alpha = .05\\) as well as about the interpretation of a significant result/certain p-value!\n\n\nA p-value of .01 does….\n\nNOT mean that the probability that \\(H_0\\) is true is 1%!\n\nWe tested \\(P(data|H_0)\\) not \\(P(H_0|data)\\)!\n\nNOT mean that the probability that you’re making a wrong decision is 1%!\n\nThis would also be \\(P(H_0|data)\\)! p-values are probabilities of data (under \\(H_0\\)), not probabilities of hypotheses! And we cannot easily use Bayes to turn the condition because we would need additional information like the prior probability of an alternative hypothesis being true.\n\nNOT mean that you would get the same significance 99% of the time if you repeated the study.\n\nThe p-value is a statement about the likelihood of one particular dataset under the null.\n\nNOT mean that you found a practically important effect.\n\nDifference between statistical significance and practical significance! Effect sizes more important. (Statistical significance depends on sample size!)",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#multiple-testing",
    "href": "W7_Hypothesis.html#multiple-testing",
    "title": "07 Hypothesis Testing",
    "section": "Multiple Testing",
    "text": "Multiple Testing\nNowadays, we often have huge datasets in neuroscience, e.g. collecting brain imaging data of thousands of voxels or quantifying the entire genome.\n\nLet’s look at genome-wide associations studies (GWAS). We have more than a million places in where the genome could differ. If we want to know whether schizophrenia was associated with any of these differences, we would do ~1.000.000 tests! If we simply used \\(\\alpha \\le .05\\) as a threshold, we would get a lot of (\\(1000000 * .05 = 500\\)!) false positives, even if no true effect is present at all.\n\n\nIn this case, we have a lot of dependent tests, which form a family of tests. In such a case, we need to control the family-wise error rate, e.g. by fixing it to a total of \\(\\alpha \\le .05\\) (i.e. the probability of making any Type I error in our study is controlled at .05).\n\n\nOne option is to use the Bonferroni correction, in which we divide .05 by the number of tests (e.g. 1.000.000) and use the new value (\\(\\alpha \\le .000005\\)) as threshold for each individual test.\n\n\nThis is extremely conservative and often results in false negative test results.\n\n\nFor an interesting example what can happen when not correcting for multiple comparisons, see this dead fish showing significant brain activity (Link).",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#confidence-intervals",
    "href": "W7_Hypothesis.html#confidence-intervals",
    "title": "07 Hypothesis Testing",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\nSingle value statistic (e.g. t-value, mean…) = point estimate\n\nWe know from the sampling error discussion that each point estimate comes with some uncertainty, described by the standard error.\nRemember, the SEM (standard error of the mean) was calculated with the sample standard deviation \\(\\hat{\\sigma}\\) and the square root of the sample size \\(n\\):\n\\[SEM = \\frac{\\hat{\\sigma}}{\\sqrt{n}}\\]\n\\(n\\) is generally under our control (\\(\\hat{\\sigma}\\) is unknown but fixed*), and we can thus decrease our uncertainty by increasing the sample size.\n\n\n\nWe can more directly describe our uncertainty with confidence intervals (CI), which provides a range of values for our parameter estimate that are consistent with our data! The wider the CI, the more uncertain we are about our estimate.\n\n\n* In practice, we can acquire homogeneous samples (like students) or heterogeneous samples (like extreme groups). This will, however, influence our generalizability.",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#confidence-intervals-2",
    "href": "W7_Hypothesis.html#confidence-intervals-2",
    "title": "07 Hypothesis Testing",
    "section": "Confidence Intervals 2",
    "text": "Confidence Intervals 2\nBecause the CI depends on the SEM, which decreases with sample size, the CI also gets narrower with increasing sample size:\n\n\nif we sample the whole population, we know the population parameter and there is no uncertainty at all!\nRange of possible values (estimate) in concordance with the data",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#confidence-intervals-3",
    "href": "W7_Hypothesis.html#confidence-intervals-3",
    "title": "07 Hypothesis Testing",
    "section": "Confidence Intervals 3",
    "text": "Confidence Intervals 3\nJust like p-values, confidence intervals can be confusing because they are counter-intuitive: A 95% CI for a statistic does NOT mean that we can have 95% confidence that the true parameter falls within this interval!\nIt is, again, the long-run probability: It will contain the true population parameter 95% of the time in the long-run.\nLet’s sample 100 times with \\(n = 250\\) from the NHANES data and calculate CIs. We use the NHANES mean as true score (dashed line) and check how often the CI misses to include it: 5% of the time.\n\n\nbut: new experiment = new estimate (under exact same conditions would work)!",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#calculating-the-ci",
    "href": "W7_Hypothesis.html#calculating-the-ci",
    "title": "07 Hypothesis Testing",
    "section": "Calculating the CI",
    "text": "Calculating the CI\nWe calculate the CI as follows:\n\\(CI = \\text{point estimate} \\pm \\text{critical value} * \\text{standard error}\\)\nThe “critical value” depends on the sampling distribution. Most of the time, we will use the normal distribution.\n\nCI depends on the confidence level (95%, critical value), the sample size and the variability in the data (both SE)",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#ci-using-the-normal-distribution",
    "href": "W7_Hypothesis.html#ci-using-the-normal-distribution",
    "title": "07 Hypothesis Testing",
    "section": "CI using the Normal Distribution",
    "text": "CI using the Normal Distribution\nThe critical value are the values of the standard normal distribution that capture 95% (in case of a 95% CI) of the distribution, i.e. the 2.5th and 97.5th percentile.\n\nqnorm(p=c(.025,.975))\n\n[1] -1.959964  1.959964\n\n\nThe CI of the mean would thus be:\n\\(CI = \\bar{X} \\pm 1.96*SE\\)\nOur mean weight in the NHANES sample was 79.92 kg and the SE was \\(\\frac{SD_{weight}}{\\sqrt{n}} = 1.35\\) (for a random \\(n=250\\) subsample)*.\n\nThe lower boundary of the CI of the mean would then be \\(CI = 79.92 - 1.96 * 1.35 = 77.28\\) and the upper \\(CI = 79.92 + 1.96 * 1.35 = 82.56\\). We would write this as [77.28, 82.56].\n\n* In practice, both the mean and standard deviation will be subject to sampling error, i.e., CIs will differ both in location and size despite having the same sample size (cf. plot 2 slides ago)",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#ci-using-the-t-distribution",
    "href": "W7_Hypothesis.html#ci-using-the-t-distribution",
    "title": "07 Hypothesis Testing",
    "section": "CI using the t Distribution",
    "text": "CI using the t Distribution\nIf we don’t know the population standard deviation, which is usually the case, it is more appropriate to use the t distribution.\nIn this case, we use the critical value of the t distribution:\n\nqt(p = c(.025, .975), 250) #t distribution depends on sample size! =&gt; n = 250\n\n[1] -1.969498  1.969498\n\n\nFor the NHANES weight example, the CI would be: \\(79.92 \\pm 1.97 * 1.35 = [77.15, 82.58]\\).\nThe CI for a t distribution is always larger than for a normal distribution. In practice, this difference is negligible at \\(n \\ge 30\\) (1.984 vs. 1.960).\n\nThe t distribution is wider than the normal distribution (especially for smaller samples), which means that the CI will be slightly wider -&gt; extra uncertainty smaller samples.\npopulation parameter hast a fixed value, so it either falls into CI or not. (Doesn’t make sense to talk about probability of it)",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#ci-using-the-bootstrap",
    "href": "W7_Hypothesis.html#ci-using-the-bootstrap",
    "title": "07 Hypothesis Testing",
    "section": "CI using the Bootstrap",
    "text": "CI using the Bootstrap\nIf we can’t assume normality or don’t know the sampling distribution, we can also use the bootstrap to compute the CI.\n\nReminder: bootstrap = resampling with replacement, using this distribution as the sampling distribution!\n\n\nIf we use an R function for bootstrapping (boot()), we get CI estimates that are fairly close to the ones calculated:\n\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 1000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = bs, type = \"perc\")\n\nIntervals : \nLevel     Percentile     \n95%   (78.41, 83.81 )  \nCalculations and Intervals on Original Scale\n\n\n\n\n\n\n\n\n\nMethod\nCI\n\n\n\n\nnormal distribution\n[77.28, 82.56]\n\n\nt distribution\n[77.15, 82.58]\n\n\nbootstrap\n[78.41, 83.81]\n\n\n\n\n\nNote: CIs from the normal and t distribution are always symmetrical around the mean (here: 79.92), bootstrapped intervals need not be.",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#relationship-of-cis-to-hypothesis-tests",
    "href": "W7_Hypothesis.html#relationship-of-cis-to-hypothesis-tests",
    "title": "07 Hypothesis Testing",
    "section": "Relationship of CIs to Hypothesis Tests",
    "text": "Relationship of CIs to Hypothesis Tests\nIf the CI does not include the value of the null hypothesis (usually 0), then the associated two-sided one sample test would be significant.\n\nIf we want to compare two conditions, it gets trickier.\n\nIf each mean is contained within the CI of the other mean, then there’s definitely no significant difference.\nIf there is no overlap between CIs, then there is certainly a significant difference (two-sidedly).\nIf the CIs overlap (but don’t contain the other mean), it depends on the relative variability of the two variables\n\nIn general, avoid this “eyeball test” and look at the p value!\nNote: Slightly overlapping CIs can still be significant (e.g., one sided hypothesis)",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#effect-sizes",
    "href": "W7_Hypothesis.html#effect-sizes",
    "title": "07 Hypothesis Testing",
    "section": "Effect Sizes",
    "text": "Effect Sizes\nPractical significance!\nWe need a standard way to describe the size of an effect.\nAn effect size is a standardized measurement that compares the size of an effect to e.g. the variability of the statistic. This is also referred to as signal-to-noise ratio.\nThere are many different variants of effect sizes!",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#cohens-d",
    "href": "W7_Hypothesis.html#cohens-d",
    "title": "07 Hypothesis Testing",
    "section": "Cohen’s d",
    "text": "Cohen’s d\nCohen’s d is used to quantify the difference between two means, in terms of their SD:\n\\[d = \\frac{\\bar{X_1} - \\bar{X}_2}{s}\\]\nwhere \\(\\hat{X_1}\\) and \\(\\hat{X_2}\\) are the means of the two groups and \\(s\\) is the pooled SD:\n\\[s = \\sqrt{\\frac{(n_1 - 1)s^2_1 + (n_2 - 1)s^2_2 }{n_1 +n_2 -2}}\\]\nwhich is a combination of both groups’ SDs (\\(s_1\\) and \\(s_2\\)) weighted by their sample size (\\(n_1\\) and \\(n_2\\)).\n\nNote that this is very similar to the t statistic, only the denominator differs:\nt = SEM, d = SD of the data\n–&gt; d will not grow with sample size but remain stable!",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#cohens-d-2",
    "href": "W7_Hypothesis.html#cohens-d-2",
    "title": "07 Hypothesis Testing",
    "section": "Cohen’s d 2",
    "text": "Cohen’s d 2\nThere is a commonly used interpretation of Cohen’s d (although it is criticized to use these cutoffs!):\n\n\n\nInterpetation of Cohen’s d\n\n\nd\nInterpretation\n\n\n\n\n0.0 - 0.2\nnegligible\n\n\n0.2 - 0.5\nsmall\n\n\n0.5 - 0.8\nmedium\n\n\n&gt; 0.8\nlarge\n\n\n\n\n\n\nEven with a large effect of \\(d = 1.78\\) (as in the NHANES data set), the distributions still overlap greatly!\n\n\n\n\n\n\n\n\n\n\nSmall effect but huge total impact: Psychosocial stress due to Covid-19 (deployed to a whole population)",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#pearsons-r",
    "href": "W7_Hypothesis.html#pearsons-r",
    "title": "07 Hypothesis Testing",
    "section": "Pearson’s r",
    "text": "Pearson’s r\nPearson’s r is a correlation coefficient, and thus a measure of the strength of a linear relationship between two continuous variables.\nr can vary from -1 to 1: -1 is a perfect negative relationship, 0 no (linear) relationship, and 1 a perfect positive relationship. Try your skills eye-balling the size of a correlation: https://www.guessthecorrelation.com/\n\n\nmore on correlations later in the semester!",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#odds-ratio",
    "href": "W7_Hypothesis.html#odds-ratio",
    "title": "07 Hypothesis Testing",
    "section": "Odds Ratio",
    "text": "Odds Ratio\nFor binary variables, the odds ratio is a useful effect size.\nOdds describes the relative likelihood of some event happening versus not happening:\n\\[\n\\text{odds of A} = \\frac{P(A)}{P(\\neg{A})}\n\\]\nOdds ratio is simply the ratio of two odds, i.e. \\(\\frac{\\text{odds of A}}{\\text{odds of B}}\\).\n\nExample:\n\n\n\nLung cancer occurrence separately for current smokers and those who have never smoked\n\n\nStatus\nNeverSmoked\nCurrentSmoker\n\n\n\n\nNo Cancer\n2883\n3829\n\n\nCancer\n220\n6784\n\n\n\n\n\n\\[OR = \\frac{\\frac{220}{220+2883}}{\\frac{6784}{6784+3829}} = 23.22 \\]\nThe odds ratio of 23.22 tells us that the odds of lung cancer in smokers are roughly 23x higher than that of non-smokers!",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#statistical-power",
    "href": "W7_Hypothesis.html#statistical-power",
    "title": "07 Hypothesis Testing",
    "section": "Statistical Power",
    "text": "Statistical Power\nRemember: Type I and Type II error!\nTolerance for Type I errors set to \\(\\alpha = 0.05\\), which is very low –&gt; we want to avoid this error!\nWhat about Type II errors?\n\nType II = failing to reject \\(H_0\\) although an effect exists (often set at \\(\\beta = 0.20\\), i.e., a statistical power of \\(80\\%\\)).\nBut \\(\\beta\\) also depends on the effect size: The likelihood of finding a large effect is higher than finding a small effect (at constant \\(n\\))!\n\n\nStatistical power is the complement of the Type II error:\nThe likelihood of finding a positive result given that it exits!\n\\[power = 1 - \\beta\\]\n\n\nStatistical power is affected by three factors:\n\nsample size (larger n = more power)\neffect size (larger effect = more power)\nType I error rate (smaller Type I error = less power)\n\n\nType I: false positives\nType II: false negatives",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W7_Hypothesis.html#statistical-power-2",
    "href": "W7_Hypothesis.html#statistical-power-2",
    "title": "07 Hypothesis Testing",
    "section": "Statistical Power 2",
    "text": "Statistical Power 2\nHere, we can see how these three factors influence the power (i.e. the proportion of significant results found):\n\nThe black dotted line denotes the standard 80% power that is often aimed at.\n\nEven with \\(n = 96\\), we have only little power to detect a small effect (\\(d = 0.2\\)): Only ~25% of studies would find the true effect. This means doing this study would be futile, we would likely fail to find the true effect.\n\n\nTherefore, we would do a power analysis before we even run the study - to determine the necessary sample size for a well-powered study that would be able to find an effect if the effect is true.\nFurthermore, positive findings from an underpowered study are more likely to be false positive!\n\nMore on that in Chapter 18 of ST21!",
    "crumbs": [
      "07 Hypothesis Testing"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#chi²-test-general",
    "href": "W8_ModelingRelationships.html#chi²-test-general",
    "title": "08 Modeling Relationships",
    "section": "Chi² Test: General",
    "text": "Chi² Test: General\nWe will first focus on modeling categorical relationships (of variables that are qualitative!).\n\nThese data are usually expressed in terms of counts.\n\n\nExample: Candy colors\nBag of candy: 30 chocolates, 33 licorices, and 37 gumballs.\n\n\nIs the distribution fair (i.e., 1/3rd of the bag = each candy) and the fact that there are only 30 chocolates a random accident?\n\n\nWhat is the likelihood that the count would come out this way (or even more extreme) if the true probability of each candy type is the same?\n\nCounts: For each combination of variables, how many observations do we have?\nIf the machine really sorts on average 1/3 of each in each bag? How much is due to chance?",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#chi²-test-one-variable",
    "href": "W8_ModelingRelationships.html#chi²-test-one-variable",
    "title": "08 Modeling Relationships",
    "section": "Chi² Test: One Variable",
    "text": "Chi² Test: One Variable\nThe Chi² test checks whether observed counts differ from expected values (\\(H_0\\)).\n\\[\n\\chi^2 = \\sum_i\\frac{(observed_i - expected_i)^2}{expected_i}\n\\]\n\nThe null hypothesis in our example is that the proportion of each type of candy is equal (1/3 or ~33.33).\nIf we plug in our values from above, we would calculate \\(\\chi^2\\) like this:\n\\[ \\chi^2 = \\frac{(30 - 33.33)^2}{33.33} + \\frac{(33 - 33.33)^2}{33.33} + \\frac{(37 - 33.33)^2}{33.33} = 0.74 \\]\n\ntake the difference between observed and expected (33.33), square it, divide it by expected 33.33 and add everything up",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#chi²-test-general-2",
    "href": "W8_ModelingRelationships.html#chi²-test-general-2",
    "title": "08 Modeling Relationships",
    "section": "Chi² Test: General 2",
    "text": "Chi² Test: General 2\nOn its own, the \\(\\chi^2\\) statistic is not interpretable - it depends on its distribution.\nThe shape of the chi-squared distribution depends on the degrees of freedom (much like the t distribution), which is the number of category levels \\(k-1\\).\n\nFor the candy example, we use a chi-squared distribution with DFs = 2 (3 candy categories minus one). If we’d look at the distribution and found \\(\\chi^2 = .74\\) on the x-axis, we would see that it does not fall far into the tail of the distribution but is rather in the middle. If we calculate the p-value, we’d get \\(P(\\chi^2 &gt; .74) = 0.691\\).\nIt is thus not particularly surprising to find this distribution of candies and we would not reject \\(H_0\\) (equal proportions).",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#contingency-tables-and-the-two-way-test",
    "href": "W8_ModelingRelationships.html#contingency-tables-and-the-two-way-test",
    "title": "08 Modeling Relationships",
    "section": "Contingency Tables and the Two-Way Test",
    "text": "Contingency Tables and the Two-Way Test\nThe \\(\\chi^2\\) test is also used to test whether two categorical variables are related to each other.\n\nExample: Are Black drivers more likely to be pulled over by police than white drivers?\nWe have two variables: Skin color (black vs white) and being pulled over (true vs. false). We can represent the data in a contingency table (remember: the count() function was helpful to do this in R):\n\n\n\nContingency table for police search data\n\n\nsearched\nBlack\nWhite\nBlack (relative)\nWhite (relative)\n\n\n\n\nFALSE\n36244\n239241\n0.1295298\n0.8550062\n\n\nTRUE\n1219\n3108\n0.0043565\n0.0111075\n\n\n\n\n\n\n\nIf there is no relationship between skin color and being searched, the frequencies of searches would be proportional to the frequencies of skin color. This would be our expected values. We can determine them using probabilities:\n\n\n\n\nBlack\nWhite\n\n\n\n\n\nNot searched\n\\(P(\\neg S)*P(B)\\)\n\\(P(\\neg S)*P(W)\\)\n\\(P(\\neg S)\\)\n\n\nSearched\n\\(P(S)*P(B)\\)\n\\(P(S)*P(W)\\)\n\\(P(S)\\)\n\n\n\n\\(P(B)\\)\n\\(P(W)\\)\n\\(100\\%\\)\n\n\n\nRemember: You can only multiply two probabilities to get their conjoint probability if they are independent. Here, we assume independence to calculate expected values and then check how much our observed values deviate from independence.\n\nProbabilities: Because we expect the variables to be unrelated, we can calculate the joint probability as the product of the marginal probabilities:\n\\(P(X \\cap Y) = P(X) * P(Y)\\)\nMarginal probabilities are the prob of each event occuring regardless of other events (in the margins of the table!)",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#chi²-test-two-variables",
    "href": "W8_ModelingRelationships.html#chi²-test-two-variables",
    "title": "08 Modeling Relationships",
    "section": "Chi² Test: Two Variables",
    "text": "Chi² Test: Two Variables\nIf we compute the standardized squared difference between observed and expected values, we can sum them up to get \\(\\chi^2 = 828.3\\)\n\n\n\nContingency table for police search data\n\n\nsearched\ndriver_race\nn\nexpected\nstdSqDiff\n\n\n\n\nFALSE\nBlack\n36244\n36883.67\n11.09\n\n\nTRUE\nBlack\n1219\n579.33\n706.31\n\n\nFALSE\nWhite\n239241\n238601.33\n1.71\n\n\nTRUE\nWhite\n3108\n3747.67\n109.18\n\n\n\n\n\nWe can then compute the p-value using a chi-squared distribution with \\(DF = (levels_{var1} - 1) * (levels_{var2} - 1) = (2-1) * (2-1) = 1\\)\nWe can also calculate a \\(\\chi^2\\) test easily in R:\n\nchisq.test(summaryDf2wayTable, correct = FALSE)\n\n\n    Pearson's Chi-squared test\n\ndata:  summaryDf2wayTable\nX-squared = 828.3, df = 1, p-value &lt; 2.2e-16\n\n\nThe results indicate that the data are highly unlikely if there was no true relationship between skin color and police searches! We would thus reject \\(H_0\\).\nQuestion: What is the direction of the observed relationship?\n\nDF: computing the expected frequencies requires three values: total number of observations and marg probs each variable. thus only one of the four values can vary freely.",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#standardized-residuals",
    "href": "W8_ModelingRelationships.html#standardized-residuals",
    "title": "08 Modeling Relationships",
    "section": "Standardized Residuals",
    "text": "Standardized Residuals\nIf we want to know not only whether but also how the data differ from what we would expect under \\(H_0\\), we can examine the residuals of the model.\nThe residuals tell us for each cell how much the observed data deviates from the expected data.\nTo make the residuals better comparable, we will look at the standardized residuals:\n\\[\n\\text{standardized residual}_{ij} = \\frac{observed_{ij} - expected_{ij}}{\\sqrt{expected_{ij}}}\n\\]\nwhere \\(i\\) and \\(j\\) are the rows and columns respectively.\n\nNegative residuals indicate an observed value smaller than expected.\n\n\n\nSummary of standardized residuals for police stop data\n\n\nsearched\ndriver_race\nStandardized residuals\n\n\n\n\nFALSE\nBlack\n-3.330746\n\n\nTRUE\nBlack\n26.576456\n\n\nFALSE\nWhite\n1.309550\n\n\nTRUE\nWhite\n-10.449072\n\n\n\n\n\n\nraw residuals depend on number of observations!\nBlack individuals are searched way more often than expected –&gt; helps us intepret significant results.",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#odds-ratios",
    "href": "W8_ModelingRelationships.html#odds-ratios",
    "title": "08 Modeling Relationships",
    "section": "Odds Ratios",
    "text": "Odds Ratios\nAlternatively, we can represent the relative likelihood of different outcomes as odds ratios:\n\\[\nodds_{searched|black} = \\frac{N(searched\\cap black)}{N(\\neg searched \\cap black)} = \\frac{1219}{36244} = 0.034\n\\]\n\\[\nodds_{searched|white} = \\frac{N(searched \\cap white)}{N(\\neg searched \\cap white)} = \\frac{3108}{239241} = 0.013\n\\]\n\\[\nodds\\ ratio = \\frac{odds(searched|black)}{odds(searched|white)} = 2.59\n\\]\nThe odds of being searched are 2.59x higher for Black vs. white drivers!",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#simpsons-paradox",
    "href": "W8_ModelingRelationships.html#simpsons-paradox",
    "title": "08 Modeling Relationships",
    "section": "Simpson’s Paradox",
    "text": "Simpson’s Paradox\nThe Simpson’s Paradox is a great example of misleading summaries.\nIf we look at the baseball data below, we see that David Justice has a better batting average in every single year, but Derek Jeter has a better overall batting average:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlayer\n1995\n\n1996\n\n1997\n\nCombined\n\n\n\n\n\nD. Jeter\n12/48\n.250\n183/582\n.314\n190/654\n.291\n385/1284\n.300\n\n\nD. Justice\n104/411\n.253\n45/140\n.321\n163/495\n.329\n312/1046\n.298\n\n\n\nHow can this be?\n\nSimpson’s Paradox: A pattern is present in the combined dataset but may be different in subsets of the data.\n\n\nHappens if another (lurking) variable changes across subsets (e.g., the number of at-bats, i.e., the denominator).\n\nbatting average: hits/at bats\n1995: in general low batting averages, Justice a lot of at-bats =&gt; diminishes total combined value more strongly than for Jeter.",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#simpsons-paradox-more-intuitive",
    "href": "W8_ModelingRelationships.html#simpsons-paradox-more-intuitive",
    "title": "08 Modeling Relationships",
    "section": "Simpson’s Paradox: More intuitive",
    "text": "Simpson’s Paradox: More intuitive\nWhile typing on a keyboard, what is the relationship between speed and accuracy (or typing errors)?\n(positive, negative, or none)\n\n\n\nIf I try to type faster, I will make more errors =&gt; speed-accuracy trade-off (negative association)\nPeople who are better at typing usually are both faster and make fewer mistakes (positive association)\n\n\n\n\nAnswer: It depends\n\nWithin a person, the relationship between speed and accuracy is negative. My own skill is limited, I can either use it for speed or accuracy.\nBetween persons, the relationship is positive due to inter-individual differences in overall typing skill.\n\n\nUsually, when leveling up, people don’t put all their skill points in only speed or accuracy.",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#example-income-inequality-and-hate-crimes",
    "href": "W8_ModelingRelationships.html#example-income-inequality-and-hate-crimes",
    "title": "08 Modeling Relationships",
    "section": "Example: Income Inequality and Hate Crimes",
    "text": "Example: Income Inequality and Hate Crimes\nWe want to look at a dataset that was used for an analysis of the relationship between income inequality (Gini index) and the prevalence of hate crimes in the USA.\n\nIt looks like there is a positive relationship between the variables. How can we quantify this relationship?",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#covariance-and-correlation",
    "href": "W8_ModelingRelationships.html#covariance-and-correlation",
    "title": "08 Modeling Relationships",
    "section": "Covariance and Correlation",
    "text": "Covariance and Correlation\nCovariance: How much do two variables co-vary with each other?\nVariance (single variable): \\(s^2 = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{N - 1}\\)\nCovariance (two variables): \\(covariance = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{N - 1}\\)\n(Side note: Variance is the covariance of a variable with itself.)\n\n\n\n“Is there a relation between the deviations of two different variables (from their means) across observations?”\n\n\nWill be far from 0 if data points share a relationship. Positive values for same direction, negative values for opposite directions.\n\n\nCovariance varies with overall level of variance in the data, so not that useful to describe relationships in general.\n\n\n\n\nCorrelation coefficient (Pearson correlation): Scales the covariance by the standard deviations of the two variables and thus standardizes it (=&gt; \\(r\\) varies between \\(-1\\) and \\(1\\) =&gt; comparability!)\n\\[\nr = \\frac{covariance}{s_xs_y} = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{(N - 1)s_x s_y}\n\\]\n\nCovariance depends on dataset!",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#hypothesis-testing-for-correlations",
    "href": "W8_ModelingRelationships.html#hypothesis-testing-for-correlations",
    "title": "08 Modeling Relationships",
    "section": "Hypothesis Testing for Correlations",
    "text": "Hypothesis Testing for Correlations\nThe correlation between income inequality and hate crimes is \\(r = .42\\), which seems to be a reasonably strong (positive) relationship.\n\nWe can test whether such a relationship could occur by chance, even if there is actually no relationship. In this case, our null hypothesis is \\(H_0: r = 0\\).\n\n\nTo test whether there is a significant relationship, we can transform the \\(r\\) statistic into a \\(t\\) statistic:\n\\[\nt_r = \\frac{r\\sqrt{N-2}}{\\sqrt{1-r^2}}\n\\]\nWe can compute this easily in R:\n\n# perform correlation test on hate crime data\ncor.test(\n  hateCrimes$avg_hatecrimes_per_100k_fbi,\n  hateCrimes$gini_index\n)\n\n\n    Pearson's product-moment correlation\n\ndata:  hateCrimes$avg_hatecrimes_per_100k_fbi and hateCrimes$gini_index\nt = 3.2182, df = 48, p-value = 0.002314\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.1619097 0.6261922\nsample estimates:\n      cor \n0.4212719 \n\n\nThe p-value is quite small, which indicates that it is quite unlikely to find an \\(r\\) value this high or more extreme. We would thus reject \\(H_0: r = 0\\).\nSide note: There are more beautiful / convenient ways to do this in R. We will cover this in the next session.\n\nsubsetting with $!",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#robust-correlations",
    "href": "W8_ModelingRelationships.html#robust-correlations",
    "title": "08 Modeling Relationships",
    "section": "Robust Correlations",
    "text": "Robust Correlations\nIn the plot, we have seen an outlier: The District of Columbia was quite different from the other data points.\n\nThe Pearson’s correlation coefficient \\(r\\) is highly sensitive to outliers, see this hypothetical example:",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#robust-correlation-2",
    "href": "W8_ModelingRelationships.html#robust-correlation-2",
    "title": "08 Modeling Relationships",
    "section": "Robust Correlation 2",
    "text": "Robust Correlation 2\nWe can use a different correlation coefficient, though, which is less sensitive to outliers: Spearman correlation.\nIt is based on ranking (i.e., ordering) the data and using the ranks (instead of the original data) for the correlation.\n\ncor.test(hateCrimes$avg_hatecrimes_per_100k_fbi,\n  hateCrimes$gini_index,\n  method = \"spearman\")\n\n\n    Spearman's rank correlation rho\n\ndata:  hateCrimes$avg_hatecrimes_per_100k_fbi and hateCrimes$gini_index\nS = 20146, p-value = 0.8221\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n       rho \n0.03261836 \n\n\nThe correlation has now dropped from \\(.42\\) to \\(.03\\) and is no longer significant. The influence of the one outlier has been greatly diminished.\nOf course, a ranked correlation can also obscure true effects that critically depend on the scale of the data. When in doubt, try both and discuss reasons for differences.\n\nWithout outlier: perfectly negative correlation, with outlier: highly positive!",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#correlation-and-causation",
    "href": "W8_ModelingRelationships.html#correlation-and-causation",
    "title": "08 Modeling Relationships",
    "section": "Correlation and Causation",
    "text": "Correlation and Causation\nDoing a well controlled, randomized experiment (RCT) is extremely helpful to gather causal evidence.\nHowever, it is not always possible or ethical to do an experiment!\nWe can still collect (observational) data. However, if we correlate two variables, we can’t conclude that one causes the other: They might be related but there could also be a third variable that causes both (or even more complex causal structures).\n\nIf we have observational data, causal graphs can be helpful for interpreting causality:\n\n\n\n\n\n\n\n\n\n\n\n\nCircle: observed variables\nrectangle: latent (unobservable) variable\n\nGreen arrow: positive relationship,\nred: negative\nExamGrade and FinishTime seem negatively related if we ignore other variables!\n(“Hand in your exam early to improve your grade!”)\nKnowledge = theoretical mediator\nStudyTime = proxy for knowledge\nIf we control for StudyTime (which approximates individual knowledge), we find out that ExamGrade and FinishTime are (causally) unrelated!\n\n\n\nWe have briefly talked about causation in week 1\nThink of data/questions where it is impossible/unethical!\nabused children and brain development!\n(3rd var: family stress -&gt; less intellectual engagement –&gt; poorer brain dev)\nCorrelation: s.th. is probably causing s.th. else but not clear what causes what!\nDAG:\ngreen: pos, red: net\ncircle: observed, rect: latent (unobservable)\nExamGrade and FinishTime seem neg related if we ignore others\nknowledge = mediates\nStudyTime = proxy for knowledge, if we “control” it/hold it constant/only use people with same amount, we would see that EG and FT are unrelated!",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#testing-a-single-mean-one-sample-t-test",
    "href": "W8_ModelingRelationships.html#testing-a-single-mean-one-sample-t-test",
    "title": "08 Modeling Relationships",
    "section": "Testing a Single Mean (One sample t-Test)",
    "text": "Testing a Single Mean (One sample t-Test)\nWe sometimes might want to know whether a single value, the mean of a group, differs from a specific value, e.g. whether the blood pressure in the sample differs from or is bigger than 80.\n\nWe can test this using the \\(t\\)-test, which we have already encountered in the “Hypothesis Testing” session!\n\\[\nt = \\frac{\\hat{X} - \\mu}{SEM}\n\\]\n\\[\nSEM = \\frac{\\hat{\\sigma}}{\\sqrt{n}}\n\\]\n\\(\\hat{X}\\) is the mean of our sample, \\(\\mu\\) the hypothesized population mean (e.g. the value we want to test against, such as 80 for the blood pressure example).\nWe can easily calculate the \\(t\\)-test in R:\n\nt.test(x=NHANES_adult$BPDiaAve, mu=80, alternative='greater')\n\n\n    One Sample t-test\n\ndata:  NHANES_adult$BPDiaAve\nt = -55.23, df = 4599, p-value = 1\nalternative hypothesis: true mean is greater than 80\n95 percent confidence interval:\n 69.1588     Inf\nsample estimates:\nmean of x \n 69.47239 \n\n\n\n(The \\(t\\) statistic thus asks how large the deviation of sample mean from the expected value with respect to the sampling variability of the mean!)\nWe tested the one-sided alternative (&gt;) and the blood pressure in the sample is much lower than 80, so it is far from significance\nWe can’t interpret the \\(p\\)-value as evidence in favor of \\(H_0\\) (i.e. larger \\(p\\)-value! vs non.sign) –&gt; Bayes!",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#comparing-two-means-two-sample-t-test",
    "href": "W8_ModelingRelationships.html#comparing-two-means-two-sample-t-test",
    "title": "08 Modeling Relationships",
    "section": "Comparing Two Means (Two sample t-Test)",
    "text": "Comparing Two Means (Two sample t-Test)\nMore often, we want to know whether there is a difference between the means of two groups.\nExample: Do regular marijuana smokers watch more television?\nIn this example, we expect that they watch more TV, which leads us to the following directional hypotheses:\n\\(H_0\\) = marijuana smokers watch less or equally often TV,\n\\(H_A\\) = marijuana smokers watch more TV.\n\nIf the observations are independent (i.e. you really have two unrelated groups), you can use a very similar formula to calculate the \\(t\\) statistic:\n\\[\nt = \\frac{\\bar{X_1} - \\bar{X_2}}{\\sqrt{\\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}}}\n\\]\nwhereby \\(\\hat{X_1}\\) and \\(\\hat{X_2}\\) are the group means, \\(S_1^2\\) and \\(S_2^2\\) the group variances, and \\(n_1\\) and \\(n_2\\) the group sizes.\nHere are the results from a one-tailed \\(t\\)-test in R:\n\n\n\n    Welch Two Sample t-test\n\ndata:  TVHrsNum by RegularMarij\nt = -1.2147, df = 116.9, p-value = 0.1135\nalternative hypothesis: true difference in means between group No and group Yes is less than 0\n95 percent confidence interval:\n       -Inf 0.09866006\nsample estimates:\n mean in group No mean in group Yes \n          2.02963           2.30000 \n\n\n\nDV: continuous, IV: categories\nn.s. (differs from book), although mean is higher in Yes, not significantly different!",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#comparing-dependent-observations-paired-t-test",
    "href": "W8_ModelingRelationships.html#comparing-dependent-observations-paired-t-test",
    "title": "08 Modeling Relationships",
    "section": "Comparing Dependent Observations (Paired t-test)",
    "text": "Comparing Dependent Observations (Paired t-test)\nIf we have repeated observations of the same subject (i.e., a within-subject design), we might want to compare the same subject thus on multiple, repeated measurements.\n\nIf we want to test whether blood pressure differs between the first and second measurement session across individuals, we can use a paired \\(t\\)-test.\nIn R, we would run a paired-samples \\(t\\)-test like this:\n\nwith(NHANES_sample, t.test(BPSys1, BPSys2, paired = TRUE))\n\n\n    Paired t-test\n\ndata:  BPSys1 and BPSys2\nt = 2.7369, df = 199, p-value = 0.006763\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.2850857 1.7549143\nsample estimates:\nmean difference \n           1.02 \n\n\nSide note: A paired \\(t\\)-test is equivalent to a one-sample \\(t\\)-test, when using the paired differences as \\(\\hat{X}\\) and testing them against a value of 0 (if we expect no difference for \\(H_0\\)) for \\(\\mu\\).\n\nimportant: If we run an independent sample t-test, it would probably be n.s.! (check out book)",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#comparing-more-than-two-means",
    "href": "W8_ModelingRelationships.html#comparing-more-than-two-means",
    "title": "08 Modeling Relationships",
    "section": "Comparing More Than Two Means",
    "text": "Comparing More Than Two Means\nOften, we want to compare more than two means, e.g. different treatment groups or timepoints.\nExample: Different treatments for blood pressure",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#analysis-of-variance-anova",
    "href": "W8_ModelingRelationships.html#analysis-of-variance-anova",
    "title": "08 Modeling Relationships",
    "section": "Analysis of Variance (ANOVA)",
    "text": "Analysis of Variance (ANOVA)\n\\(H_0\\): all means are equal\n\\(H_A\\): not all means are equal (e.g. at least one differs)\n\nWe can partition the variance in the data into different parts:\n\\(SS_{total}\\) = total variance in the data\n\\(SS_{model}\\) = Variance explained by the model*\n\\(SS_{error}\\) = Variance not explained by the model\n\n\nWe can use those to calculate the mean squares for the model and the error:\n\\(MS_{model} =\\frac{SS_{model}}{df_{model}}= \\frac{SS_{model}}{p-1}\\) (\\(p\\) is the number of factor levels)\n\\(MS_{error} = \\frac{SS_{error}}{df_{error}} = \\frac{SS_{error}}{N - p}\\)\n\n\nWe want to test whether the variance accounted for by the model is greater than expected by chance (\\(H_0\\): no difference).\n\n\nquite common analysis! We will just scratch the surface\n\n\n\n\\(SS\\) = Sum of Squares, remember that the variance is the sum of the squared deviation of an observation to the mean\n\\(MS\\) = Mean (Sum of) Squares: How much variance per degree of freedom?\n*more on that in the next session!",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#anova-2",
    "href": "W8_ModelingRelationships.html#anova-2",
    "title": "08 Modeling Relationships",
    "section": "ANOVA 2",
    "text": "ANOVA 2\nIn R, we would run an ANOVA like this:\n\ndf &lt;-\n  df %&gt;% \n  mutate(group2=fct_relevel(group,c(\"placebo\",\"drug1\",\"drug2\")))\n# reorder the factor levels so that \"placebo\" is the control condition/intercept!\n  \n \n# test model without separate duymmies\nlmResultAnovaBasic &lt;- lm(sysBP ~ group2, data=df)\nsummary(lmResultAnovaBasic)\n\n\nCall:\nlm(formula = sysBP ~ group2, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-29.0838  -7.7452  -0.0978   7.6872  23.4313 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  141.595      1.656  85.502  &lt; 2e-16 ***\ngroup2drug1  -10.237      2.342  -4.371 2.92e-05 ***\ngroup2drug2   -2.027      2.342  -0.865    0.389    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.936 on 105 degrees of freedom\nMultiple R-squared:  0.1695,    Adjusted R-squared:  0.1537 \nF-statistic: 10.71 on 2 and 105 DF,  p-value: 5.83e-05\n\n# emm.result &lt;- emmeans(lmResultAnovaBasic, \"group\" )",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#anova-3",
    "href": "W8_ModelingRelationships.html#anova-3",
    "title": "08 Modeling Relationships",
    "section": "ANOVA 3",
    "text": "ANOVA 3\n\n\n\nCall:\nlm(formula = sysBP ~ group2, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-29.0838  -7.7452  -0.0978   7.6872  23.4313 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  141.595      1.656  85.502  &lt; 2e-16 ***\ngroup2drug1  -10.237      2.342  -4.371 2.92e-05 ***\ngroup2drug2   -2.027      2.342  -0.865    0.389    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.936 on 105 degrees of freedom\nMultiple R-squared:  0.1695,    Adjusted R-squared:  0.1537 \nF-statistic: 10.71 on 2 and 105 DF,  p-value: 5.83e-05\n\n\nWe can see a \\(t\\)-test for every drug. This is because the factor group2 is automatically dummy coded by R: We always compare one drug against the intercept, which is the mean of the placebo group!\nThe \\(t\\)-test shows us that drug1 differs significantly from placebo but not drug2.\nThe \\(F\\)-statistic (also called omnibus test) actually tests our overall hypothesis of no difference between conditions.",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W8_ModelingRelationships.html#anova-side-notes",
    "href": "W8_ModelingRelationships.html#anova-side-notes",
    "title": "08 Modeling Relationships",
    "section": "ANOVA side notes",
    "text": "ANOVA side notes\nIn R, there are different functions that you can use to run an ANOVA besides lm(), which have different advantages and disadvantages (functions like ezANOVA() from the ez packages or functions from the afex package might be helpful).\nJust like with the \\(t\\)-test, there’s also a distinction between between-subjects and within-subjects (i.e., repeated measures ANOVA). The previous example contained just between-subjects measures, i.e. different groups without repeated measures. We will talk about other options later, but see the packages mentioned above as well for functional parameters called, e.g., within.\n\nDummy coded (explicitly):\n\n\n\nCall:\nlm(formula = sysBP ~ d1 + d2, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-29.0838  -7.7452  -0.0978   7.6872  23.4313 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  141.595      1.656  85.502  &lt; 2e-16 ***\nd1           -10.237      2.342  -4.371 2.92e-05 ***\nd2            -2.027      2.342  -0.865    0.389    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.936 on 105 degrees of freedom\nMultiple R-squared:  0.1695,    Adjusted R-squared:  0.1537 \nF-statistic: 10.71 on 2 and 105 DF,  p-value: 5.83e-05\n\n\n\\(t\\)-tests: dummy coded = 0 vs. 1\n- control for multiple comparisons! (later)\n- if we wanted to compare the two drugs, we’d have to dummy code/relevel differently or use follow-up comparisons like with emmeans()\n\\(F\\): Is our model better than a simple model that just includes the intercept? In this case placebo…",
    "crumbs": [
      "08 Modeling Relationships"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#set-up",
    "href": "W9_FirstAnalysisR.html#set-up",
    "title": "09 Statistical Analyses in R",
    "section": "Set Up",
    "text": "Set Up\n\nOpen RStudio and load your Biostats R project. Create a new script called DataAnalysis1.R.\nInstall and load new packages you’ll need: car, effectsize, and apa.",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#one-sample-chi²-test",
    "href": "W9_FirstAnalysisR.html#one-sample-chi²-test",
    "title": "09 Statistical Analyses in R",
    "section": "One Sample Chi²-Test",
    "text": "One Sample Chi²-Test\n\nlibrary(tidyverse) \n\n# Input data into R\nlever_presses &lt;- tibble(levers=c(rep(\"blue\", 5), rep(\"green\", 4), rep(\"red\", 11))) %&gt;% #data in usual format\n  count(levers) #convert to a frequency table\n\n# run Chi² test\nchi2_lever &lt;- chisq.test(lever_presses %&gt;% pivot_wider(names_from=\"levers\", values_from=\"n\")) #wide format needed\n#chi2_lever &lt;- chisq.test(tibble(blue=5, green=4, red=11)) #enter data directly as summary table\n\nchi2_lever %&gt;% apa::chisq_apa() #output results\n\nchi^2(2) = 4.30, p = .116\n\n# add expected count and residuals to data\nlever_presses %&gt;% mutate(expected = chi2_lever$expected, \n                         residuals = chi2_lever$residuals)\n\n# A tibble: 3 × 4\n  levers     n expected residuals\n  &lt;chr&gt;  &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 blue       5     6.67    -0.645\n2 green      4     6.67    -1.03 \n3 red       11     6.67     1.68 \n\n\n\nIs sample size not important for significance here? \\[\\chi^2 = \\sum\\frac{(Observed - Expected)^2}{Expected}\\] More observations =&gt; easier to see greater absolute difference between observed and expected values =&gt; gets squared and therefore “outcompetes” denominator (what about expected reductions in sampling error?)",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#chi²-test-2",
    "href": "W9_FirstAnalysisR.html#chi²-test-2",
    "title": "09 Statistical Analyses in R",
    "section": "Chi²-Test 2",
    "text": "Chi²-Test 2\nWe can also run a Chi²-test for two variables, such as if we want to know whether the lever presses differ per group.\nLet’s say we have a treatment and a control group and we record the different lever presses:\n\n\n\nGroup\nBlue\nGreen\nRed\nTotals\n\n\n\n\nTreatment\n3\n12\n5\n20\n\n\nControl\n5\n4\n11\n20\n\n\nTotals\n8\n16\n16\n40\n\n\n\nRemember: We use the assumption of independence to calculate the expected values.\n\n\nlever_presses2 = tibble(group=\"treatment\", blue=3, green=12, red=5) %&gt;% \n  bind_rows(tibble(group=\"control\", blue=5, green=4, red=11)) #clearest way to manually input data\n#for long data, you create the frequency table identically to previous slide but with: count(group, levers)\n\nchisq.test(lever_presses2 %&gt;% column_to_rownames(\"group\")) %&gt;% apa::chisq_apa()\n\nchi^2(2) = 6.75, p = .034",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#assumptions-of-chi²-tests",
    "href": "W9_FirstAnalysisR.html#assumptions-of-chi²-tests",
    "title": "09 Statistical Analyses in R",
    "section": "Assumptions of Chi²-Tests",
    "text": "Assumptions of Chi²-Tests\n\n\nRandom sample\nCategorical variables, i.e., counts within (combinations of) groups\nExpected cell count: &gt;5 counts per cell\nIndependence: Each observation is independent of the others, e.g. there are no repeated measurements/paired data (within-subjects data are correlated!)\n\n\n\nIn the case of the last analysis, we got a warning because the expected cell sizes were too small. In this case, it is better to use Fisher’s exact test:\n\nfisher.test(lever_presses2 %&gt;% column_to_rownames(\"group\"))\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  lever_presses2 %&gt;% column_to_rownames(\"group\")\np-value = 0.04168\nalternative hypothesis: two.sided",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#t-test-setup",
    "href": "W9_FirstAnalysisR.html#t-test-setup",
    "title": "09 Statistical Analyses in R",
    "section": "t-test setup",
    "text": "t-test setup\nTo run a t-Test, let’s first simulate data. What happens here?\n\nset.seed(31415)\nsim_data_t &lt;- tibble(\n  group = rep(c(\"treatment\", \"control\"), each=20),\n  reaction_times = c(rnorm(20, 400, 100), rnorm(20, 450, 100)))",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#t-test",
    "href": "W9_FirstAnalysisR.html#t-test",
    "title": "09 Statistical Analyses in R",
    "section": "t-Test",
    "text": "t-Test\nWe can use the formula notation to run the t-test. This notation usually looks like this:\ndependent variable ~ independent variable.\nReplace the NULLs:\n\nt.test(NULL ~ NULL,\n       data = NULL,\n       alternative = NULL,\n       paired = NULL) \n\n\n\nt.test(reaction_times ~ group,\n       data = sim_data_t,\n       alternative = \"greater\", #depends on ALPHABETICAL order of groups in data!\n       #paired = FALSE # this is the default, so no need to specify it\n)\n\n\n    Welch Two Sample t-test\n\ndata:  reaction_times by group\nt = 1.9841, df = 34.42, p-value = 0.02763\nalternative hypothesis: true difference in means between group control and group treatment is greater than 0\n95 percent confidence interval:\n 10.02639      Inf\nsample estimates:\n  mean in group control mean in group treatment \n               468.0592                400.3289 \n\n\n\n\nAs you can see in the output, R automatically chose to run Welch’s t-test, which does not assume variance homogeneity in contrast to Student’s t-test. For the latter, you can add the function parameter var.equal = TRUE\n\nWhen changing the name “treatment” to “a”, the results change:\n\nt.test(reaction_times ~ group,\n       data = sim_data_t %&gt;% mutate(group = ifelse(group==\"treatment\", \"a\", group)),\n       alternative = \"greater\", #depends on order of groups in data! 1st group &gt; 2nd group\n       var.equal = TRUE) %&gt;% apa::t_apa()\n\nt(38) = -1.98, p = .973, d = -0.63",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#t-test-alternatives",
    "href": "W9_FirstAnalysisR.html#t-test-alternatives",
    "title": "09 Statistical Analyses in R",
    "section": "t-Test: alternatives",
    "text": "t-Test: alternatives\nYou can also supply two vectors of numerical values for the groups:\n\nt.test(x = sim_data_t %&gt;% filter(group==\"treatment\") %&gt;% pull(reaction_times),\n       y = sim_data_t %&gt;% filter(group==\"control\") %&gt;% pull(reaction_times),\n       alternative = \"less\") #more intuitive now because you can filter for treatment first\n\n\n    Welch Two Sample t-test\n\ndata:  sim_data_t %&gt;% filter(group == \"treatment\") %&gt;% pull(reaction_times) and sim_data_t %&gt;% filter(group == \"control\") %&gt;% pull(reaction_times)\nt = -1.9841, df = 34.42, p-value = 0.02763\nalternative hypothesis: true difference in means is less than 0\n95 percent confidence interval:\n      -Inf -10.02639\nsample estimates:\nmean of x mean of y \n 400.3289  468.0592 \n\n\n\nMore useful output with apa package (only for Student’s t-tests):\n\nt.test(x = sim_data_t %&gt;% filter(group==\"treatment\") %&gt;% pull(reaction_times),\n       y = sim_data_t %&gt;% filter(group==\"control\") %&gt;% pull(reaction_times),\n       alternative = \"less\", \n       var.equal = T) %&gt;% \n  apa::t_apa(es_ci=T) #optional: confidence interval around effect size\n\nt(38) = -1.98, p = .027, d = -0.63 [-1.26; 0.01]\n\n\n\n\nFor paired t-tests, you can also work with the wide format of data (advantage: missing values become explicit):\n\nsim_data_t_wide = sim_data_t %&gt;% mutate(subject=rep.int(1:(n()/2), 2)) %&gt;% \n  pivot_wider(names_from=\"group\", values_from=\"reaction_times\")\nt.test(x = sim_data_t_wide %&gt;% pull(treatment),\n       y = sim_data_t_wide %&gt;% pull(control),\n       alternative = \"less\", \n       paired = T) %&gt;% \n  apa::t_apa(es_ci=T) #optional: confidence interval around effect size\n\nt(19) = -1.98, p = .031, d = -0.44 [-0.90; 0.02]",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#assumptions-of-t-tests",
    "href": "W9_FirstAnalysisR.html#assumptions-of-t-tests",
    "title": "09 Statistical Analyses in R",
    "section": "Assumptions of t-Tests",
    "text": "Assumptions of t-Tests\nBefore we run a t-test, we also want to check the assumptions for violations:\n\n\nThe dependent variable is continuous (otherwise: chi²-test)\nThe data are independent (otherwise: paired sample t-test)\nThe variance between the groups is homogeneous (only for Student’s t-test, R uses Welch’s test by default)\nThe residuals are normally distributed for each group (otherwise: wilcox.test)\n\n\n\nOftentimes, the last assumption is misquoted as: “The dependent variable needs to be normally distributed”.\nIn fact, only its sampling distribution needs to be (blue vs. grey distribution in the lecture on sampling [direct link]), which will always be the case for big enough samples due to the central limit theorem.",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#assumptions-of-t-tests-2",
    "href": "W9_FirstAnalysisR.html#assumptions-of-t-tests-2",
    "title": "09 Statistical Analyses in R",
    "section": "Assumptions of t-Tests 2",
    "text": "Assumptions of t-Tests 2\nTest for normality of residuals (for both groups): If points fall along the line nicely, assumption is met.\n\n\ntreatment &lt;- sim_data_t %&gt;%\n  filter(group == \"treatment\") %&gt;%\n  mutate(group_resid = \n           reaction_times - mean(reaction_times)) %&gt;%\n  pull(group_resid)\n\n#base R QQ plot\nqqnorm(treatment)\nqqline(treatment)\n\n\n\n\n\n\n\n\n\n\n\n\ncontrol &lt;- sim_data_t %&gt;%\n  filter(group == \"control\") %&gt;%\n  mutate(group_resid = reaction_times - mean(reaction_times)) %&gt;%\n  pull(group_resid)\n\n#car's version highlighting (and returning) problematic values\ncar::qqPlot(control)\n\n\n\n\n\n\n\n\n\n[1] 18  4",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#assumptions-of-t-tests-3",
    "href": "W9_FirstAnalysisR.html#assumptions-of-t-tests-3",
    "title": "09 Statistical Analyses in R",
    "section": "Assumptions of t-Tests 3",
    "text": "Assumptions of t-Tests 3\nAlternatively, we can also run a Shapiro-Wilk test to test for deviations from normality:\n\nshapiro.test(x = treatment)\n\n\n    Shapiro-Wilk normality test\n\ndata:  treatment\nW = 0.91403, p-value = 0.0761\n\nshapiro.test(x = control)\n\n\n    Shapiro-Wilk normality test\n\ndata:  control\nW = 0.96812, p-value = 0.7147\n\n\nIf the test is non-significant, then we can conclude that normality of residuals is not violated.\n\n\nTransform your data to try and normalise the distribution. Not usually recommended these days but some still use it.\nUse a non-parametric test. The non-parametric equivalent of the independent t-test is the Mann-Whitney and the equivalent of the paired-samples t-test is the Wilcoxon signed-ranks test. Though more modern permutation tests are better.\nDo nothing. Delacre, Lakens & Leys, 2017 argue that with a large enough sample (&gt;30), the Welch test is robust to deviations from assumptions. With very large samples normality is even less of an issue, so design studies with large samples.",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#assumptions-of-the-paired-samples-t-test",
    "href": "W9_FirstAnalysisR.html#assumptions-of-the-paired-samples-t-test",
    "title": "09 Statistical Analyses in R",
    "section": "Assumptions of the Paired-Samples t-Test",
    "text": "Assumptions of the Paired-Samples t-Test\n\nThe data are continuous.\nAll participants should appear in both conditions/groups.\nThe residuals are normally distributed.\n\n\nA paired-samples t-test actually tests whether the difference between two measurements is significantly different from 0 (= no difference/effect).\nIn our example data, this means that the test values are subtracted from the baseline values, and this difference is used as data.\nTo test the assumption that residuals are normally distributed, we thus calculate the residuals as follow:\n\ngaze_residual &lt;- gaze %&gt;%\n  mutate(diff = baseline - test) %&gt;%\n  mutate(group_resid = diff - mean(diff))\n\nqqPlot(gaze_residual$group_resid)\n\n\n\n\n\n\n\n\n[1] 22 29\n\nshapiro.test(gaze_residual$group_resid)\n\n\n    Shapiro-Wilk normality test\n\ndata:  gaze_residual$group_resid\nW = 0.97818, p-value = 0.7451",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#descriptives-visualization",
    "href": "W9_FirstAnalysisR.html#descriptives-visualization",
    "title": "09 Statistical Analyses in R",
    "section": "Descriptives & Visualization",
    "text": "Descriptives & Visualization\nFor the visualization, we need the data in long format (this is identical for between-subject groups):\n\n\ngaze_tidy &lt;- gaze %&gt;%\n  pivot_longer(names_to = \"phase\", \n               values_to = \"looking_time\", \n               cols = c(baseline, test))\n\n# boxplot\ngaze_tidy %&gt;% \n  ggplot(aes(x=phase, y=looking_time)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\nWe can also calculate the means and SDs per phase:\n\n\ngaze_tidy %&gt;% \n  summarise(mean_looking = mean(looking_time),\n            sd_looking = sd(looking_time),\n            n = n(),\n            .by = phase)\n\n\n# A tibble: 2 × 4\n  phase    mean_looking sd_looking     n\n  &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt;\n1 baseline        0.521      0.177    32\n2 test            0.593      0.179    32",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#paired-samples-t-test-in-r",
    "href": "W9_FirstAnalysisR.html#paired-samples-t-test-in-r",
    "title": "09 Statistical Analyses in R",
    "section": "Paired Samples t-Test in R",
    "text": "Paired Samples t-Test in R\nAny ideas how you would specify the paired samples t-test in R?\n\n\nwith(gaze, t.test(NULL, NULL,\n                  paired = NULL,\n                  alternative = NULL))\n\n\n\n\nwith(gaze, t.test(baseline, test,\n                  paired = TRUE,\n                  alternative = \"two.sided\"))\n\n\n    Paired t-test\n\ndata:  baseline and test\nt = -2.4164, df = 31, p-value = 0.02175\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.13349698 -0.01129217\nsample estimates:\nmean difference \n    -0.07239458",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#effect-size-for-the-t-test",
    "href": "W9_FirstAnalysisR.html#effect-size-for-the-t-test",
    "title": "09 Statistical Analyses in R",
    "section": "Effect Size for the t-Test",
    "text": "Effect Size for the t-Test\nYou can (and should!) of course calculate and report effect sizes for your test statistics to get an impression of how practically relevant the effect is.\nFor the t-tests, you would calculate Cohen’s d (using the function from the effectsize package):\n\nwith(gaze, effectsize::cohens_d(baseline, test, paired=T))\n\nCohen's d |         95% CI\n--------------------------\n-0.43     | [-0.79, -0.06]\n\n\n\n\nOr just use the apa package and you get everything in one go:\n\nwith(gaze, #the with function allows to call columns as if they were variables (but pipe function doesn't work with it)\n     t.test(baseline, test, paired = TRUE)) %&gt;% \n  apa::t_apa(es_ci=T)\n\nt(31) = -2.42, p = .022, d = -0.43 [-0.79; -0.06]",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#summary-optional-activity",
    "href": "W9_FirstAnalysisR.html#summary-optional-activity",
    "title": "09 Statistical Analyses in R",
    "section": "Summary: Optional Activity",
    "text": "Summary: Optional Activity\n\n\nMost things are similar between independent and dependent sample t-tests\nMake sure to include paired=T for repeated measures to get correct results\nRecommendation: Use apa::t_apa() with es.ci=T to get (most of) the information you need\nIt is often a good idea to also report means and standard deviations per group (summarise with .by argument)\nPlotting: Unfortunately, (between subjects) confidence intervals are not diagnostic for the significance of dependent samples. Instead, we need the confidence interval around the paired differences (i.e., the within subject changes). Since this is not easy to do and there is little consensus yet, I will just raise awareness here.",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#correlation-test",
    "href": "W9_FirstAnalysisR.html#correlation-test",
    "title": "09 Statistical Analyses in R",
    "section": "Correlation Test",
    "text": "Correlation Test\nWith these data, we might be interested in whether there is a relationship between the two measures of gaze, i.e., whether those children who looked at the stranger more at baseline would also be the ones who looked at the stranger more often at the follow-up test (here: indicating stability of preferences).\n\nSimilar to the paired t-Test, the continuous variables are also “paired” within subjects. Thus, we can a similar syntax that is easier for a wide format of data (gaze instead of gaze_tidy):\n\ncor.test(x = gaze %&gt;% pull(baseline), \n         y = gaze %&gt;% pull(test), \n         method = \"pearson\", \n         alternative = \"two.sided\")\n\n\n    Pearson's product-moment correlation\n\ndata:  gaze %&gt;% pull(baseline) and gaze %&gt;% pull(test)\nt = 3.5686, df = 30, p-value = 0.00123\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.2435655 0.7515352\nsample estimates:\n      cor \n0.5458966 \n\n\nNote: We don’t have to indicate paired=T because correlations only work for paired values.",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#correlations-write-up",
    "href": "W9_FirstAnalysisR.html#correlations-write-up",
    "title": "09 Statistical Analyses in R",
    "section": "Correlations: Write Up",
    "text": "Correlations: Write Up\nOnce again, the apa package offers help to summarize the results:\n\ncor.test(x = gaze %&gt;% pull(baseline), \n         y = gaze %&gt;% pull(test), \n         method = \"pearson\", \n         alternative = \"two.sided\") %&gt;% \n  apa::cor_apa(r_ci=T)\n\nr(30) = .55 [.24; .75], p = .001\n\n\n\nYou can even use report() to get an automatic suggestion of how to report the results (works with a lot of different models!).\n\nlibrary(report)\nwith(gaze, cor.test(x = baseline, \n                    y = test, \n                    method = \"pearson\", \n                    alternative = \"two.sided\")) %&gt;% \n  report()\n\nEffect sizes were labelled following Funder's (2019) recommendations.\n\nThe Pearson's product-moment correlation between baseline and test is positive,\nstatistically significant, and very large (r = 0.55, 95% CI [0.24, 0.75], t(30)\n= 3.57, p = 0.001)\n\n\n\nWe mainly use this dataset so that you don’t have to load another one, but in practice you would either run a t-test or a correlation, not necessarily both!\nThe t-tests answers whether there is a change across all participants between the two time points, the correlation answers the question whether those who score high at one time point would also score high at the next (regardless of overall level).",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#correlations-notes",
    "href": "W9_FirstAnalysisR.html#correlations-notes",
    "title": "09 Statistical Analyses in R",
    "section": "Correlations: Notes",
    "text": "Correlations: Notes\nThere are also some assumptions that need to be checked:\n\nAre the data continuous? (for ordinal values: Spearman’s rho)\nIs there a data point for each participant on both variables? (paired values)\nAre the residuals normally distributed?\nDoes the relationship between variables appear linear?\nDoes the spread have homoscedasticity? (Variance of residuals should be constant across x-axis)\nNote: This is very hard to judge by eye and is not the same as the confidence band around the regression line to show constant width. In fact, the latter will always be larger near the ends of the regression line due to how it is computed.\n\nPlease see the text book for how to test these assumptions.\n\nYou should - as always - report the descriptive statistics (summary statistics such as mean and SD).\n\n\nYou can also report and visualize multiple correlations at once, using a scatterplot matrix or heatmaps. Check out e.g. the corrplot package!",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#one-way-anova",
    "href": "W9_FirstAnalysisR.html#one-way-anova",
    "title": "09 Statistical Analyses in R",
    "section": "One-Way ANOVA",
    "text": "One-Way ANOVA\nFor this activity, we will use data from a study about memory of traumatic events (see the textbook for details). In short, the authors of the paper were interested to find out whether:\n\nreconsolidation - the process during which memories become malleable when recalled - can be blocked using a cognitive task and whether such an approach can reduce these unbidden intrusions.\n\n\n\nDownload the data James Holmes_Expt 2_DATA.csv. This time, put it in a subfolder of your project called “Data”.\nAdd a column to the dataframe called subject that equals the row_number(), which will act as a participant ID.\nrename(): Days_One_to_Seven_Image_Based_Intrusions_in_Intrusion_Diary to intrusions.\nSelect only the columns subject, Condition and intrusions.\nChange the variable Condition from numeric to a factor using as.factor()\n\n\n\n\nlibrary(tidyverse)\n\ndat &lt;- read_csv(\"Data/James Holmes_Expt 2_DATA.csv\") %&gt;% \n  rownames_to_column(\"subject\") %&gt;% #mutate(subject = 1:n()) %&gt;% \n  rename(intrusions = Days_One_to_Seven_Image_Based_Intrusions_in_Intrusion_Diary) %&gt;% \n  select(subject, Condition, intrusions) %&gt;% \n  mutate(Condition = as.factor(Condition))\n\n\nwe will today only look at one-way anovas! Next week we will cover the case when we have more than one IV/predictor!",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#one-way-anova-2",
    "href": "W9_FirstAnalysisR.html#one-way-anova-2",
    "title": "09 Statistical Analyses in R",
    "section": "One-Way ANOVA 2",
    "text": "One-Way ANOVA 2\nCreate summary/descriptive statistics and visualize the data.\nAs summary statistics, we want the mean, SD, and SE.\n\nse = function(x, na.rm = FALSE) { sd(x, na.rm) / sqrt(if(!na.rm) length(x) else sum(!is.na(x))) }\n\nsum_dat &lt;- dat %&gt;%\n  summarise(mean = mean(intrusions),\n            sd = sd(intrusions),\n            se = se(intrusions),\n            .by = Condition)\nprint(sum_dat)\n\n# A tibble: 4 × 4\n  Condition  mean    sd    se\n  &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 1          5.11  4.23 0.996\n2 2          1.89  1.75 0.411\n3 3          3.89  2.89 0.681\n4 4          4.83  3.33 0.785\n\n\nNote: The names of the factor levels are missing. If we wanted to plot the data, we should have added them in the previous step. For brevity, we will not do it this time.\n\n\ndon’t use a bar chart!",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#one-way-anova-3",
    "href": "W9_FirstAnalysisR.html#one-way-anova-3",
    "title": "09 Statistical Analyses in R",
    "section": "One-Way ANOVA 3",
    "text": "One-Way ANOVA 3\n\nRun the ANOVA using lm() and formula notation.\n\n\nmod1 &lt;- lm(intrusions ~ Condition, data = dat)\nanova(mod1)\n\nAnalysis of Variance Table\n\nResponse: intrusions\n          Df Sum Sq Mean Sq F value  Pr(&gt;F)  \nCondition  3 114.82  38.273  3.7948 0.01409 *\nResiduals 68 685.83  10.086                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nUsing afex::aov_ez:\n\n\nlibrary(afex)\nmod &lt;- aov_ez(id = \"subject\", # the column containing the subject IDs\n              dv = \"intrusions\", # the DV \n              between = \"Condition\", # the between-subject variable\n              es = \"pes\", # can output an effect size! we want partial eta-squared\n              type = 3, # there are both reasons for 2 and 3 (not covered here)\n              include_aov = TRUE, # needed for some calculations with emmeans but takes longer\n              data = dat)\nanova(mod)\n\nAnova Table (Type 3 tests)\n\nResponse: intrusions\n          num Df den Df    MSE      F     ges  Pr(&gt;F)  \nCondition      3     68 10.086 3.7948 0.14341 0.01409 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#checking-the-assumptions",
    "href": "W9_FirstAnalysisR.html#checking-the-assumptions",
    "title": "09 Statistical Analyses in R",
    "section": "Checking the Assumptions",
    "text": "Checking the Assumptions\n\nlibrary(performance)\nlibrary(patchwork)\n\ncheck_model(mod1) # doesn't work for ezANOVA output!\n\n\n\n\n\n\n\n# \"manually\" check normality of residuals \n\nqqPlot(mod$aov$residuals)\n\n\n\n\n\n\n\n\n[1]  3 57\n\nshapiro.test(mod$aov$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  mod$aov$residuals\nW = 0.87739, p-value = 4.252e-06\n\n# check homogeneity of variance\ntest_levene(mod)\n\nWarning: Variances differ between groups (Levene's Test, p = 0.039).\n\n\nBoth assumptions are not met!\nBut ANOVAS are quite robust to (minor) deviations…\n(if the assumptions are violated more, you could…\n- run a non-parametric test (Kruskall-Wallis for between-subjects designs of Friedman for repeated measures)\n- transform the data (see Field et al., 2009)\n- use bootstrapping (see Field et al., 2009)",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#post-hoc-tests",
    "href": "W9_FirstAnalysisR.html#post-hoc-tests",
    "title": "09 Statistical Analyses in R",
    "section": "Post-Hoc Tests",
    "text": "Post-Hoc Tests\nSo now we know that there are differences between the Conditions, but we don’t know yet which groups differ from each other. We could thus calculate pairwise comparisons or post-hoc t-tests to compare each condition to the others by by filtering the data (so that only two conditions remain) and running t-tests.\nA more convenient way is to use the emmeans() function from the package with the same name. We can also adjust the tests for multiple comparisons directly.\nWe could also define specific contrasts to test a priori (i.e., based on hypotheses). But we will skip this here.\n\nlibrary(emmeans)\nmod %&gt;% emmeans(pairwise ~ Condition, adjust = \"bonferroni\") # also works with mod1!\n\n$emmeans\n Condition emmean    SE df lower.CL upper.CL\n 1           5.11 0.749 68    3.617     6.60\n 2           1.89 0.749 68    0.395     3.38\n 3           3.89 0.749 68    2.395     5.38\n 4           4.83 0.749 68    3.340     6.33\n\nConfidence level used: 0.95 \n\n$contrasts\n contrast                estimate   SE df t.ratio p.value\n Condition1 - Condition2    3.222 1.06 68   3.044  0.0199\n Condition1 - Condition3    1.222 1.06 68   1.155  1.0000\n Condition1 - Condition4    0.278 1.06 68   0.262  1.0000\n Condition2 - Condition3   -2.000 1.06 68  -1.889  0.3787\n Condition2 - Condition4   -2.944 1.06 68  -2.781  0.0420\n Condition3 - Condition4   -0.944 1.06 68  -0.892  1.0000\n\nP value adjustment: bonferroni method for 6 tests \n\n\n\nShould we adjust for multiple comparisons? It depends. There are good reasons for either.",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#effect-sizes-power",
    "href": "W9_FirstAnalysisR.html#effect-sizes-power",
    "title": "09 Statistical Analyses in R",
    "section": "Effect Sizes & Power",
    "text": "Effect Sizes & Power\nThe most common effect size estimate for an ANOVA is partial eta squared \\(\\eta_p^2\\) (as we calculated with afex::aov_ez before). We get one per factor and it summarizes all pairwise effects within it.\nWe could also calculate Cohen’s d for each pairwise comparison within the factor but this is tedious and gets confusing quickly (1 factor with 5 levels = 10 effects; 3 factors with 5 levels each = 30 effects). It’s still sad that emmeans doesn’t output it as one additional column.\n\n\n\nEffect sizes are important to calculate the statistical power of your study before conducting it. Use an estimated effect size based on prior research:\n\nlibrary(pwr)\npwr.anova.test(k = 4, f = .4, sig.level = .05, power = .8) #we leave out the n parameter to let it be calculated\n\n\n     Balanced one-way analysis of variance power calculation \n\n              k = 4\n              n = 18.04262\n              f = 0.4\n      sig.level = 0.05\n          power = 0.8\n\nNOTE: n is number in each group",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W9_FirstAnalysisR.html#write-up",
    "href": "W9_FirstAnalysisR.html#write-up",
    "title": "09 Statistical Analyses in R",
    "section": "Write Up",
    "text": "Write Up\nOnce again, the apa package helps us here - if we used afex::aov_ez instead of lm 😅:\n\nmod %&gt;% apa::anova_apa()\n\n       Effect                                              \n1 (Intercept) F(1, 68) = 110.29, p &lt; .001, petasq = .62 ***\n2   Condition F(3, 68) =   3.79, p = .014, petasq = .14 *  \n\n\n\n\nmod %&gt;% emmeans(\"Condition\") %&gt;% pairs(adjust=\"none\") #follow up t-tests without adjustment\n\n contrast                estimate   SE df t.ratio p.value\n Condition1 - Condition2    3.222 1.06 68   3.044  0.0033\n Condition1 - Condition3    1.222 1.06 68   1.155  0.2523\n Condition1 - Condition4    0.278 1.06 68   0.262  0.7938\n Condition2 - Condition3   -2.000 1.06 68  -1.889  0.0631\n Condition2 - Condition4   -2.944 1.06 68  -2.781  0.0070\n Condition3 - Condition4   -0.944 1.06 68  -0.892  0.3755\n\n\nLooking at contrasts including condition 1 (control group): Only condition 2 different.\nLet’s get the associated effect size of this specific contrast:\n\n\n\nlibrary(lsr)\ncohensD(intrusions ~ Condition, \n        data = filter(dat, Condition %in% c(1,2)) %&gt;% droplevels())\n\n[1] 0.9964172\n\n\n\n\n\nThere was a significant difference between groups in overall intrusion frequency in daily life, \\(F(3, 68) = 3.79, p = 0.014, \\eta_p^2 = .14\\). Pairwise comparisons demonstrated that relative to the no-task control group, only those in the reactivation-plus-Tetris group, \\(t(68) = 3.04, p &lt; 0.01, d = 1.00\\), experienced significantly fewer intrusive memories…",
    "crumbs": [
      "09 Statistical Analyses in R"
    ]
  },
  {
    "objectID": "W13_RMarkdown.html#comparison-r-vs.-r-markdown-1",
    "href": "W13_RMarkdown.html#comparison-r-vs.-r-markdown-1",
    "title": "13 R Markdown",
    "section": "Comparison: R vs. R Markdown 1",
    "text": "Comparison: R vs. R Markdown 1\n\n\n\nR script\n\n\n\n\n\n\nR Markdown",
    "crumbs": [
      "13 R Markdown"
    ]
  },
  {
    "objectID": "W13_RMarkdown.html#comparison-r-vs.-r-markdown-2",
    "href": "W13_RMarkdown.html#comparison-r-vs.-r-markdown-2",
    "title": "13 R Markdown",
    "section": "Comparison: R vs. R Markdown 2",
    "text": "Comparison: R vs. R Markdown 2\n\n\n\nR Markdown\n\n\n\n\n\nR Markdown rendered as html report",
    "crumbs": [
      "13 R Markdown"
    ]
  },
  {
    "objectID": "W13_RMarkdown.html#your-first-r-markdown-script",
    "href": "W13_RMarkdown.html#your-first-r-markdown-script",
    "title": "13 R Markdown",
    "section": "Your First R Markdown Script",
    "text": "Your First R Markdown Script\n\nOpen a new .Rmd file, change/insert the title and author.\nCheck out the content of it. What different parts do you see?\n\n\n\nSwitch between “Source” and “Visual” in the top left. What changes? What is “Visual”?\n\n\n\n\nDelete and add some of the text on the white background. Change the Header (indicated by ##) to “About me” and write something about yourself underneath.\nIn the grey boxes (“code chunks”), add some code. Try to find out how you can add a new code chunk.\n\n\n\n\nSave the file with a sensible name.\nWhat happens when you click on “Knit” (top of Script pane)?\n\n\n\nhint: The green C with the + on the top right will do so (or using “insert” in the visual view)\nClick on the little arrow next to knit and select “Knit to PDF”\ninsert inline code",
    "crumbs": [
      "13 R Markdown"
    ]
  },
  {
    "objectID": "W13_RMarkdown.html#r-markdown-advantages",
    "href": "W13_RMarkdown.html#r-markdown-advantages",
    "title": "13 R Markdown",
    "section": "R Markdown Advantages",
    "text": "R Markdown Advantages\nThere are many useful things you can do with R Markdown (adding different headers, adding inline code, knitting as a PDF, adding pictures or tables…). You can also decide whether the code chunks should be visible in the output, etc.\nFor further information, check out the R Markdown cheatsheet: https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf\n\nOptions for your code chunks:\n\nExamples:\n```{r, eval=FALSE}\n#your code here\n```",
    "crumbs": [
      "13 R Markdown"
    ]
  },
  {
    "objectID": "W13_RMarkdown.html#code-chunk-options",
    "href": "W13_RMarkdown.html#code-chunk-options",
    "title": "13 R Markdown",
    "section": "Code Chunk Options",
    "text": "Code Chunk Options\nOptions for your code chunks:\n\nYou can change these default values for code chunks for the rest of your document:\n```{r, include=FALSE}\nknitr::opts_chunk$set(\n  comment = \"#&gt;\", echo = FALSE, fig.width = 6\n)\n```\nFore more information, see https://bookdown.org/yihui/rmarkdown-cookbook/chunk-options.html",
    "crumbs": [
      "13 R Markdown"
    ]
  },
  {
    "objectID": "W13_RMarkdown.html#from-an-r-script-to-r-markdown",
    "href": "W13_RMarkdown.html#from-an-r-script-to-r-markdown",
    "title": "13 R Markdown",
    "section": "From an R script to R Markdown",
    "text": "From an R script to R Markdown\nPreviously, we have just worked with .R scripts. If you have a full R script with your entire analysis (or even several scripts), how do you include them in an R Markdown file?\n\n\nCopy all code into one giant code chunk:\n\n```{r}\n#copy all code here\n```\nYou can break this code chunk apart into smaller ones by copying this into a new line of the code chunk:\n```\n\n```{r}\n\n\n\n2. “Import” the R script and run it with the source function:\n```{r message=FALSE, warning=FALSE}\nsource(\"analysis.R\", #your R script here (same folder as your project)\n       local = knitr::knit_global())\n```\nYou can now use all variables that you have created in your R script.",
    "crumbs": [
      "13 R Markdown"
    ]
  },
  {
    "objectID": "W13_RMarkdown.html#your-second-r-markdown-script",
    "href": "W13_RMarkdown.html#your-second-r-markdown-script",
    "title": "13 R Markdown",
    "section": "Your Second R Markdown Script",
    "text": "Your Second R Markdown Script\n\nUse one of the two methods described before to include any R script from a previous R code session in your R Markdown document.\nOutput the content of any variable of your R script and include it as inline code in some text (Cheat Sheet).\n\n\n```{r}\ndata = tibble(rt = rnorm(n=100, mean=.5, sd=.2))\n```\nWe observed an average reaction time of `r data %&gt;% pull(rt) %&gt;% mean() %&gt;% signif(digits=3)` seconds.\nWe observed an average reaction time of 0.484 seconds.\n\n\n```{r}\ndata = tibble(a = rnorm(n=100, mean=.5, sd=.2), b = rnorm(n=100, mean=.4, sd=.2))\nmytest = with(data, t.test(a, b, paired=T))\n#mytest %&gt;% apa::t_apa()\n```\nWe performed a paired *t*-test and found a significant difference between both conditions \n(`r mytest %&gt;% apa::t_apa(print=F, format=\"rmarkdown\")`). In condition A, reaction times were higher \n(*M* = `r data %&gt;% pull(a) %&gt;% mean() %&gt;% signif(3)` s, *SD* = `r data %&gt;% pull(a) %&gt;% sd() %&gt;% signif(3)` s)\ncompared to condition B  (*M* = `r data %&gt;% pull(b) %&gt;% mean() %&gt;% signif(3)` s, *SD* = `r data %&gt;% pull(b) %&gt;% sd() %&gt;% signif(3)` s).\nWe performed a paired t-test and found a significant difference between both conditions (t(99) = 2.58, p = .011, d = 0.26). In condition A, reaction times were higher (M = 0.478 s, SD = 0.197 s) compared to condition B (M = 0.41 s, SD = 0.188 s).\n\n\n\n3. Knit the document and open the output with a double click.",
    "crumbs": [
      "13 R Markdown"
    ]
  },
  {
    "objectID": "W6_Sampling.html#how-do-we-sample",
    "href": "W6_Sampling.html#how-do-we-sample",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "How Do We Sample?",
    "text": "How Do We Sample?\nThe sample needs to be representative of the entire population, that’s why it’s critical how we select the individuals.\nThink about examples of non-representative samples!\n\nRepresentative: Every member of the population has an equal chance of being selected.\nIf non-representative: sample statistic is biased, its value is (systematically) different from the true population value (parameter).\n(But talking about bias is mostly a theoretical discussion: Usually we of course don’t know the population parameter and thus cannot compare our estimate with it! Otherwise we wouldn’t need to sample.)\n\nNon-representative: pollster calls people from list of Democratic party, or from rich neighborhood, or only uses psychology students :D\nThink about “your” sample, how could this be non-representative?",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#different-ways-of-sampling",
    "href": "W6_Sampling.html#different-ways-of-sampling",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Different Ways of Sampling",
    "text": "Different Ways of Sampling\n\nwithout replacement: Once a member of the population is sampled, they are not eligible to be sampled again. This is the most common variant of sampling.\nwith replacement: After a member of the population has been sampled, they are put back into the pool and could potentially be sampled again. This usually happens out of accident or by necessity (cf. Bootstrapping)",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#sampling-error",
    "href": "W6_Sampling.html#sampling-error",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Sampling Error",
    "text": "Sampling Error\nIt is likely that our sample statistic differs slightly from the population parameter. This is called the sampling error.\nIf we collect multiple samples, the sample statistic will always differ slightly. If we combine all those sample statistics, we can approximate the sampling distribution.\nOf course, we want to minimize the sampling error and get a good estimate of the population parameter!",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#example-sampling-distribution",
    "href": "W6_Sampling.html#example-sampling-distribution",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Example Sampling Distribution",
    "text": "Example Sampling Distribution\nLet’s use the NHANES dataset again and let’s assume it is the entire population. We can calculate the mean (\\(\\mu = 168.35\\)) and standard deviation (\\(\\sigma = 10.16\\)) as the population parameters. If we repeatedly sample 50 individuals, we get this:\n\n\n\n\n\n\n\nsampleMean\nsampleSD\n\n\n\n\n164.582\n8.631756\n\n\n168.102\n10.388759\n\n\n167.206\n9.812454\n\n\n170.006\n11.372477\n\n\n168.512\n11.101804\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe sample means and SDs are similar, but not exactly equal to the population parameters.\nIf we sample 5000 times (50 individuals each), we can see that the average of these 5000 sample means (depicted in blue) is similar to the population mean!\nAverage sample mean across 5000 sample: \\(\\hat{X} = 168.3463\\).\n\ngrey = population histogram (raw data) blue = sample means of samples with N=50\nWhat is similar between these distributions? What is different?",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#standard-error-of-the-mean",
    "href": "W6_Sampling.html#standard-error-of-the-mean",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Standard Error of the Mean",
    "text": "Standard Error of the Mean\nIn the example on the last slide, the means were all pretty close to each other, i.e. the blue distribution was very narrow and the variance small (compared to the grey distribution). This is an inherent statistical property of sample means: By averaging several individual values, thus aggregating them into a sample (here with \\(n = 50\\)), we reduce the variability of the sampling distribution.\n\nWe can quantify this variability of the sample mean with the standard error of the mean (SEM).\n\\[SEM = \\frac{\\hat{\\sigma}}{\\sqrt{n}}\\]\nThis formula needs two values: the population variability \\(\\sigma\\) (or sample SD \\(\\hat{\\sigma}\\) as approximation) and the size of our sample \\(n\\).\n\n\nWe can only control our sample size, thus if we want a better estimate, we can increase sample size!\nA sample of \\(n = 50\\) already decreases the population variability by a factor of \\(\\sqrt{50} = 7.1\\) !\n\nSEM ~ SD of sampling distribution of the mean\nTakes the SD of the data and divides it by sample size (so always smaller than SD!)\nWe use the sample SD as an approximation for the population SD\nUse the sigma of the data? same as sd(sample_means)\n“the utility of larger samples diminishes with the square root of the sample size”: Doubling the sample size will not double the quality of the statistic.",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#the-central-limit-theorem",
    "href": "W6_Sampling.html#the-central-limit-theorem",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "The Central Limit Theorem",
    "text": "The Central Limit Theorem\nThe Central Limit Theorem (CLT) is a fundamental (and often misunderstood) concept of statistics.\nCLT: With larger sample sizes, the sampling distribution of sample means (i.e., the blue distribution from before) will become more and more normally distributed*, even if the population distribution is not (i.e., the grey distribution from before)!\n\nNormal Distribution of Height\nNote: Means approximate a normal distribution, irrespective of the distribution from which the data stem. This is because the sampling error between the sampling mean \\(\\hat{\\mu}\\) and the population mean \\(\\mu\\) follows a normal distribution.\n\nDescribed by mean and sd: Shape never changes, only location and width!",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#clt-in-action",
    "href": "W6_Sampling.html#clt-in-action",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "CLT in Action",
    "text": "CLT in Action\nOn the left you can see a highly skewed distribution of alcohol consumption per year (from the NHANES dataset). If we repeatedly draw samples of size 50 from the datset and take the mean, we get the right distribution of sample means - which looks a lot more “normal” (normal distribution is added in red)!\n\n\nThe CLT is important because it allows us to safely assume that the sampling distribution of the mean will be normal in most cases, which is a necessary prerequisite for many statistical techniques.\n\nRed peak: True population mean Blue values left of peak: Sampling error with underestimation of the true population mean Blue values right of peak: Sampling error with overestimation of the true population mean",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#monte-carlo-simulation",
    "href": "W6_Sampling.html#monte-carlo-simulation",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Monte Carlo Simulation",
    "text": "Monte Carlo Simulation\nWith the increasing use of computers, simulations have become an essential part of modern statistics. Monte Carlo simulations are the most common ones in statistics.\nThere are four steps to performing a Monte Carlo simulation:\n\nDefine a domain of possible values.\nGenerate random numbers within that domain from a probability distribution.\nPerform a computation using the random numbers.\nCombine the results across many repetitions.",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#randomness-in-statistics",
    "href": "W6_Sampling.html#randomness-in-statistics",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Randomness in Statistics",
    "text": "Randomness in Statistics\nRandom = unpredictable.\nFor a Monte Carlo simulation, we need pseudo-random* numbers, which are generated by a computer algorithm.\n\nWe can simply generate (pseudo-)random numbers from different distributions with R, e.g. with rnorm() to draw (pseudo-)random numbers from a normal distribution:\n\n\n# Draw 10000 random numbers of a normal distribution with mean=0, sd=1\nrand_num &lt;- rnorm(n=10000, mean=0, sd=1)\n\n# Plot the random numbers and verify that they make up a normal distribution\ntibble(x = rand_num) %&gt;% \n  ggplot(aes(x)) +\n  geom_histogram(bins = 100) +\n  labs(title = \"Normal\")\n\n\n\n\n\n\n\n\n\n\n\n\nEach time, we generate random numbers, these will differ slightly.\nBut we can also generate the exact same set of random numbers (which will be helpful to reproduce results!) by setting the random seed to a specific value such as 123: set.seed(123).\n\n\nrnorm(): Here, r stands for random normal distribution\nFlip a coin, we don’t know the outcome! (Only if we knew a lot of physics and the conditions…)\nHumans have a bad sense of randomness, we think we see patterns everywhere (gambler’s fallacy: being due for a win).\n\n\n\n* Truly random numbers, that are completely unpredictable, are only possible through physical processes that are difficult to obtain.\nPseudo-random numbers will only seem random (they are difficult to predict) but will repeat at some point.",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#using-monte-carlo-simulations",
    "href": "W6_Sampling.html#using-monte-carlo-simulations",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Using Monte Carlo Simulations",
    "text": "Using Monte Carlo Simulations\nExample: Let’s try to find out how much time we should allow for a short in-class quiz.\nWe pretend to know the distribution of completion times is normal, with mean = 5 min and SD = 1 min.\nHow long does the test period need to be so that we can expect ALL students (n = 150) to finish in 99% of the quizzes?\n\nTo answer this question, we need the distribution of the longest finishing time.\nWhat we will do is to simulate finishing times for a great number of quizzes and take the maximum of each (the longest finishing time). We can then look at the distribution of maximum finishing times and see where the 99% quantile is.\nThis value is the amount of time that we should allow - given our assumptions!!",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#using-monte-carlo-simulations-2",
    "href": "W6_Sampling.html#using-monte-carlo-simulations-2",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Using Monte Carlo Simulations 2",
    "text": "Using Monte Carlo Simulations 2\nLet’s repeat the steps of the simulation by going through the four steps mentioned before:\n\nDefine a domain of possible values.\n\n–&gt; Our assumptions: The values would come from a normal distribution with \\(n = 150\\), \\(mean = 5\\), and \\(SD = 1\\).\n\n\nGenerate random numbers within that domain from a probability distribution.\n\n\nrand_num &lt;- rnorm(n = 150, mean = 5, sd = 1)\n\n\n\n\nPerform a computation using the random numbers.\n\n\nmax_rand_num &lt;- max(rand_num) #time of slowest student",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#using-monte-carlo-simulations-3",
    "href": "W6_Sampling.html#using-monte-carlo-simulations-3",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Using Monte Carlo Simulations 3",
    "text": "Using Monte Carlo Simulations 3\n\nCombine the results across many repetitions.\n\n\nnrep &lt;- 5000 #number of repetitions\n\n# initialize an empty matrix to fill in the max values later\nmax_rand_num &lt;- matrix(data = NA, nrow = nrep, ncol=1)\n\n# use a for-loop to repeat resampling nrep times!\nfor (i in 1:nrep) {\n  rand_num &lt;- rnorm(n = 150, mean = 5, sd = 1)\n  max_rand_num[i, 1] &lt;- max(rand_num)\n}\n\n# get the cutoff (99%) of the distribution of max values\ncutoff &lt;- quantile(max_rand_num, 0.99)\nprint(cutoff)\n\n     99% \n8.793609",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#using-monte-carlo-simulations-4",
    "href": "W6_Sampling.html#using-monte-carlo-simulations-4",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Using Monte Carlo Simulations 4",
    "text": "Using Monte Carlo Simulations 4\n\nThis shows that the 99th percentile of the finishing time distribution falls at 8.8602684 minutes, meaning that if we were to give that much time for the quiz, then we expect that in 99% of quizzes, every student would finish.\n\nAssumptions matter, otherwise results wrong! (We assumed: normal dist w/ particular mean and SD). Here assumptions certainly wrong –&gt; elapsed time not normal",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#the-bootstrap",
    "href": "W6_Sampling.html#the-bootstrap",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "The Bootstrap",
    "text": "The Bootstrap\nWe can use simulations to demonstrate statistical principles (like we just did) but also to answer statistical questions.\nThe bootstrap is a simulation technique that allows us to quantify our uncertainty of estimates!\n\n\nWe repeatedly sample with replacement from an actual dataset.\nWe compute a statistic of interest for each sample.\nWe get the distribution of those statistics and use it as our sampling distribution.",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#bootstrap-example",
    "href": "W6_Sampling.html#bootstrap-example",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Bootstrap Example",
    "text": "Bootstrap Example\nLet’s use the bootstrap to estimate the sampling distribution of the mean heights of the NHANES dataset. We can then compare the result to the SEM (=uncertainty of the mean) that we discussed earlier.\n\n\n\n# perform the bootstrap to compute SEM and compare to parametric method\nnRuns &lt;- 2500\nsampleSize &lt;- 32\n\nheightSample &lt;- \n  NHANES_adult %&gt;%\n  sample_n(sampleSize) # draw 32 observations\n\n# function to bootstrap (sample w/ replacement) & get mean\nbootMeanHeight &lt;- function(df) {\n  bootSample &lt;- sample_n(df, dim(df)[1], replace = TRUE)\n  return(mean(bootSample$Height))\n}\n\n# run function 2500x\nbootMeans &lt;- replicate(nRuns, bootMeanHeight(heightSample))\n\n# calculate \"normal\" SEM and bootstrap SEM\nSEM_standard &lt;- sd(heightSample$Height) / sqrt(sampleSize)\nSEM_bootstrap &lt;- sd(bootMeans)\n\nSEM_standard\n\n[1] 2.081422\n\nSEM_bootstrap\n\n[1] 2.008614\n\n\n\n\n\n\n\n\nAn example of bootstrapping to compute the standard error of the mean adult height in the NHANES dataset. The histogram shows the distribution of means across bootstrap samples, while the red line shows the normal distribution based on the sample mean and standard deviation.",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#evaluation-bootstrapping",
    "href": "W6_Sampling.html#evaluation-bootstrapping",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Evaluation: Bootstrapping",
    "text": "Evaluation: Bootstrapping\n\n\nCon\nTakes very long to compute (compared to the SEM)\nPrecision depends on computing time\n\nPro\nNo assumption about sampling distribution necessary\nIs a good solution if you do not want to rely on certain assumptions\n\n\n\nBootstrapping is a so-called model-free procedure: You put in just the data and get a result that does not depend on any further assumptions.\nModel-based procedures (like most statistical tests we will cover in this class) are usually more precise if their assumptions are met. Unfortunately, assumptions are not always straightforward to check.",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#simulate-different-distributions",
    "href": "W6_Sampling.html#simulate-different-distributions",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Simulate Different Distributions",
    "text": "Simulate Different Distributions\nIt is possible to draw data from different distributions:\n\n\nnsamples &lt;- 10000 \nnhistbins &lt;- 100  \n\n# uniform distribution \np1 &lt;- tibble(x = runif(nsamples)) %&gt;%    \n  ggplot((aes(x))) + \n  geom_histogram(bins = nhistbins) +    \n  labs(title = \"Uniform\")  \n\n# binomial distribution \np2 &lt;- tibble(x = rbinom(nsamples, 20, 0.25)) %&gt;%    \n  ggplot(aes(x)) + \n  geom_histogram(bins = nhistbins) +   \n  labs(title = \"Binomial (p=0.25, 20 trials)\")  \n\n# normal distribution \np3 &lt;- tibble(x = rnorm(nsamples)) %&gt;%    \n  ggplot(aes(x)) + \n  geom_histogram(bins = nhistbins) +   \n  labs(title = \"Normal\")  \n\n# Chi-squared distribution \np4 &lt;- tibble(x = rchisq(nsamples, df=1)) %&gt;%    \n  ggplot(aes(x)) + \n  geom_histogram(bins = nhistbins) +   \n  labs(title = \"Chi-squared\")  \n\ncowplot::plot_grid(p1, p2, p3, p4, ncol = 1)",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#simulate-a-fake-dataset",
    "href": "W6_Sampling.html#simulate-a-fake-dataset",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Simulate a Fake Dataset",
    "text": "Simulate a Fake Dataset\nLet’s simulate data of 120 participants of different heights and genders flipping a coin. To do so, we need to know how to simulate a) heights, b) flip a coin, and c) assign genders.\n\nSimulate heights:\n\nheights &lt;- rnorm(120, mean = 170, sd = 10)\n\n\n\nSimulate coin flips:\n(Instead of drawing from a probability distribution function that starts with an r, e.g. rnorm(), we use sample(), which randomly (uniformly) draws from values you determine. We need to set replace=TRUE)\n\ncoin_flips &lt;- sample(c(\"Head\", \"Tail\"), 120, replace=TRUE) \n\n\n\nWe could of course use similar code to simulate gender or the like.\nBut if we want to predetermine which genders we want to collect data from (i.e. same number in each gender group), we can also use the function rep(). This function will simply repeat an observation for a number of rows:\n\ngenders &lt;- rep(x = c(\"man\", \"woman\", \"nonbinary\"), each = 40) #%&gt;% sample() \n#you can run just \"sample\" on a vector to randomize its order \n\n\n\nDetermine participant numbers and combining everything into one dataframe:\n\nsim_data &lt;- tibble(   \n  participant_number = 1:120,   \n  gender = rep(x = c(\"man\", \"woman\", \"nonbinary\"), each = 40),   \n  height = rnorm(120, mean = 170, sd = 10),   \n  coin_flip = sample(c(\"Head\", \"Tail\"), 120, replace=TRUE) )  \n\n# or if you have run all the code before, you could also use the objects you have already in your Environment: \n# sim_data &lt;- tibble(participant_number = 1:120, genders, heights, coin_flips)\n\nIf we wanted to do a Monte Carlo Simulation, we could use the code from the last slide and put the simulation into a for loop. Inside the for loop, we would also calculate some value of interest (one estimate per subsample, such as the mean).",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#resampling",
    "href": "W6_Sampling.html#resampling",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Resampling",
    "text": "Resampling\nLet’s look at the Bootstrap. Remember that we usually use real data for bootstrapping and draw samples with replacement of the same size as the original dataset. We can use this to quantify uncertainty, such as with the Standard Error of the Mean (SEM) or Confidence Intervals.\nLet’s say we have a very small sample of “sweets consumed”. We don’t know the underlying distribution. We make up a dataset, but let’s pretend it is our real data:\n\ndata_10 &lt;- tibble(\n  participant = 1:10,\n  sweets = c(5, 5, 5, 7, 3, 3, 4, 6, 8, 4)\n)\n\n\nWe want to know how sample size influences the SEM, so we also have a sample with twice 10x as many observations:\n\ndata_20 &lt;- tibble(\n  participant = 1:100,\n  sweets = rpois(100,4) #random Poisson distribution\n)",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#resampling-2",
    "href": "W6_Sampling.html#resampling-2",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Resampling 2",
    "text": "Resampling 2\nBut for now, let’s look at the Bootstrap. Remember that we usually use real data for bootstrapping and draw samples with replacement of the same size as the original dataset. We can use this to quantify uncertainty, such as with the Standard Error of the Mean (SEM) or Confidence Intervals.\nLet’s say we have a very small sample of “sweets consumed”. We don’t know the underlying distribution. We make up a dataset, but let’s pretend it is our real data:\n\ndata_10 &lt;- tibble(\n  participant = 1:10,\n  sweets = c(5, 5, 5, 7, 3, 3, 4, 6, 8, 4)\n)\n\n\nWe want to know how sample size influences the SEM, so we also have a sample with twice 10x as many observations:\n\ndata_20 &lt;- tibble(\n  participant = 1:100,\n  sweets = rpois(100,4) #random Poisson distribution\n)",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#resampling-3",
    "href": "W6_Sampling.html#resampling-3",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Resampling 3",
    "text": "Resampling 3\nLet’s resample 1000 times. To get the sampling distributions of the means, we have to save each mean of each iteration:\n\nset.seed(8465123)\niterations &lt;- 1000 \n\n# initialize empty matrices\nmean_bootstrap_10 &lt;- matrix(NA, nrow = iterations, ncol = 1)\nmean_bootstrap_20 &lt;- matrix(NA, nrow = iterations, ncol = 1)\n\nfor (i in 1:iterations) {\n  # draw exactly the same amount of datapoints as in the original dataset, but with replacement\n  bootstrap_data_10 &lt;- sample_n(data_10, 10, replace=TRUE)\n  bootstrap_data_20 &lt;- sample_n(data_20, 20, replace=TRUE)\n  \n  # calculate the mean for each of the subsamples, put it into matrix in subsequent rows\n  mean_bootstrap_10[i,1] &lt;- mean(bootstrap_data_10$sweets)\n  mean_bootstrap_20[i,1] &lt;- mean(bootstrap_data_20$sweets)\n}\n\n# calculate the SEMs\nsd(mean_bootstrap_10)\n\n[1] 0.4948013\n\nsd(mean_bootstrap_20)\n\n[1] 0.4638429\n\n\nWe can conclude that the SEM is smaller with a larger sample size, which means we can be more certain about our estimate! (We already knew this from the \\(\\sqrt{n}\\) in the denominator of the SE formular but it’s nice to see it confirmed.)",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#resampling-the-bootstrap",
    "href": "W6_Sampling.html#resampling-the-bootstrap",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Resampling: The Bootstrap",
    "text": "Resampling: The Bootstrap\nWe can use simulations to demonstrate statistical principles (like we just did) but also to answer statistical questions.\nThe bootstrap is a simulation technique that allows us to quantify our uncertainty of estimates!\n\n\nWe repeatedly sample with replacement from an actual dataset.\nWe compute a statistic of interest for each sample.\nWe get the distribution of those statistics and use it as our sampling distribution.",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  },
  {
    "objectID": "W6_Sampling.html#simulations",
    "href": "W6_Sampling.html#simulations",
    "title": "06 Sampling and Resampling/Simulations",
    "section": "Simulations",
    "text": "Simulations\nAs you saw in last lecture, we can also use similar functions (usually starting with r) to simulate data (i.e., to draw samples from probability distributions).\nThis can be helpful if we don’t know the “ground truth” or want to quantify uncertainty. We can also use simulations to calculate the power of a study.\nWith simulations, we define the expected “ground truth” (distribution of the population) and generate data from it.\n\nExample: We can use rnorm() to simulate data from a normal distribution with given parameters. Here, we will use means and SDs from the Scottish Health Survey (2008) to visualize two normal distributions:\n\n\nmen &lt;- rnorm(n = 100000, mean = 176.2, sd = 6.748) \nwomen &lt;- rnorm(n = 100000, mean = 163.8, sd = 6.931)  \nheights &lt;- tibble(men, women) %&gt;%   \n  pivot_longer(names_to = \"sex\", values_to = \"height\", men:women)  \nheights %&gt;% \n  ggplot(aes(x = height, fill = sex)) +   \n  geom_density(alpha = .6) +   \n  scale_fill_viridis_d(option = \"E\") +   \n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nWe could use these data to visualize how much overlap there is between the two distributions of men and women, or to test how big the difference in height needs to be to become significant etc.\nWe use “real data” as input for the simulations! So the simulations are based on empirical values (means, sd), but we actually draw more observations, 100.000!",
    "crumbs": [
      "06 Sampling and Resampling/Simulations"
    ]
  }
]